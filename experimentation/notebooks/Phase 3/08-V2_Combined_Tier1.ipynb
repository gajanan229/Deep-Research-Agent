{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ceeb693",
   "metadata": {},
   "source": [
    "# Combined Tier 1 Paradigms: Deep Research Agent\n",
    "\n",
    "This notebook implements the **Combined Tier 1 Architecture** that unifies four paradigms:\n",
    "\n",
    "1. **Cascading Knowledge Cache** - Global search layer wrapping all operations\n",
    "2. **Agile Sprints** - Information gathering with retrospectives\n",
    "3. **Iterative Refinement V2** - Skeleton-based document generation with patches\n",
    "4. **Quality Gates** - Strategic checkpoints for quality assurance\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The architecture follows a **funnel pattern**:\n",
    "```\n",
    "Wide Research → Structured Synthesis → Focused Refinement → Polished Output\n",
    "```\n",
    "\n",
    "### Five Phases:\n",
    "1. **Phase 1: Agile Research Sprints** - Comprehensive information gathering\n",
    "2. **Phase 2: Skeleton Generation** - Create document structure\n",
    "3. **Phase 3: Node Expansion** - Generate prose per section\n",
    "4. **Phase 4: Verification & Refinement** - Quality gates and patching\n",
    "5. **Phase 5: Final Assembly** - Compile polished report\n",
    "\n",
    "## Technology Stack\n",
    "- **LLM**: gpt-5-mini-2025-08-07\n",
    "- **Web Search**: Tavily API\n",
    "- **Embeddings**: OpenAI text-embedding-3-small\n",
    "- **Tracing**: LangSmith\n",
    "- **Framework**: LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4d2e2",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ecf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import asyncio\n",
    "import hashlib\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Annotated, TypedDict, Literal, Optional, Any\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "env_path = Path(\"../../.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"deep_research_new\"\n",
    "\n",
    "print(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-5-mini-2025-08-07\n",
      "Research: max 3 sprints, 5 queries/sprint\n",
      "Refinement: max 2 iterations, threshold 7.5/10\n",
      "Cache: HIGH >= 0.75, LOW < 0.4\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM, Tavily, and Embeddings\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0, max_retries=10)\n",
    "tavily_client = TavilyClient()\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ===== CONFIGURATION PARAMETERS =====\n",
    "\n",
    "# Research Phase (Agile Sprints)\n",
    "MAX_RESEARCH_SPRINTS = 3\n",
    "QUERIES_PER_SPRINT = 5\n",
    "MIN_SOURCES_FOR_GATE1 = 15\n",
    "MIN_DOMAINS_FOR_GATE1 = 5\n",
    "\n",
    "# Skeleton Generation\n",
    "TARGET_WORDS_PER_NODE = 300\n",
    "MIN_SECTIONS = 5\n",
    "MAX_SECTIONS = 8\n",
    "\n",
    "# Knowledge Cache\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.75\n",
    "LOW_CONFIDENCE_THRESHOLD = 0.40\n",
    "SPECIFICITY_ADJUSTMENT = 0.2\n",
    "TOP_K_RETRIEVAL = 5\n",
    "\n",
    "# Verification & Refinement\n",
    "MAX_REFINEMENT_ITERATIONS = 2\n",
    "QUALITY_THRESHOLD = 7.5\n",
    "MIN_EVIDENCE_SCORE = 6\n",
    "MAX_CASCADES_PER_ITERATION = 5\n",
    "\n",
    "# Token Management\n",
    "MAX_CONTEXT_CHARS = 12000\n",
    "MAX_FINDINGS_CHARS = 10000\n",
    "\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "print(f\"Research: max {MAX_RESEARCH_SPRINTS} sprints, {QUERIES_PER_SPRINT} queries/sprint\")\n",
    "print(f\"Refinement: max {MAX_REFINEMENT_ITERATIONS} iterations, threshold {QUALITY_THRESHOLD}/10\")\n",
    "print(f\"Cache: HIGH >= {HIGH_CONFIDENCE_THRESHOLD}, LOW < {LOW_CONFIDENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caa8a6",
   "metadata": {},
   "source": [
    "## 2. Knowledge Cache Implementation\n",
    "\n",
    "The Knowledge Cache wraps ALL search operations throughout the agent, providing:\n",
    "- **Layer 1**: Deterministic deduplication (exact query match)\n",
    "- **Layer 2**: Semantic similarity retrieval (vector search)\n",
    "- **Layer 3**: LLM-augmented judgment (gap analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b97ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base initialized\n"
     ]
    }
   ],
   "source": [
    "# ===== Knowledge Cache Data Models =====\n",
    "\n",
    "class CachedDocument(BaseModel):\n",
    "    \"\"\"A cached web document.\"\"\"\n",
    "    url: str\n",
    "    normalized_url: str\n",
    "    content: str\n",
    "    content_hash: str\n",
    "    title: str = \"\"\n",
    "    retrieval_timestamp: str\n",
    "    source_query: str = \"\"\n",
    "\n",
    "\n",
    "class CachedChunk(BaseModel):\n",
    "    \"\"\"A chunk of content with embedding.\"\"\"\n",
    "    chunk_id: str\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "    source_url: str\n",
    "    position: int\n",
    "\n",
    "\n",
    "class CacheDecision(BaseModel):\n",
    "    \"\"\"Record of a cache decision for observability.\"\"\"\n",
    "    query: str\n",
    "    layer_reached: Literal[\"L1\", \"L2\", \"L3\"]\n",
    "    decision: str\n",
    "    confidence_score: float = 0.0\n",
    "    action_taken: Literal[\"USE_CACHE\", \"SEARCH\", \"TARGETED_SEARCH\"]\n",
    "    reasoning: str = \"\"\n",
    "    timestamp: str = \"\"\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    \"\"\"Session-scoped knowledge base with cascading cache capabilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url_registry: Dict[str, CachedDocument] = {}\n",
    "        self.query_cache: Dict[str, dict] = {}\n",
    "        self.chunks: List[CachedChunk] = []\n",
    "        self.chunk_embeddings: Optional[np.ndarray] = None\n",
    "        self.stats = {\n",
    "            \"total_queries\": 0, \"l1_hits\": 0, \"l2_high\": 0, \"l2_medium\": 0,\n",
    "            \"l2_low\": 0, \"l3_sufficient\": 0, \"l3_partial\": 0, \"l3_insufficient\": 0,\n",
    "            \"web_searches_executed\": 0, \"web_searches_avoided\": 0\n",
    "        }\n",
    "\n",
    "    def normalize_url(self, url: str) -> str:\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            host = parsed.netloc.lower()\n",
    "            if host.startswith(\"www.\"):\n",
    "                host = host[4:]\n",
    "            path = parsed.path.rstrip(\"/\")\n",
    "            return f\"https://{host}{path}\"\n",
    "        except:\n",
    "            return url.lower()\n",
    "\n",
    "    def normalize_query_light(self, query: str) -> str:\n",
    "        return \" \".join(query.lower().split())\n",
    "\n",
    "    def normalize_query_aggressive(self, query: str) -> str:\n",
    "        stop_words = {\"the\", \"a\", \"an\", \"is\", \"are\", \"of\", \"in\", \"to\", \"for\", \"and\", \"or\", \"what\", \"how\", \"why\"}\n",
    "        light = self.normalize_query_light(query)\n",
    "        terms = [t for t in light.split() if t not in stop_words and len(t) > 1]\n",
    "        return \" \".join(sorted(terms))\n",
    "\n",
    "    def compute_content_hash(self, content: str) -> str:\n",
    "        return hashlib.sha256(content.encode()).hexdigest()\n",
    "\n",
    "    def add_document(self, url: str, content: str, title: str = \"\", source_query: str = \"\"):\n",
    "        normalized_url = self.normalize_url(url)\n",
    "        doc = CachedDocument(\n",
    "            url=url, normalized_url=normalized_url, content=content,\n",
    "            content_hash=self.compute_content_hash(content), title=title,\n",
    "            retrieval_timestamp=datetime.now().isoformat(), source_query=source_query\n",
    "        )\n",
    "        self.url_registry[normalized_url] = doc\n",
    "        self._chunk_and_embed(doc)\n",
    "        return doc\n",
    "\n",
    "    def _chunk_and_embed(self, doc: CachedDocument):\n",
    "        content = doc.content\n",
    "        chunks_text = []\n",
    "        for i in range(0, len(content), CHUNK_SIZE - CHUNK_OVERLAP):\n",
    "            chunk_text = content[i:i + CHUNK_SIZE]\n",
    "            if len(chunk_text) > 50:\n",
    "                chunks_text.append(chunk_text)\n",
    "        if not chunks_text:\n",
    "            return\n",
    "        embeddings = embeddings_model.embed_documents(chunks_text)\n",
    "        for i, (text, embedding) in enumerate(zip(chunks_text, embeddings)):\n",
    "            chunk = CachedChunk(\n",
    "                chunk_id=f\"{doc.content_hash[:8]}_{i}\", text=text,\n",
    "                embedding=embedding, source_url=doc.url, position=i\n",
    "            )\n",
    "            self.chunks.append(chunk)\n",
    "        self._update_embedding_matrix()\n",
    "\n",
    "    def _update_embedding_matrix(self):\n",
    "        if self.chunks:\n",
    "            self.chunk_embeddings = np.array([c.embedding for c in self.chunks])\n",
    "\n",
    "    def add_query(self, query: str, result_urls: List[str], result_summary: str):\n",
    "        entry = {\n",
    "            \"original_query\": query, \"light_normalized\": self.normalize_query_light(query),\n",
    "            \"aggressive_normalized\": self.normalize_query_aggressive(query),\n",
    "            \"timestamp\": datetime.now().isoformat(), \"result_urls\": result_urls,\n",
    "            \"result_summary\": result_summary\n",
    "        }\n",
    "        self.query_cache[entry[\"light_normalized\"]] = entry\n",
    "        self.query_cache[entry[\"aggressive_normalized\"]] = entry\n",
    "        return entry\n",
    "\n",
    "    def lookup_query_exact(self, query: str) -> Optional[dict]:\n",
    "        return self.query_cache.get(self.normalize_query_light(query))\n",
    "\n",
    "    def semantic_search(self, query: str, top_k: int = TOP_K_RETRIEVAL) -> List[Tuple[CachedChunk, float]]:\n",
    "        if not self.chunks or self.chunk_embeddings is None:\n",
    "            return []\n",
    "        query_embedding = np.array(embeddings_model.embed_query(query))\n",
    "        similarities = np.dot(self.chunk_embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.chunk_embeddings, axis=1) * np.linalg.norm(query_embedding) + 1e-8\n",
    "        )\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        return [(self.chunks[idx], float(similarities[idx])) for idx in top_indices]\n",
    "\n",
    "    def get_stats_summary(self) -> str:\n",
    "        total = self.stats[\"total_queries\"]\n",
    "        if total == 0:\n",
    "            return \"No queries processed yet.\"\n",
    "        avoided = self.stats[\"web_searches_avoided\"]\n",
    "        hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "        return f\"Total: {total} queries, {avoided} avoided ({hit_rate:.1f}% hit rate), {len(self.chunks)} chunks cached\"\n",
    "\n",
    "\n",
    "# Initialize global knowledge base\n",
    "knowledge_base = KnowledgeBase()\n",
    "print(\"Knowledge base initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05d7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cascaded search function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Cascaded Search Function =====\n",
    "\n",
    "def search_web(query: str, max_results: int = 8) -> Tuple[str, List[str], List[str], List[Dict[str, Any]]]:\n",
    "    \"\"\"Execute web search using Tavily. Returns (summary, results, urls, raw_results).\n",
    "\n",
    "    raw_results contains the full Tavily response including relevance scores for validation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(query) > 400:\n",
    "            query = query[:400]\n",
    "        response = tavily_client.search(query=query, max_results=max_results, include_answer=True)\n",
    "        results = []\n",
    "        urls = []\n",
    "        raw_results = []\n",
    "        summary = response.get(\"answer\", \"\")\n",
    "        for r in response.get(\"results\", []):\n",
    "            url = r.get('url', '')\n",
    "            urls.append(url)\n",
    "            content = r.get('content', '')[:500]\n",
    "            title = r.get('title', 'No title')\n",
    "            score = r.get('score', 0.0)  # Tavily relevance score\n",
    "            results.append(f\"[{title}] {content}... (Source: {url})\")\n",
    "            # Store raw result for validation\n",
    "            raw_results.append({\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"content\": content,\n",
    "                \"full_content\": r.get('content', ''),\n",
    "                \"tavily_score\": score,\n",
    "                \"query\": query\n",
    "            })\n",
    "        return summary, results, urls, raw_results\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\", [], [], []\n",
    "\n",
    "\n",
    "def compute_confidence(top_results: List[Tuple[CachedChunk, float]], query: str) -> float:\n",
    "    \"\"\"Compute multi-signal confidence score.\"\"\"\n",
    "    if not top_results:\n",
    "        return 0.0\n",
    "    top_score = top_results[0][1]\n",
    "    score_gap = top_results[0][1] - top_results[1][1] if len(top_results) > 1 else top_score\n",
    "    query_terms = set(query.lower().split())\n",
    "    top_chunk_terms = set(top_results[0][0].text.lower().split())\n",
    "    term_overlap = len(query_terms & top_chunk_terms) / len(query_terms | top_chunk_terms) if query_terms | top_chunk_terms else 0\n",
    "    return 0.5 * top_score + 0.25 * min(score_gap * 2, 1.0) + 0.25 * term_overlap\n",
    "\n",
    "\n",
    "async def cascaded_search(query: str, kb: KnowledgeBase) -> Tuple[str, List[str], CacheDecision, List[Dict[str, Any]]]:\n",
    "    \"\"\"Execute full cascading cache check and search if needed.\n",
    "\n",
    "    Returns: (content, urls, cache_decision, raw_results)\n",
    "    raw_results contains Tavily results with scores for validation (empty if cache hit).\n",
    "    \"\"\"\n",
    "    kb.stats[\"total_queries\"] += 1\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    # Layer 1: Exact match\n",
    "    exact_match = kb.lookup_query_exact(query)\n",
    "    if exact_match:\n",
    "        kb.stats[\"l1_hits\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        return exact_match[\"result_summary\"], exact_match[\"result_urls\"], CacheDecision(\n",
    "            query=query, layer_reached=\"L1\", decision=\"HIT\", confidence_score=1.0,\n",
    "            action_taken=\"USE_CACHE\", reasoning=\"Exact query match\", timestamp=timestamp\n",
    "        ), []  # No raw results for cache hit\n",
    "\n",
    "    # Layer 2: Semantic search\n",
    "    results = kb.semantic_search(query)\n",
    "    if results:\n",
    "        confidence = compute_confidence(results, query)\n",
    "        if confidence >= HIGH_CONFIDENCE_THRESHOLD:\n",
    "            kb.stats[\"l2_high\"] += 1\n",
    "            kb.stats[\"web_searches_avoided\"] += 1\n",
    "            content = \"\\n\\n\".join([f\"[From: {c.source_url}]\\n{c.text}\" for c, _ in results[:3]])\n",
    "            urls = list(set([c.source_url for c, _ in results]))\n",
    "            return content, urls, CacheDecision(\n",
    "                query=query, layer_reached=\"L2\", decision=\"HIGH_CONF\", confidence_score=confidence,\n",
    "                action_taken=\"USE_CACHE\", reasoning=f\"High semantic similarity ({confidence:.2f})\", timestamp=timestamp\n",
    "            ), []  # No raw results for cache hit\n",
    "        elif confidence >= LOW_CONFIDENCE_THRESHOLD:\n",
    "            kb.stats[\"l2_medium\"] += 1\n",
    "            # For medium confidence, still do a search but could use cached context\n",
    "        else:\n",
    "            kb.stats[\"l2_low\"] += 1\n",
    "\n",
    "    # Execute web search\n",
    "    summary, search_results, urls, raw_results = search_web(query)\n",
    "    kb.stats[\"web_searches_executed\"] += 1\n",
    "\n",
    "    # Cache results\n",
    "    query_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\nResults:\\n\" + \"\\n\\n\".join(search_results)\n",
    "    synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "    kb.add_document(synthetic_url, query_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "    kb.add_query(query, urls, summary)\n",
    "\n",
    "    return query_content, urls, CacheDecision(\n",
    "        query=query, layer_reached=\"L2\", decision=\"LOW_CONF\",\n",
    "        confidence_score=compute_confidence(results, query) if results else 0.0,\n",
    "        action_taken=\"SEARCH\", reasoning=\"Executed web search\", timestamp=timestamp\n",
    "    ), raw_results\n",
    "\n",
    "\n",
    "print(\"Cascaded search function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8198469",
   "metadata": {},
   "source": [
    "## 3. State Definition and Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bd042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data models defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Skeleton and Prose Models =====\n",
    "\n",
    "class SkeletonNode(BaseModel):\n",
    "    \"\"\"A node in the document skeleton hierarchy.\"\"\"\n",
    "    node_id: str = Field(description=\"Unique identifier like 'sec:intro'\")\n",
    "    title: str = Field(description=\"Section title\")\n",
    "    intent: str = Field(description=\"1-3 sentence description of purpose\")\n",
    "    target_word_count: int = Field(description=\"Target word count for this section, typically 200-500\")\n",
    "    dependencies: List[str] = Field(description=\"List of node_ids this section depends on - use empty list [] if none\")\n",
    "    children: List[str] = Field(description=\"List of child node_ids - use empty list [] if no children\")\n",
    "    is_expanded: bool = Field(description=\"Whether this section has been expanded - always false initially\")\n",
    "\n",
    "\n",
    "class SkeletonGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for skeleton generation.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence thesis statement\")\n",
    "    sections: List[SkeletonNode] = Field(description=\"All sections in document order\")\n",
    "\n",
    "\n",
    "class ProseGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for prose generation.\"\"\"\n",
    "    bridge_in: str = Field(description=\"Transitional sentences from previous section\")\n",
    "    main_content: str = Field(description=\"Main prose content\")\n",
    "    bridge_out: str = Field(description=\"Transitional sentences to next section\")\n",
    "    summary: str = Field(description=\"1-2 sentence summary\")\n",
    "\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"A verifiable assertion in the document.\"\"\"\n",
    "    claim_id: str\n",
    "    claim_text: str\n",
    "    source_node: str\n",
    "    verification_status: Literal[\"unverified\", \"verified\", \"contested\"] = Field(description=\"Verification status\")\n",
    "    supporting_evidence: List[str] = Field(description=\"List of evidence URLs - use empty list [] if none\")\n",
    "\n",
    "\n",
    "class ClaimExtractionOutput(BaseModel):\n",
    "    \"\"\"Output for claim extraction.\"\"\"\n",
    "    claims: List[Claim]\n",
    "\n",
    "\n",
    "class CritiqueIssue(BaseModel):\n",
    "    \"\"\"An issue identified during critique.\"\"\"\n",
    "    issue_id: str\n",
    "    scope: Literal[\"global\", \"section\", \"transition\"]\n",
    "    target_nodes: List[str]\n",
    "    issue_type: str\n",
    "    severity: Literal[\"critical\", \"major\", \"minor\"]\n",
    "    description: str\n",
    "    suggestion: str\n",
    "    search_query: str = Field(description=\"Search query to find better evidence - empty string if not needed\")\n",
    "\n",
    "\n",
    "class CritiqueResult(BaseModel):\n",
    "    \"\"\"Complete critique output.\"\"\"\n",
    "    overall_quality: float = Field(description=\"Quality score 1-10\")\n",
    "    issues: List[CritiqueIssue] = Field(description=\"List of issues found - use empty list [] if no issues\")\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# ===== NEW: Source Validation Models =====\n",
    "\n",
    "class ValidatedSource(BaseModel):\n",
    "    \"\"\"A validated source with relevance scoring.\"\"\"\n",
    "    url: str\n",
    "    title: str = \"\"\n",
    "    content_snippet: str = \"\"\n",
    "    relevance_score: float = Field(ge=0, le=1, description=\"Relevance score 0-1\")\n",
    "    tavily_score: float = Field(ge=0, le=1, default=0.0, description=\"Tavily's relevance score\")\n",
    "    source_type: Literal[\"primary\", \"secondary\", \"unknown\"] = \"unknown\"\n",
    "    is_accessible: bool = True\n",
    "    rejection_reason: str = \"\"\n",
    "\n",
    "\n",
    "class SourceValidationOutput(BaseModel):\n",
    "    \"\"\"Output for source validation LLM call.\"\"\"\n",
    "    relevance_score: int = Field(ge=1, le=10, description=\"Relevance 1-10\")\n",
    "    source_type: Literal[\"primary\", \"secondary\"] = Field(description=\"Source type: primary or secondary\")\n",
    "    reasoning: str = Field(description=\"Brief explanation of relevance assessment\")\n",
    "\n",
    "\n",
    "# ===== NEW: Audience Analysis Models =====\n",
    "\n",
    "class AudienceProfile(BaseModel):\n",
    "    \"\"\"Profile of the target audience for calibrating output.\"\"\"\n",
    "    primary_audience: Literal[\"decision_makers\", \"analysts\", \"general_readers\", \"researchers\"] = \"analysts\"\n",
    "    audience_needs: List[str] = Field(default_factory=list)\n",
    "    methodology_weight: float = Field(ge=0.1, le=0.3, default=0.15, description=\"How much methodology to include\")\n",
    "    executive_summary_priority: Literal[\"high\", \"medium\", \"low\"] = \"high\"\n",
    "    recommendation_style: Literal[\"prescriptive\", \"analytical\", \"educational\"] = \"analytical\"\n",
    "    jargon_level: Literal[\"low\", \"medium\", \"high\"] = \"medium\"\n",
    "\n",
    "\n",
    "class AudienceAnalysisOutput(BaseModel):\n",
    "    \"\"\"Output schema for audience analysis.\"\"\"\n",
    "    primary_audience: str\n",
    "    audience_needs: List[str]\n",
    "    methodology_weight: float\n",
    "    executive_summary_priority: str\n",
    "    recommendation_style: str\n",
    "    jargon_level: str\n",
    "\n",
    "\n",
    "# ===== NEW: Claims Verification Models =====\n",
    "\n",
    "class ExtractedClaim(BaseModel):\n",
    "    \"\"\"A claim extracted from prose for verification.\"\"\"\n",
    "    claim_text: str = Field(description=\"The exact factual assertion\")\n",
    "    claim_type: Literal[\"statistic\", \"fact\", \"trend\", \"comparison\", \"causation\"] = Field(description=\"Type of claim\")\n",
    "    cited_url: str = Field(description=\"URL cited for this claim, empty string if none\")\n",
    "    source_node: str = Field(description=\"Section this claim came from\")\n",
    "    verification_needed: bool = Field(description=\"Whether this claim requires source verification\")\n",
    "\n",
    "\n",
    "class ClaimVerificationResult(BaseModel):\n",
    "    \"\"\"Result of verifying a claim against its source.\"\"\"\n",
    "    supported: Literal[\"true\", \"false\", \"partial\"] = Field(description=\"Whether claim is supported: true, false, or partial\")\n",
    "    source_quote: str = Field(description=\"Relevant quote from source if found, empty string if none\")\n",
    "    issue: str = Field(description=\"Description if not fully supported, empty string if fully supported\")\n",
    "\n",
    "\n",
    "class ClaimsExtractionOutput(BaseModel):\n",
    "    \"\"\"Output for extracting claims from a section.\"\"\"\n",
    "    claims: List[ExtractedClaim]\n",
    "\n",
    "\n",
    "# ===== NEW: Executive Summary Models =====\n",
    "\n",
    "class KeyTakeaway(BaseModel):\n",
    "    \"\"\"A key takeaway for the executive summary.\"\"\"\n",
    "    takeaway: str\n",
    "    confidence: Literal[\"High\", \"Medium\", \"Low\"] = Field(description=\"Confidence level: High, Medium, or Low\")\n",
    "\n",
    "\n",
    "class ExecutiveSummaryOutput(BaseModel):\n",
    "    \"\"\"Output for executive summary generation.\"\"\"\n",
    "    main_finding: str = Field(description=\"One sentence core conclusion\")\n",
    "    key_takeaways: List[KeyTakeaway] = Field(description=\"3-5 key takeaways with confidence\")\n",
    "    bottom_line: str = Field(description=\"One sentence actionable implication\")\n",
    "\n",
    "\n",
    "# ===== NEW: Decision Framework Models =====\n",
    "\n",
    "class Recommendation(BaseModel):\n",
    "    \"\"\"A recommendation in the decision framework.\"\"\"\n",
    "    action: str = Field(description=\"Specific action to take\")\n",
    "    rationale: str = Field(description=\"Why this action\")\n",
    "    conditions: str = Field(description=\"When this applies - use 'Always applicable' if no specific conditions\")\n",
    "    priority: Literal[\"High\", \"Medium\", \"Low\"] = Field(description=\"Priority level: High, Medium, or Low\")\n",
    "\n",
    "\n",
    "class DecisionFrameworkOutput(BaseModel):\n",
    "    \"\"\"Output for decision framework generation.\"\"\"\n",
    "    primary_recommendations: List[Recommendation] = Field(description=\"1-3 most important actions\")\n",
    "    conditional_recommendations: List[Recommendation] = Field(description=\"If X then Y recommendations - use empty list [] if none\")\n",
    "    monitoring_indicators: List[str] = Field(description=\"What to watch going forward - use empty list [] if none\")\n",
    "\n",
    "\n",
    "# ===== NEW: Confidence Assessment Models =====\n",
    "\n",
    "class ConfidenceAssessment(BaseModel):\n",
    "    \"\"\"Confidence assessment for a conclusion.\"\"\"\n",
    "    conclusion: str\n",
    "    confidence: Literal[\"High\", \"Medium\", \"Low\"] = Field(description=\"Confidence level: High, Medium, or Low\")\n",
    "    evidence_quality: Literal[\"strong\", \"moderate\", \"weak\"] = Field(description=\"Evidence quality: strong, moderate, or weak\")\n",
    "    source_count: int = Field(description=\"Number of sources supporting this conclusion\")\n",
    "    key_uncertainty: str = Field(description=\"Main uncertainty or limitation\")\n",
    "    what_would_change_this: str = Field(description=\"What evidence would change this conclusion\")\n",
    "\n",
    "\n",
    "class ConfidenceAssessmentOutput(BaseModel):\n",
    "    \"\"\"Output for confidence level assessment.\"\"\"\n",
    "    assessments: List[ConfidenceAssessment]\n",
    "    overall_confidence: Literal[\"High\", \"Medium\", \"Low\"] = Field(description=\"Overall confidence: High, Medium, or Low\")\n",
    "    limitations_summary: str = Field(description=\"Summary of key limitations and uncertainties\")\n",
    "\n",
    "\n",
    "# ===== NEW: Updated Prose Generation Output =====\n",
    "\n",
    "class ClaimEntry(BaseModel):\n",
    "    \"\"\"A claim made in prose content.\"\"\"\n",
    "    claim: str = Field(description=\"The factual claim being made\")\n",
    "    source_url: str = Field(description=\"URL of the source supporting this claim, or empty string if no specific source\")\n",
    "\n",
    "\n",
    "class ProseGenerationOutputV2(BaseModel):\n",
    "    \"\"\"Updated output schema for prose generation - no bridge sentences.\"\"\"\n",
    "    main_content: str = Field(description=\"Main prose content\")\n",
    "    section_conclusion: str = Field(description=\"1-2 sentence summary of what this section established\")\n",
    "    claims_made: List[ClaimEntry] = Field(description=\"List of claims made in this section - use empty list [] if no specific claims\")\n",
    "\n",
    "\n",
    "print(\"Data models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined state defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Combined Tier 1 State =====\n",
    "\n",
    "class CombinedTier1State(TypedDict):\n",
    "    \"\"\"State for the Combined Tier 1 Deep Research Agent.\"\"\"\n",
    "    # Input\n",
    "    question: str\n",
    "\n",
    "    # ===== PHASE 1: Research Sprints =====\n",
    "    research_backlog: List[str]  # REPLACED each sprint\n",
    "    current_research_sprint: int\n",
    "    max_research_sprints: int\n",
    "    sprint_findings: Annotated[List[str], operator.add]  # ACCUMULATED\n",
    "    research_source_urls: Annotated[List[str], operator.add]\n",
    "    research_retrospective_notes: Annotated[List[str], operator.add]\n",
    "    research_summary: str\n",
    "    research_complete: bool\n",
    "\n",
    "    # ===== NEW: Source Validation =====\n",
    "    validated_sources: Dict[str, Dict[str, Any]]  # url -> ValidatedSource dict\n",
    "    rejected_sources: Annotated[List[Dict[str, Any]], operator.add]  # {url, reason, query}\n",
    "    raw_search_results: Annotated[List[Dict[str, Any]], operator.add]  # Store raw Tavily results for validation\n",
    "\n",
    "    # ===== NEW: Audience Analysis =====\n",
    "    audience_profile: Dict[str, Any]  # AudienceProfile dict\n",
    "\n",
    "    # ===== PHASE 2: Skeleton =====\n",
    "    skeleton: Dict[str, Any]\n",
    "    skeleton_validated: bool\n",
    "\n",
    "    # ===== PHASE 3: Node Expansion =====\n",
    "    prose_store: Dict[str, Dict[str, Any]]\n",
    "    claims_registry: Dict[str, Dict[str, Any]]\n",
    "    nodes_expanded: List[str]\n",
    "\n",
    "    # ===== NEW: Claims Verification =====\n",
    "    extracted_claims: Annotated[List[Dict[str, Any]], operator.add]  # All claims from prose\n",
    "    verified_claims: Dict[str, Dict[str, Any]]  # claim_id -> verification result\n",
    "    claims_needing_revision: List[str]  # claim_ids that failed verification\n",
    "\n",
    "    # ===== PHASE 4: Verification =====\n",
    "    noise_map: List[Dict[str, Any]]\n",
    "    nodes_to_patch: List[str]\n",
    "    cascade_queue: List[str]\n",
    "    targeted_evidence: Dict[str, List[str]]\n",
    "    current_refinement_iteration: int\n",
    "    max_refinement_iterations: int\n",
    "    quality_scores: Annotated[List[float], operator.add]\n",
    "    verification_log: Annotated[List[str], operator.add]\n",
    "\n",
    "    # ===== NEW: Output Components =====\n",
    "    executive_summary: str\n",
    "    decision_framework: str\n",
    "    confidence_assessments: List[Dict[str, Any]]\n",
    "    limitations_summary: str\n",
    "\n",
    "    # ===== PHASE 5: Output =====\n",
    "    final_report: str\n",
    "\n",
    "    # ===== NEW: Quality Tracking =====\n",
    "    information_density_score: float  # Novel info per 100 words\n",
    "    self_reference_count: int  # Should be 0\n",
    "    methodology_ratio: float  # Should be < 0.2\n",
    "\n",
    "    # ===== METRICS =====\n",
    "    total_searches: int\n",
    "    cache_hits: int\n",
    "    cache_decisions: Annotated[List[Dict], operator.add]\n",
    "\n",
    "\n",
    "print(\"Combined state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3237bc",
   "metadata": {},
   "source": [
    "## 4. Phase 1: Agile Research Sprints\n",
    "\n",
    "This phase decomposes the question, executes sprints with retrospectives, and produces a compressed research brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b8f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 prompts defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Prompts =====\n",
    "\n",
    "DECOMPOSE_PROMPT = \"\"\"You are a research planning expert. Decompose this research question into 5-7 specific sub-questions.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Generate a prioritized list of specific, focused research questions that together will comprehensively answer the main question. Each should be independently searchable.\n",
    "\n",
    "Return as a numbered list (highest priority first):\n",
    "1. [Most critical sub-question]\n",
    "2. [Second priority]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "SPRINT_SYNTHESIS_PROMPT = \"\"\"You are a research agent conducting Sprint {sprint_num} of {max_sprints}.\n",
    "\n",
    "Current research focus: {current_questions}\n",
    "\n",
    "Based on the search results below, extract key findings addressing these questions.\n",
    "Be specific and cite sources with URLs.\n",
    "\n",
    "Search Results:\n",
    "{search_results}\n",
    "\n",
    "Provide a comprehensive summary of findings (400-600 words) with specific facts and source URLs.\n",
    "\"\"\"\n",
    "\n",
    "RETROSPECTIVE_PROMPT = \"\"\"You are conducting a sprint retrospective for a research project.\n",
    "\n",
    "Original Question: {original_question}\n",
    "\n",
    "Sprint {sprint_num} of {max_sprints} has completed.\n",
    "\n",
    "Summary of findings so far:\n",
    "{findings_summary}\n",
    "\n",
    "Current remaining questions:\n",
    "{remaining_backlog}\n",
    "\n",
    "Provide a STRUCTURED response:\n",
    "\n",
    "## LEARNINGS\n",
    "Key insights from this sprint.\n",
    "\n",
    "## GAPS\n",
    "What is still unclear or needs investigation?\n",
    "\n",
    "## CONTINUE\n",
    "Should we continue with another sprint? Answer YES or NO.\n",
    "\n",
    "## NEW_QUESTIONS\n",
    "List 2-4 NEW questions that emerged (or \"None\"):\n",
    "- [New question 1]\n",
    "- [New question 2]\n",
    "\n",
    "## REPRIORITIZED_BACKLOG\n",
    "Reorder remaining questions by priority:\n",
    "1. [Highest priority]\n",
    "2. [Next priority]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "COMPRESS_FINDINGS_PROMPT = \"\"\"Summarize these research findings into a concise research brief.\n",
    "\n",
    "All Findings:\n",
    "{all_findings}\n",
    "\n",
    "Create a bullet-point summary (max 600 words) capturing:\n",
    "- Key facts and statistics\n",
    "- Main themes and patterns\n",
    "- Important sources\n",
    "- Any contradictions identified\n",
    "\n",
    "Be concise but preserve critical information.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Phase 1 prompts defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f1118",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 node functions defined (part 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Node Functions =====\n",
    "\n",
    "async def decompose_question(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Decompose the research question into a backlog of sub-questions.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in decompose_question\")\n",
    "    \n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1a: Question Decomposition\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    prompt = DECOMPOSE_PROMPT.format(question=question)\n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    lines = response.content.strip().split(\"\\n\")\n",
    "    backlog = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "            clean = line.lstrip(\"0123456789.-) \").strip()\n",
    "            if clean:\n",
    "                backlog.append(clean)\n",
    "    \n",
    "    print(f\"  Created backlog with {len(backlog)} research questions\")\n",
    "    for i, q in enumerate(backlog[:5], 1):\n",
    "        print(f\"    {i}. {q[:60]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"research_backlog\": backlog,\n",
    "        \"current_research_sprint\": 1,\n",
    "        \"max_research_sprints\": MAX_RESEARCH_SPRINTS,\n",
    "        \"research_complete\": False\n",
    "    }\n",
    "\n",
    "\n",
    "async def execute_research_sprint(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Execute a research sprint on top backlog items.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in execute_research_sprint\")\n",
    "\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 1b: Research Sprint {current_sprint}/{max_sprints}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not backlog:\n",
    "        return {\"sprint_findings\": [\"No questions in backlog.\"]}\n",
    "\n",
    "    # Take top questions for this sprint\n",
    "    current_questions = backlog[:QUERIES_PER_SPRINT]\n",
    "\n",
    "    all_content = []\n",
    "    all_urls = []\n",
    "    all_decisions = []\n",
    "    all_raw_results = []  # NEW: Collect raw results for validation\n",
    "\n",
    "    for i, question in enumerate(current_questions, 1):\n",
    "        print(f\"  [{i}/{len(current_questions)}] {question[:50]}...\")\n",
    "        content, urls, decision, raw_results = await cascaded_search(question, knowledge_base)\n",
    "        all_content.append(f\"### {question}\\n{content}\")\n",
    "        all_urls.extend(urls)\n",
    "        all_decisions.append(decision.model_dump())\n",
    "        all_raw_results.extend(raw_results)  # Collect for validation\n",
    "\n",
    "        action = \"CACHE\" if decision.action_taken == \"USE_CACHE\" else \"SEARCH\"\n",
    "        print(f\"      {action} | Layer: {decision.layer_reached}\")\n",
    "\n",
    "    # Synthesize findings\n",
    "    combined_results = \"\\n\\n---\\n\\n\".join(all_content)\n",
    "    if len(combined_results) > 12000:\n",
    "        combined_results = combined_results[:12000] + \"\\n...[truncated]\"\n",
    "\n",
    "    synthesis_prompt = SPRINT_SYNTHESIS_PROMPT.format(\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        current_questions=\"\\n\".join(f\"- {q}\" for q in current_questions),\n",
    "        search_results=combined_results\n",
    "    )\n",
    "\n",
    "    synthesis = await llm.ainvoke([HumanMessage(content=synthesis_prompt)])\n",
    "    finding = f\"## Sprint {current_sprint} Findings\\n\\n{synthesis.content}\"\n",
    "\n",
    "    # Update backlog (remove processed questions)\n",
    "    updated_backlog = backlog[QUERIES_PER_SPRINT:]\n",
    "\n",
    "    print(f\"  Synthesized {len(synthesis.content)} chars, {len(all_urls)} sources\")\n",
    "    print(f\"  Collected {len(all_raw_results)} raw results for validation\")\n",
    "\n",
    "    return {\n",
    "        \"sprint_findings\": [finding],\n",
    "        \"research_source_urls\": all_urls,\n",
    "        \"cache_decisions\": all_decisions,\n",
    "        \"research_backlog\": updated_backlog,\n",
    "        \"raw_search_results\": all_raw_results  # NEW: Pass to validate_sources\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 1 node functions defined (part 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ef729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source validation node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Source Validation Node =====\n",
    "\n",
    "SOURCE_VALIDATION_PROMPT = \"\"\"You are evaluating the relevance of a source to a research query.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Source Title: {title}\n",
    "Source URL: {url}\n",
    "Source Content Snippet:\n",
    "{content_snippet}\n",
    "\n",
    "Rate the relevance of this source on a scale of 1-10:\n",
    "- 10: Directly answers the query with authoritative, primary information\n",
    "- 7-9: Highly relevant, provides substantial supporting information\n",
    "- 4-6: Somewhat relevant, tangentially related\n",
    "- 1-3: Not relevant, completely different topic\n",
    "\n",
    "Also classify the source type:\n",
    "- \"primary\": Official documents, company filings, government data, academic papers, official announcements\n",
    "- \"secondary\": News articles, blog posts, analysis pieces, commentary, aggregator sites\n",
    "\n",
    "IMPORTANT: Be strict. Sources that are:\n",
    "- Retail/e-commerce sites (amazon, ebay, etc.) = score 1-2\n",
    "- Generic dictionary definitions = score 1-2\n",
    "- Unrelated conference/event pages = score 1-2\n",
    "- Random corporate homepages without relevant content = score 1-3\n",
    "\n",
    "Output your assessment.\"\"\"\n",
    "\n",
    "# Minimum Tavily score threshold for initial filtering\n",
    "MIN_TAVILY_SCORE = 0.3\n",
    "# Minimum LLM relevance score (1-10) to keep source\n",
    "MIN_RELEVANCE_SCORE = 5\n",
    "# Skip LLM check if Tavily score is very high\n",
    "HIGH_TAVILY_SCORE_THRESHOLD = 0.85\n",
    "\n",
    "\n",
    "async def validate_sources(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Validate and filter sources based on relevance.\n",
    "\n",
    "    This node filters out irrelevant URLs before they pollute the knowledge base.\n",
    "    Uses Tavily's score and optionally LLM judgment for borderline cases.\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in validate_sources\")\n",
    "\n",
    "    raw_results = state.get(\"raw_search_results\", [])\n",
    "    existing_validated = state.get(\"validated_sources\", {})\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1b.1: Source Validation\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not raw_results:\n",
    "        print(\"  No new sources to validate\")\n",
    "        return {\"validated_sources\": existing_validated, \"rejected_sources\": []}\n",
    "\n",
    "    validated_sources = dict(existing_validated)  # Copy existing\n",
    "    rejected_sources = []\n",
    "\n",
    "    # Deduplicate by URL\n",
    "    seen_urls = set(validated_sources.keys())\n",
    "    unique_results = []\n",
    "    for r in raw_results:\n",
    "        url = r.get(\"url\", \"\")\n",
    "        if url and url not in seen_urls:\n",
    "            seen_urls.add(url)\n",
    "            unique_results.append(r)\n",
    "\n",
    "    print(f\"  Processing {len(unique_results)} unique new sources\")\n",
    "\n",
    "    for i, result in enumerate(unique_results):\n",
    "        url = result.get(\"url\", \"\")\n",
    "        title = result.get(\"title\", \"\")\n",
    "        content = result.get(\"content\", \"\")\n",
    "        tavily_score = result.get(\"tavily_score\", 0.0)\n",
    "        query = result.get(\"query\", \"\")\n",
    "\n",
    "        # Quick rejection based on Tavily score\n",
    "        if tavily_score < MIN_TAVILY_SCORE:\n",
    "            rejected_sources.append({\n",
    "                \"url\": url,\n",
    "                \"reason\": f\"Tavily score too low ({tavily_score:.2f} < {MIN_TAVILY_SCORE})\",\n",
    "                \"query\": query\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Quick acceptance for very high Tavily scores\n",
    "        if tavily_score >= HIGH_TAVILY_SCORE_THRESHOLD:\n",
    "            validated_sources[url] = {\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"content_snippet\": content[:300],\n",
    "                \"relevance_score\": tavily_score,\n",
    "                \"tavily_score\": tavily_score,\n",
    "                \"source_type\": \"unknown\",  # Would need LLM to classify\n",
    "                \"is_accessible\": True,\n",
    "                \"rejection_reason\": \"\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # For medium scores, use LLM to validate\n",
    "        try:\n",
    "            validation_prompt = SOURCE_VALIDATION_PROMPT.format(\n",
    "                query=query,\n",
    "                title=title,\n",
    "                url=url,\n",
    "                content_snippet=content[:500]\n",
    "            )\n",
    "\n",
    "            structured_llm = llm.with_structured_output(SourceValidationOutput, method=\"function_calling\")\n",
    "            result_validation = await structured_llm.ainvoke([HumanMessage(content=validation_prompt)])\n",
    "\n",
    "            llm_score = result_validation.relevance_score / 10.0  # Normalize to 0-1\n",
    "            combined_score = (tavily_score + llm_score) / 2\n",
    "\n",
    "            if result_validation.relevance_score >= MIN_RELEVANCE_SCORE:\n",
    "                validated_sources[url] = {\n",
    "                    \"url\": url,\n",
    "                    \"title\": title,\n",
    "                    \"content_snippet\": content[:300],\n",
    "                    \"relevance_score\": combined_score,\n",
    "                    \"tavily_score\": tavily_score,\n",
    "                    \"source_type\": result_validation.source_type,\n",
    "                    \"is_accessible\": True,\n",
    "                    \"rejection_reason\": \"\"\n",
    "                }\n",
    "            else:\n",
    "                rejected_sources.append({\n",
    "                    \"url\": url,\n",
    "                    \"reason\": f\"LLM relevance score too low ({result_validation.relevance_score}/10): {result_validation.reasoning}\",\n",
    "                    \"query\": query\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            # If LLM validation fails, use Tavily score alone\n",
    "            if tavily_score >= 0.5:\n",
    "                validated_sources[url] = {\n",
    "                    \"url\": url,\n",
    "                    \"title\": title,\n",
    "                    \"content_snippet\": content[:300],\n",
    "                    \"relevance_score\": tavily_score,\n",
    "                    \"tavily_score\": tavily_score,\n",
    "                    \"source_type\": \"unknown\",\n",
    "                    \"is_accessible\": True,\n",
    "                    \"rejection_reason\": \"\"\n",
    "                }\n",
    "            else:\n",
    "                rejected_sources.append({\n",
    "                    \"url\": url,\n",
    "                    \"reason\": f\"Validation failed and Tavily score borderline: {str(e)}\",\n",
    "                    \"query\": query\n",
    "                })\n",
    "\n",
    "    print(f\"  Validated: {len(validated_sources)} sources\")\n",
    "    print(f\"  Rejected: {len(rejected_sources)} sources\")\n",
    "\n",
    "    # Show some rejections for debugging\n",
    "    if rejected_sources:\n",
    "        print(f\"  Sample rejections:\")\n",
    "        for r in rejected_sources[:3]:\n",
    "            print(f\"    - {r['url'][:50]}... : {r['reason'][:60]}\")\n",
    "\n",
    "    return {\n",
    "        \"validated_sources\": validated_sources,\n",
    "        \"rejected_sources\": rejected_sources\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Source validation node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73057011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 node functions defined (part 2)\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Node Functions (continued) =====\n",
    "\n",
    "def parse_reprioritized_backlog(response_content: str) -> List[str]:\n",
    "    \"\"\"Parse reprioritized backlog from retrospective.\"\"\"\n",
    "    backlog_match = re.search(r'## REPRIORITIZED_BACKLOG\\s*(.*?)(?=##|$)', response_content, re.DOTALL | re.IGNORECASE)\n",
    "    if backlog_match:\n",
    "        backlog_text = backlog_match.group(1)\n",
    "        questions = []\n",
    "        for line in backlog_text.strip().split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "                clean = re.sub(r'^[\\d\\.\\-\\)\\s]+', '', line).strip()\n",
    "                if clean and len(clean) > 10:\n",
    "                    questions.append(clean)\n",
    "        return questions\n",
    "    return []\n",
    "\n",
    "\n",
    "def parse_should_continue_research(response_content: str) -> bool:\n",
    "    \"\"\"Parse whether to continue from retrospective.\"\"\"\n",
    "    continue_match = re.search(r'## CONTINUE\\s*(.*?)(?=##|$)', response_content, re.DOTALL | re.IGNORECASE)\n",
    "    if continue_match:\n",
    "        text = continue_match.group(1).strip().lower()\n",
    "        negative_patterns = [r'^no\\b', r'should\\s+stop', r'sufficient', r'adequately']\n",
    "        for pattern in negative_patterns:\n",
    "            if re.search(pattern, text):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "async def research_retrospective(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Conduct retrospective after research sprint.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in research_retrospective\")\n",
    "    \n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "        \n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 1c: Sprint {current_sprint} Retrospective\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Summarize findings for token efficiency\n",
    "    if len(all_findings) > 4000:\n",
    "        compress_prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:8000])\n",
    "        compress_response = await llm.ainvoke([HumanMessage(content=compress_prompt)])\n",
    "        findings_summary = compress_response.content\n",
    "    else:\n",
    "        findings_summary = all_findings\n",
    "    \n",
    "    prompt = RETROSPECTIVE_PROMPT.format(\n",
    "        original_question=question,\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        findings_summary=findings_summary,\n",
    "        remaining_backlog=\"\\n\".join(f\"- {q}\" for q in backlog) if backlog else \"None\"\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    reprioritized = parse_reprioritized_backlog(response.content)\n",
    "    should_continue = parse_should_continue_research(response.content)\n",
    "    \n",
    "    if not reprioritized and backlog:\n",
    "        reprioritized = backlog\n",
    "    \n",
    "    print(f\"  Should continue: {should_continue}\")\n",
    "    print(f\"  Backlog size: {len(reprioritized)}\")\n",
    "    \n",
    "    return {\n",
    "        \"research_retrospective_notes\": [f\"### Sprint {current_sprint} Retrospective\\n{response.content}\"],\n",
    "        \"current_research_sprint\": current_sprint + 1,\n",
    "        \"research_backlog\": reprioritized,\n",
    "        \"research_summary\": findings_summary,\n",
    "        \"research_complete\": not should_continue\n",
    "    }\n",
    "\n",
    "\n",
    "async def quality_gate_1(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Check source sufficiency before moving to synthesis.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in quality_gate_1\")\n",
    "        \n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    unique_urls = list(set(source_urls))\n",
    "    \n",
    "    # Count unique domains\n",
    "    domains = set()\n",
    "    for url in unique_urls:\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            domains.add(parsed.netloc)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Quality Gate 1: Source Sufficiency\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Unique sources: {len(unique_urls)} (min: {MIN_SOURCES_FOR_GATE1})\")\n",
    "    print(f\"  Unique domains: {len(domains)} (min: {MIN_DOMAINS_FOR_GATE1})\")\n",
    "    \n",
    "    passed = len(unique_urls) >= MIN_SOURCES_FOR_GATE1 and len(domains) >= MIN_DOMAINS_FOR_GATE1\n",
    "    print(f\"  Gate 1 {'PASSED' if passed else 'PASSED (relaxed)'}\")  # Always pass but note\n",
    "    \n",
    "    return {\"research_complete\": True}\n",
    "\n",
    "\n",
    "async def compress_findings(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Compress all findings into a research brief for skeleton generation.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in compress_findings\")\n",
    "        \n",
    "    all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1d: Compressing Research Brief\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(all_findings) > MAX_FINDINGS_CHARS:\n",
    "        prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:MAX_FINDINGS_CHARS])\n",
    "        response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        summary = response.content\n",
    "    else:\n",
    "        summary = all_findings\n",
    "    \n",
    "    print(f\"  Compressed to {len(summary)} chars\")\n",
    "    \n",
    "    return {\"research_summary\": summary}\n",
    "\n",
    "\n",
    "def should_continue_research(state: CombinedTier1State) -> Literal[\"execute_sprint\", \"quality_gate_1\"]:\n",
    "    \"\"\"Decide whether to continue research or move to quality gate.\"\"\"\n",
    "    if state is None:\n",
    "        return \"quality_gate_1\"\n",
    "        \n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    research_complete = state.get(\"research_complete\", False)\n",
    "    \n",
    "    if current_sprint > max_sprints:\n",
    "        print(f\"  Max sprints reached. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    if not backlog:\n",
    "        print(f\"  Backlog empty. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    if research_complete:\n",
    "        print(f\"  Research marked complete. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    \n",
    "    print(f\"  Continuing to sprint {current_sprint}.\")\n",
    "    return \"execute_sprint\"\n",
    "\n",
    "\n",
    "print(\"Phase 1 node functions defined (part 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be95f45",
   "metadata": {},
   "source": [
    "## 5. Phase 2: Skeleton Generation\n",
    "\n",
    "Creates a hierarchical document structure before writing prose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a69b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 2: Skeleton Generation =====\n",
    "\n",
    "SKELETON_PROMPT = \"\"\"You are a research document architect. Create a document skeleton optimized for {primary_audience}.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Research Findings Summary:\n",
    "{research_summary}\n",
    "\n",
    "Audience Profile:\n",
    "- Primary Audience: {primary_audience}\n",
    "- Methodology Weight: {methodology_weight} (0.1 = minimal, 0.3 = detailed)\n",
    "- Recommendation Style: {recommendation_style}\n",
    "\n",
    "Create a document structure that prioritizes FINDINGS over METHODOLOGY.\n",
    "\n",
    "Each section needs:\n",
    "- node_id: Unique identifier like \"sec:exec_summary\", \"sec:background\"\n",
    "- title: Descriptive section title\n",
    "- intent: 1-3 sentences describing what this section DELIVERS (not what it will do)\n",
    "- target_word_count: Varies by section (see below)\n",
    "- dependencies: List of node_ids this section builds upon (empty for first section)\n",
    "- children: Empty list (flat structure)\n",
    "\n",
    "REQUIRED STRUCTURE (in this order):\n",
    "\n",
    "1. sec:exec_summary - Executive Summary (~300 words)\n",
    "   - intent: Synthesize key findings for quick consumption. NO methodology here.\n",
    "   - This section must deliver conclusions and implications upfront.\n",
    "\n",
    "2. sec:background - Background/Context (~200 words)\n",
    "   - intent: Establish ONLY essential context needed to understand findings.\n",
    "   - Keep brief - this is NOT where methodology goes.\n",
    "\n",
    "3-5. Main Analysis Sections (3 sections, ~400 words each)\n",
    "   - intent: Present specific findings with evidence and citations.\n",
    "   - Each section should cover a distinct aspect of the research question.\n",
    "   - Name these based on the actual content (e.g., \"sec:market_trends\", \"sec:technology_impact\")\n",
    "\n",
    "6. sec:synthesis - Synthesis/Discussion (~300 words)\n",
    "   - intent: Integrate findings across sections, address counterarguments.\n",
    "   - Discuss implications and connections between findings.\n",
    "\n",
    "7. sec:recommendations - Recommendations/Implications (~300 words)\n",
    "   - intent: Provide actionable guidance based on findings.\n",
    "   - Include prioritized recommendations for the target audience.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Do NOT create sections that describe what the report will do (\"This section will...\")\n",
    "- Do NOT include \"testable hypotheses\" or \"parameter ranges\"\n",
    "- Do NOT promise appendices, artifacts, or external materials\n",
    "- Do NOT front-load methodology - if needed, it goes in a brief note at the end\n",
    "- Each section should DELIVER content, not ANNOUNCE what it will cover\n",
    "- The thesis statement should be a direct answer/position, not a process description\n",
    "\n",
    "BANNED SECTION TYPES:\n",
    "- \"Methodology Overview\"\n",
    "- \"Research Approach\"\n",
    "- \"Analytical Framework\"\n",
    "- \"Hypothesis Testing\"\n",
    "\n",
    "Generate a thesis statement (one sentence that states a conclusion) and the sections list.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def validate_skeleton(skeleton: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"Validate skeleton structure.\"\"\"\n",
    "    issues = []\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    \n",
    "    for root_id in root_nodes:\n",
    "        if root_id not in nodes:\n",
    "            issues.append(f\"Root node '{root_id}' not found\")\n",
    "    \n",
    "    for node_id, node in nodes.items():\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id not in nodes:\n",
    "                issues.append(f\"Node '{node_id}' depends on non-existent '{dep_id}'\")\n",
    "    \n",
    "    return len(issues) == 0, issues\n",
    "\n",
    "\n",
    "async def generate_skeleton(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Generate the document skeleton structure.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in generate_skeleton\")\n",
    "    \n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "    \n",
    "    research_summary = state.get(\"research_summary\", \"\")\n",
    "\n",
    "    # Get audience profile (with defaults if not set)\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    primary_audience = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "    methodology_weight = audience_profile.get(\"methodology_weight\", 0.15)\n",
    "    recommendation_style = audience_profile.get(\"recommendation_style\", \"analytical\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 2: Skeleton Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Audience: {primary_audience}, Methodology weight: {methodology_weight}\")\n",
    "\n",
    "    prompt = SKELETON_PROMPT.format(\n",
    "        question=question,\n",
    "        research_summary=research_summary[:6000],\n",
    "        primary_audience=primary_audience,\n",
    "        methodology_weight=methodology_weight,\n",
    "        recommendation_style=recommendation_style\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SkeletonGenerationOutput, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Build skeleton dictionary\n",
    "    skeleton = {\n",
    "        \"thesis\": result.thesis,\n",
    "        \"root_nodes\": [],\n",
    "        \"nodes\": {}\n",
    "    }\n",
    "    \n",
    "    child_ids = set()\n",
    "    for section in result.sections:\n",
    "        child_ids.update(section.children)\n",
    "    \n",
    "    for section in result.sections:\n",
    "        skeleton[\"nodes\"][section.node_id] = section.model_dump()\n",
    "        if section.node_id not in child_ids:\n",
    "            skeleton[\"root_nodes\"].append(section.node_id)\n",
    "    \n",
    "    if not skeleton[\"root_nodes\"]:\n",
    "        skeleton[\"root_nodes\"] = list(skeleton[\"nodes\"].keys())\n",
    "    \n",
    "    is_valid, issues = validate_skeleton(skeleton)\n",
    "    \n",
    "    print(f\"  Thesis: {result.thesis[:80]}...\")\n",
    "    print(f\"  Sections: {len(skeleton['nodes'])}\")\n",
    "    print(f\"  Valid: {is_valid}\")\n",
    "    if issues:\n",
    "        for issue in issues[:3]:\n",
    "            print(f\"    Warning: {issue}\")\n",
    "    \n",
    "    return {\n",
    "        \"skeleton\": skeleton,\n",
    "        \"skeleton_validated\": is_valid,\n",
    "        \"prose_store\": {},\n",
    "        \"claims_registry\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 2 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de33a5b",
   "metadata": {},
   "source": [
    "## 6. Phase 3: Node Expansion\n",
    "\n",
    "Generates prose for each skeleton node with dependency awareness and bridge sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f421dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 3: Node Expansion =====\n",
    "\n",
    "PROSE_PROMPT = \"\"\"You are a research writer generating content for a specific section.\n",
    "\n",
    "DOCUMENT CONTEXT:\n",
    "Research Question: {question}\n",
    "Document Thesis: {thesis}\n",
    "Target Audience: {audience_type}\n",
    "\n",
    "SECTION TO WRITE:\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "Target Length: ~{target_words} words\n",
    "\n",
    "CONTEXT FROM ADJACENT SECTIONS:\n",
    "Previous section established: {previous_summary}\n",
    "Next section will cover: {next_intent}\n",
    "\n",
    "DEPENDENCY SUMMARIES:\n",
    "{dependency_summaries}\n",
    "\n",
    "RESEARCH FINDINGS:\n",
    "{research_findings}\n",
    "\n",
    "WRITING RULES - CRITICAL:\n",
    "1. NEVER say \"this section will...\", \"we will show...\", \"the report presents...\" - just write the content directly\n",
    "2. NEVER reference the document structure (\"as discussed in section X\", \"in the previous section\")\n",
    "3. NEVER use formulaic transitions like \"Building on the previous...\", \"As established above...\"\n",
    "4. NEVER create dense paragraphs over 100 words - break them up\n",
    "5. DEFINE technical terms on first use\n",
    "6. Every paragraph must contain NEW information, not restatement of prior content\n",
    "7. End with a concrete conclusion about what was established, not a transition phrase\n",
    "\n",
    "BANNED PHRASES (never use these):\n",
    "- \"This section will...\"\n",
    "- \"We will show...\"\n",
    "- \"The report presents...\"\n",
    "- \"As will be demonstrated...\"\n",
    "- \"In the following paragraphs...\"\n",
    "- \"Building on the previous section...\"\n",
    "- \"As discussed earlier...\"\n",
    "- \"To summarize what we have covered...\"\n",
    "- \"This section explores...\"\n",
    "- \"We now turn to...\"\n",
    "\n",
    "CITATION RULES:\n",
    "1. Cite specific sources with URLs for factual claims: (Source: URL)\n",
    "2. Do NOT cite sources you haven't verified support your specific claim\n",
    "3. Prefer primary sources (official documents, company filings) over secondary (news, blogs)\n",
    "4. When citing statistics, include the date of the data if available\n",
    "5. If making an analytical point without a source, state it as analysis, not fact\n",
    "\n",
    "DENSITY CHECK - Before outputting, verify each paragraph:\n",
    "1. Contains at least one NEW fact, insight, or finding\n",
    "2. Is under 100 words\n",
    "3. Does not repeat information from other paragraphs\n",
    "4. Does not explain obvious concepts the audience already knows\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Generate main_content (~{target_words} words of substantive prose), section_conclusion (1-2 sentences summarizing what this section established), and claims_made (list of factual claims with their source URLs).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_leaf_nodes(skeleton: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Get all leaf node IDs in document order.\"\"\"\n",
    "    if not skeleton:\n",
    "        return []\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    \n",
    "    def collect_leaves(node_ids: List[str]) -> List[str]:\n",
    "        leaves = []\n",
    "        for nid in node_ids:\n",
    "            node = nodes.get(nid, {})\n",
    "            children = node.get(\"children\", [])\n",
    "            if not children:\n",
    "                leaves.append(nid)\n",
    "            else:\n",
    "                leaves.extend(collect_leaves(children))\n",
    "        return leaves\n",
    "    \n",
    "    return collect_leaves(root_nodes)\n",
    "\n",
    "\n",
    "def topological_sort_nodes(skeleton: Dict[str, Any], node_ids: List[str]) -> List[str]:\n",
    "    \"\"\"Sort nodes by dependency order.\"\"\"\n",
    "    if not skeleton:\n",
    "        return node_ids\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    node_id_set = set(node_ids)\n",
    "    remaining = set(node_ids)\n",
    "    sorted_nodes = []\n",
    "    \n",
    "    while remaining:\n",
    "        ready = []\n",
    "        for nid in remaining:\n",
    "            node = nodes.get(nid, {})\n",
    "            deps = set(node.get(\"dependencies\", []))\n",
    "            internal_deps = deps & node_id_set\n",
    "            if internal_deps.issubset(set(sorted_nodes)):\n",
    "                ready.append(nid)\n",
    "        \n",
    "        if not ready:\n",
    "            # Circular dependency - add remaining in order\n",
    "            for nid in node_ids:\n",
    "                if nid in remaining:\n",
    "                    sorted_nodes.append(nid)\n",
    "            break\n",
    "        \n",
    "        ready_ordered = [nid for nid in node_ids if nid in ready]\n",
    "        sorted_nodes.extend(ready_ordered)\n",
    "        remaining -= set(ready_ordered)\n",
    "    \n",
    "    return sorted_nodes\n",
    "\n",
    "\n",
    "async def expand_all_nodes(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Expand all leaf nodes in dependency order.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in expand_all_nodes\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    if not skeleton or not skeleton.get(\"nodes\"):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Phase 3: Node Expansion - SKIPPED (no skeleton)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        return {\"prose_store\": {}, \"claims_registry\": {}, \"nodes_expanded\": [], \"extracted_claims\": []}\n",
    "\n",
    "    research_summary = state.get(\"research_summary\", \"\")\n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "\n",
    "    # Get audience profile for calibration\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    audience_type = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 3: Node Expansion\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Audience: {audience_type}\")\n",
    "\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_nodes = topological_sort_nodes(skeleton, leaf_nodes)\n",
    "\n",
    "    prose_store = {}\n",
    "    claims_registry = {}\n",
    "    all_extracted_claims = []\n",
    "\n",
    "    for i, node_id in enumerate(sorted_nodes):\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        if not node:\n",
    "            continue\n",
    "        print(f\"  [{i+1}/{len(sorted_nodes)}] {node_id}: {node.get('title', node_id)}\")\n",
    "\n",
    "        # Get previous section's summary (not bridge_out - we removed those)\n",
    "        prev_summary = \"\"\n",
    "        if i > 0:\n",
    "            prev_id = sorted_nodes[i-1]\n",
    "            if prev_id in prose_store:\n",
    "                prev_summary = prose_store[prev_id].get(\"section_conclusion\", \"\")\n",
    "\n",
    "        # Get next section's intent for context\n",
    "        next_intent = \"\"\n",
    "        if i < len(sorted_nodes) - 1:\n",
    "            next_id = sorted_nodes[i+1]\n",
    "            next_node = skeleton.get(\"nodes\", {}).get(next_id, {})\n",
    "            next_intent = next_node.get(\"intent\", \"\")\n",
    "\n",
    "        # Get dependency summaries\n",
    "        dep_summaries = []\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id in prose_store:\n",
    "                dep_title = skeleton.get(\"nodes\", {}).get(dep_id, {}).get(\"title\", dep_id)\n",
    "                dep_summary = prose_store[dep_id].get(\"section_conclusion\", \"\")\n",
    "                dep_summaries.append(f\"{dep_title}: {dep_summary}\")\n",
    "\n",
    "        prompt = PROSE_PROMPT.format(\n",
    "            question=question,\n",
    "            thesis=skeleton.get(\"thesis\", \"\"),\n",
    "            audience_type=audience_type,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            target_words=node.get(\"target_word_count\", TARGET_WORDS_PER_NODE),\n",
    "            previous_summary=prev_summary if prev_summary else \"(First section - no prior context)\",\n",
    "            next_intent=next_intent if next_intent else \"(Last section)\",\n",
    "            dependency_summaries=\"\\n\".join(dep_summaries) if dep_summaries else \"(No dependencies)\",\n",
    "            research_findings=research_summary[:4000]\n",
    "        )\n",
    "\n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutputV2, method=\"function_calling\")\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "        # Store prose with new format (no bridge sentences)\n",
    "        prose_store[node_id] = {\n",
    "            \"node_id\": node_id,\n",
    "            \"main_content\": result.main_content,\n",
    "            \"section_conclusion\": result.section_conclusion,\n",
    "            \"claims_made\": result.claims_made,\n",
    "            \"revision_count\": 0\n",
    "        }\n",
    "\n",
    "        # Collect claims for verification\n",
    "        for claim_data in result.claims_made:\n",
    "            all_extracted_claims.append({\n",
    "                \"claim_text\": claim_data.claim,\n",
    "                \"source_url\": claim_data.source_url,\n",
    "                \"source_node\": node_id\n",
    "            })\n",
    "        \n",
    "        print(f\"      Generated {len(result.main_content)} chars, {len(result.claims_made)} claims\")\n",
    "\n",
    "    print(f\"  Total claims extracted: {len(all_extracted_claims)}\")\n",
    "\n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"claims_registry\": claims_registry,\n",
    "        \"nodes_expanded\": sorted_nodes,\n",
    "        \"extracted_claims\": all_extracted_claims  # For verification node\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 3 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b02bc",
   "metadata": {},
   "source": [
    "## 7. Phase 4: Verification and Refinement\n",
    "\n",
    "Critique the document, apply Quality Gate 2, do targeted retrieval for weak claims, and apply patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 critique defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 4: Critique and Quality Gate 2 =====\n",
    "\n",
    "CRITIQUE_PROMPT = \"\"\"You are a critical reviewer evaluating a research document for a {audience_type} audience.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "DOCUMENT THESIS: {thesis}\n",
    "\n",
    "FULL DOCUMENT:\n",
    "{document_content}\n",
    "\n",
    "Analyze for these SPECIFIC issues at FOUR levels:\n",
    "\n",
    "## 1. STRUCTURAL ISSUES (scope: global) - CRITICAL\n",
    "- methodology_bloat: Is methodology/process description >20% of document? Flag if yes. (severity: critical)\n",
    "- missing_executive_summary: Is there a clear upfront synthesis of key findings? (severity: critical)\n",
    "- missing_recommendations: Are there actionable conclusions or decision guidance? (severity: major)\n",
    "- poor_information_density: Are there sections that consume space without adding new information? (severity: major)\n",
    "- wrong_structure: Does the document lead with process/methodology instead of findings? (severity: critical)\n",
    "\n",
    "## 2. LANGUAGE ISSUES (scope: section) - CHECK EVERY SECTION\n",
    "- self_referential: Phrases like \"this section will\", \"we will show\", \"the report presents\", \"as will be demonstrated\" (severity: major)\n",
    "- formulaic_transitions: \"Building on the previous...\", \"As established above...\", \"Having discussed...\" (severity: minor)\n",
    "- jargon_undefined: Technical terms used without definition on first use (severity: minor)\n",
    "- repetitive_content: Same information stated multiple ways across paragraphs (severity: major)\n",
    "- dense_paragraphs: Paragraphs over 100 words that should be broken up (severity: minor)\n",
    "\n",
    "## 3. EVIDENCE ISSUES (scope: section) - MOST IMPORTANT\n",
    "- unsupported_claim: Factual assertion without any citation (severity: critical)\n",
    "- irrelevant_citation: Citation that doesn't actually support the specific claim (severity: critical)\n",
    "- stale_evidence: Data more than 2 years old without acknowledgment (severity: minor)\n",
    "- missing_counterargument: Strong claims without considering opposing views (severity: major)\n",
    "- vague_attribution: \"Studies show\" or \"Experts say\" without specific citation (severity: major)\n",
    "\n",
    "## 4. USABILITY ISSUES (scope: global)\n",
    "- unclear_audience: Document doesn't seem calibrated to any specific audience (severity: major)\n",
    "- no_confidence_levels: Major conclusions lack uncertainty/confidence indication (severity: minor)\n",
    "- no_prioritization: Lists of recommendations or findings without ranking by importance (severity: minor)\n",
    "- missing_quick_reference: No summary tables, bullet points, or scannable content (severity: minor)\n",
    "- promised_artifacts: References to appendices, data files, or artifacts that don't exist (severity: major)\n",
    "\n",
    "For each issue, output:\n",
    "- issue_id: Unique identifier (e.g., \"struct_001\", \"lang_002\")\n",
    "- issue_type: Category from the lists above (e.g., \"methodology_bloat\", \"self_referential\")\n",
    "- scope: \"global\" or \"section\"\n",
    "- target_nodes: List of affected section IDs (e.g., [\"sec:intro\", \"sec:background\"])\n",
    "- severity: \"critical\", \"major\", or \"minor\"\n",
    "- description: Specific description of what's wrong (quote the problematic text if applicable)\n",
    "- suggestion: Specific instruction for how to fix it\n",
    "- search_query: Query to find better evidence (only for evidence issues, empty otherwise)\n",
    "\n",
    "SCORING RULES:\n",
    "- Start at 10\n",
    "- -2 for each critical issue\n",
    "- -1 for each major issue\n",
    "- -0.25 for each minor issue\n",
    "- Minimum score: 1\n",
    "\n",
    "IMPORTANT CALIBRATION:\n",
    "- Be STRICT about self-referential language - it's a major quality issue\n",
    "- Be STRICT about methodology bloat - the document should lead with findings\n",
    "- Scores of 7+ should be reserved for documents that genuinely deliver clear, actionable insights\n",
    "- A document full of \"this section will\" language should score below 6\n",
    "\n",
    "Provide overall_quality score, summary of key issues, and the full issues list.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def critique_document(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Perform structured critique producing the Noise Map.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in critique_document\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "\n",
    "    # Get audience profile\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    audience_type = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "\n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4a: Critique (Iteration {iteration})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Audience: {audience_type}\")\n",
    "\n",
    "    # Check if we have content to critique\n",
    "    if not skeleton or not prose_store:\n",
    "        print(\"  No content to critique - skipping\")\n",
    "        return {\n",
    "            \"noise_map\": [],\n",
    "            \"nodes_to_patch\": [],\n",
    "            \"quality_scores\": [10.0],\n",
    "            \"current_refinement_iteration\": iteration\n",
    "        }\n",
    "\n",
    "    # Build document content (updated format - no bridge sentences)\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    document_content = \"\"\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id in prose_store:\n",
    "            node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "            prose = prose_store.get(node_id, {})\n",
    "            document_content += f\"\\n\\n## {node.get('title', node_id)} [{node_id}]\\n\"\n",
    "            document_content += f\"{prose.get('main_content', '')}\\n\"\n",
    "            # Include section conclusion if available\n",
    "            if prose.get('section_conclusion'):\n",
    "                document_content += f\"\\n[Section Conclusion: {prose.get('section_conclusion')}]\\n\"\n",
    "\n",
    "    if len(document_content) > 12000:\n",
    "        document_content = document_content[:12000] + \"\\n...[truncated]\"\n",
    "\n",
    "    prompt = CRITIQUE_PROMPT.format(\n",
    "        question=question,\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        document_content=document_content,\n",
    "        audience_type=audience_type\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(CritiqueResult, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    noise_map = [issue.model_dump() for issue in result.issues]\n",
    "    \n",
    "    # Identify nodes needing patches\n",
    "    nodes_to_patch = list(set(\n",
    "        node_id for issue in result.issues\n",
    "        for node_id in issue.target_nodes\n",
    "        if issue.severity in [\"critical\", \"major\"]\n",
    "    ))\n",
    "    \n",
    "    print(f\"  Quality Score: {result.overall_quality}/10\")\n",
    "    print(f\"  Issues: {len(result.issues)}\")\n",
    "    print(f\"  Nodes to patch: {len(nodes_to_patch)}\")\n",
    "    \n",
    "    return {\n",
    "        \"noise_map\": noise_map,\n",
    "        \"nodes_to_patch\": nodes_to_patch,\n",
    "        \"quality_scores\": [result.overall_quality],\n",
    "        \"current_refinement_iteration\": iteration\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 4 critique defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d6e68",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 retrieval and patching defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 4: Targeted Retrieval and Patching =====\n",
    "\n",
    "PATCH_PROMPT = \"\"\"You are revising a section based on critique feedback.\n",
    "\n",
    "SECTION TO REVISE:\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "Target Audience: {audience_type}\n",
    "\n",
    "CURRENT CONTENT:\n",
    "{current_content}\n",
    "\n",
    "ISSUES TO FIX:\n",
    "{issues_text}\n",
    "\n",
    "NEW EVIDENCE:\n",
    "{new_evidence}\n",
    "\n",
    "CONTEXT:\n",
    "Previous section established: {prev_summary}\n",
    "Next section covers: {next_intent}\n",
    "\n",
    "REVISION RULES - CRITICAL:\n",
    "1. NEVER say \"this section will...\", \"we will show...\", \"the report presents...\"\n",
    "2. NEVER use formulaic transitions like \"Building on the previous...\"\n",
    "3. NEVER create paragraphs over 100 words\n",
    "4. DEFINE technical terms on first use\n",
    "5. Every paragraph must contain NEW information\n",
    "6. Incorporate new evidence with proper citations (Source: URL)\n",
    "\n",
    "Address ALL listed issues. If an issue is about self-referential language, remove ALL instances.\n",
    "If an issue is about unsupported claims, either add citations or soften the language.\n",
    "\n",
    "Output: main_content (the revised prose) and section_conclusion (1-2 sentence summary).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def targeted_retrieval(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Search for evidence to address issues.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in targeted_retrieval\")\n",
    "        \n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 4b: Targeted Retrieval\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No nodes need patching\")\n",
    "        return {\"targeted_evidence\": {}}\n",
    "    \n",
    "    # Collect search queries per node\n",
    "    node_queries = {}\n",
    "    for issue in noise_map:\n",
    "        if issue.get(\"search_query\") and issue.get(\"severity\") in [\"critical\", \"major\"]:\n",
    "            for node_id in issue.get(\"target_nodes\", []):\n",
    "                if node_id in nodes_to_patch:\n",
    "                    if node_id not in node_queries:\n",
    "                        node_queries[node_id] = []\n",
    "                    node_queries[node_id].append(issue[\"search_query\"])\n",
    "    \n",
    "    targeted_evidence = {}\n",
    "    \n",
    "    for node_id, queries in node_queries.items():\n",
    "        print(f\"  Searching for: {node_id}\")\n",
    "        node_evidence = []\n",
    "        for query in queries[:2]:  # Limit queries per node\n",
    "            print(f\"    Query: {query[:40]}...\")\n",
    "            content, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "            node_evidence.append(content[:1000])\n",
    "            action = \"CACHE\" if decision.action_taken == \"USE_CACHE\" else \"SEARCH\"\n",
    "            print(f\"      {action} | Layer: {decision.layer_reached}\")\n",
    "        targeted_evidence[node_id] = node_evidence\n",
    "    \n",
    "    print(f\"  Evidence gathered for {len(targeted_evidence)} nodes\")\n",
    "    \n",
    "    return {\"targeted_evidence\": targeted_evidence}\n",
    "\n",
    "\n",
    "async def apply_patches(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Apply patches to nodes with issues.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in apply_patches\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    targeted_evidence = state.get(\"targeted_evidence\", {})\n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "\n",
    "    # Get audience profile\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    audience_type = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 4c: Apply Patches\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not nodes_to_patch or not skeleton or not prose_store:\n",
    "        print(\"  No patches needed\")\n",
    "        return {\"prose_store\": prose_store, \"current_refinement_iteration\": iteration + 1}\n",
    "\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_patch = topological_sort_nodes(skeleton, [n for n in nodes_to_patch if n in leaf_nodes])\n",
    "\n",
    "    for node_id in sorted_patch[:3]:  # Limit patches per iteration\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        if not node:\n",
    "            continue\n",
    "\n",
    "        current = prose_store[node_id]\n",
    "\n",
    "        print(f\"  Patching: {node_id}\")\n",
    "\n",
    "        # Get issues for this node\n",
    "        node_issues = [i for i in noise_map if node_id in i.get(\"target_nodes\", [])]\n",
    "        issues_text = \"\\n\".join([\n",
    "            f\"- [{i['severity']}] {i['issue_type']}: {i['description']}\\n  Suggestion: {i.get('suggestion', 'N/A')}\"\n",
    "            for i in node_issues\n",
    "        ])\n",
    "\n",
    "        evidence = targeted_evidence.get(node_id, [])\n",
    "        evidence_text = \"\\n\\n\".join(evidence) if evidence else \"No additional evidence.\"\n",
    "\n",
    "        # Get adjacent context (new format - summaries and intents, not bridges)\n",
    "        idx = leaf_nodes.index(node_id) if node_id in leaf_nodes else -1\n",
    "        prev_summary = prose_store.get(leaf_nodes[idx-1], {}).get(\"section_conclusion\", \"\") if idx > 0 else \"\"\n",
    "        next_intent = skeleton.get(\"nodes\", {}).get(leaf_nodes[idx+1], {}).get(\"intent\", \"\") if idx < len(leaf_nodes)-1 else \"\"\n",
    "\n",
    "        prompt = PATCH_PROMPT.format(\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            audience_type=audience_type,\n",
    "            current_content=current.get('main_content', ''),\n",
    "            issues_text=issues_text,\n",
    "            new_evidence=evidence_text[:3000],\n",
    "            prev_summary=prev_summary if prev_summary else \"(First section)\",\n",
    "            next_intent=next_intent if next_intent else \"(Last section)\"\n",
    "        )\n",
    "\n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutputV2, method=\"function_calling\")\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "        prose_store[node_id] = {\n",
    "            \"node_id\": node_id,\n",
    "            \"main_content\": result.main_content,\n",
    "            \"section_conclusion\": result.section_conclusion,\n",
    "            \"claims_made\": result.claims_made,\n",
    "            \"revision_count\": current.get(\"revision_count\", 0) + 1\n",
    "        }\n",
    "        \n",
    "        print(f\"    Revised: {len(result.main_content)} chars\")\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"current_refinement_iteration\": iteration + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def should_continue_refining(state: CombinedTier1State) -> Literal[\"targeted_retrieval\", \"assemble\"]:\n",
    "    \"\"\"Decide whether to continue refinement.\"\"\"\n",
    "    if state is None:\n",
    "        return \"assemble\"\n",
    "        \n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    \n",
    "    latest_score = quality_scores[-1] if quality_scores else 0\n",
    "    \n",
    "    print(f\"\\n--- Quality Gate 2 ---\")\n",
    "    print(f\"  Iteration: {iteration}/{MAX_REFINEMENT_ITERATIONS}\")\n",
    "    print(f\"  Score: {latest_score}/{QUALITY_THRESHOLD}\")\n",
    "    \n",
    "    if iteration >= MAX_REFINEMENT_ITERATIONS:\n",
    "        print(\"  Max iterations. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    if latest_score >= QUALITY_THRESHOLD:\n",
    "        print(\"  Quality threshold met. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No issues. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    \n",
    "    print(\"  Continuing refinement.\")\n",
    "    return \"targeted_retrieval\"\n",
    "\n",
    "\n",
    "print(\"Phase 4 retrieval and patching defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e960ec9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audience analysis node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Audience Analysis Node =====\n",
    "\n",
    "AUDIENCE_ANALYSIS_PROMPT = \"\"\"Analyze this research question to determine the most likely target audience.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Consider:\n",
    "1. WHO would ask this question?\n",
    "   - Executives/decision-makers: Need quick answers and actionable recommendations\n",
    "   - Analysts/researchers: Need detailed evidence and methodology\n",
    "   - General readers/students: Need accessible explanations and context\n",
    "\n",
    "2. WHAT do they need from the answer?\n",
    "   - Decisions to make\n",
    "   - Understanding to gain\n",
    "   - Validation of existing beliefs\n",
    "   - New perspectives to consider\n",
    "\n",
    "3. HOW much detail do they want?\n",
    "   - Executive summary only\n",
    "   - Full analysis with evidence\n",
    "   - Deep technical dive\n",
    "\n",
    "Based on your analysis, provide:\n",
    "- primary_audience: The main audience type\n",
    "- audience_needs: 2-4 specific needs this audience has\n",
    "- methodology_weight: 0.1 (minimal) to 0.3 (detailed) - how much methodology to include\n",
    "- executive_summary_priority: high/medium/low\n",
    "- recommendation_style: prescriptive (do X), analytical (consider X,Y,Z), or educational (understand X)\n",
    "- jargon_level: low (define everything), medium (define technical terms), high (assume expertise)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def audience_analysis(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Analyze the research question to determine target audience and calibrate output.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in audience_analysis\")\n",
    "\n",
    "    question = state.get(\"question\", \"\")\n",
    "    if not question:\n",
    "        raise ValueError(\"Question is missing or empty in state\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1e: Audience Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    prompt = AUDIENCE_ANALYSIS_PROMPT.format(question=question)\n",
    "\n",
    "    structured_llm = llm.with_structured_output(AudienceAnalysisOutput, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    audience_profile = {\n",
    "        \"primary_audience\": result.primary_audience,\n",
    "        \"audience_needs\": result.audience_needs,\n",
    "        \"methodology_weight\": result.methodology_weight,\n",
    "        \"executive_summary_priority\": result.executive_summary_priority,\n",
    "        \"recommendation_style\": result.recommendation_style,\n",
    "        \"jargon_level\": result.jargon_level\n",
    "    }\n",
    "\n",
    "    print(f\"  Audience: {result.primary_audience}\")\n",
    "    print(f\"  Methodology weight: {result.methodology_weight}\")\n",
    "    print(f\"  Recommendation style: {result.recommendation_style}\")\n",
    "\n",
    "    return {\"audience_profile\": audience_profile}\n",
    "\n",
    "\n",
    "print(\"Audience analysis node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81957362",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executive summary node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Executive Summary Generation Node =====\n",
    "\n",
    "EXECUTIVE_SUMMARY_PROMPT = \"\"\"Create an executive summary for this research report.\n",
    "\n",
    "Research Question: {question}\n",
    "Document Thesis: {thesis}\n",
    "Target Audience: {audience_type}\n",
    "\n",
    "Section Summaries:\n",
    "{section_summaries}\n",
    "\n",
    "Key Sources Used: {source_count} sources\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Maximum 400 words\n",
    "- Lead with the MAIN FINDING - the single most important conclusion\n",
    "- Include 3-5 KEY TAKEAWAYS as bullet points\n",
    "- Each takeaway should have a confidence level (High/Medium/Low)\n",
    "- End with a BOTTOM LINE - one sentence actionable implication\n",
    "- Do NOT describe methodology or how the research was conducted\n",
    "- Do NOT say \"this report shows\" or \"we found\" - just state the findings directly\n",
    "- Do NOT use self-referential language\n",
    "\n",
    "FORMAT:\n",
    "**Main Finding:** [One sentence stating the core conclusion]\n",
    "\n",
    "**Key Takeaways:**\n",
    "- [Takeaway 1] (Confidence: High/Medium/Low)\n",
    "- [Takeaway 2] (Confidence: High/Medium/Low)\n",
    "- [Takeaway 3] (Confidence: High/Medium/Low)\n",
    "\n",
    "**Bottom Line:** [One sentence actionable implication for the reader]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def generate_executive_summary(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Generate an executive summary synthesizing key findings.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in generate_executive_summary\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    question = state.get(\"question\", \"\")\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "\n",
    "    # Get audience profile\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    audience_type = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 5a: Executive Summary Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not skeleton or not prose_store:\n",
    "        print(\"  No content for executive summary\")\n",
    "        return {\"executive_summary\": \"\"}\n",
    "\n",
    "    # Collect section summaries\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    section_summaries = []\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id in prose_store:\n",
    "            node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "            conclusion = prose_store[node_id].get(\"section_conclusion\", \"\")\n",
    "            if conclusion:\n",
    "                section_summaries.append(f\"**{node.get('title', node_id)}:** {conclusion}\")\n",
    "\n",
    "    prompt = EXECUTIVE_SUMMARY_PROMPT.format(\n",
    "        question=question,\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        audience_type=audience_type,\n",
    "        section_summaries=\"\\n\".join(section_summaries),\n",
    "        source_count=len(set(source_urls))\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(ExecutiveSummaryOutput, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # Format the executive summary\n",
    "    exec_summary = f\"## Executive Summary\\n\\n\"\n",
    "    exec_summary += f\"**Main Finding:** {result.main_finding}\\n\\n\"\n",
    "    exec_summary += \"**Key Takeaways:**\\n\"\n",
    "    for takeaway in result.key_takeaways:\n",
    "        exec_summary += f\"- {takeaway.takeaway} (Confidence: {takeaway.confidence})\\n\"\n",
    "    exec_summary += f\"\\n**Bottom Line:** {result.bottom_line}\\n\"\n",
    "\n",
    "    print(f\"  Generated executive summary: {len(exec_summary)} chars\")\n",
    "    print(f\"  Key takeaways: {len(result.key_takeaways)}\")\n",
    "\n",
    "    return {\"executive_summary\": exec_summary}\n",
    "\n",
    "\n",
    "print(\"Executive summary node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7099925",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision framework node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Decision Framework Generation Node =====\n",
    "\n",
    "DECISION_FRAMEWORK_PROMPT = \"\"\"Based on this research analysis, create a decision framework with actionable recommendations.\n",
    "\n",
    "Research Question: {question}\n",
    "Target Audience: {audience_type}\n",
    "Recommendation Style: {recommendation_style}\n",
    "\n",
    "Key Findings:\n",
    "{findings_summary}\n",
    "\n",
    "Create a decision framework with:\n",
    "\n",
    "1. PRIMARY RECOMMENDATIONS (1-3 most important actions)\n",
    "   - These are the key actions the reader should consider\n",
    "   - Each should have: Action, Rationale, Conditions, Priority\n",
    "\n",
    "2. CONDITIONAL RECOMMENDATIONS (2-4 \"if X then Y\" format)\n",
    "   - These depend on the reader's specific situation\n",
    "   - Format: \"If [condition], then [action]\"\n",
    "\n",
    "3. MONITORING INDICATORS (3-5 things to watch)\n",
    "   - What should the reader monitor going forward?\n",
    "   - Early warning signs or key metrics\n",
    "\n",
    "RULES:\n",
    "- Be SPECIFIC and ACTIONABLE - avoid vague advice\n",
    "- Do NOT create hypothetical scenarios to test\n",
    "- Do NOT promise future analysis\n",
    "- Base all recommendations on the findings provided\n",
    "- Prioritize recommendations clearly (High/Medium/Low)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def generate_decision_framework(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Generate a decision framework with actionable recommendations.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in generate_decision_framework\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    question = state.get(\"question\", \"\")\n",
    "\n",
    "    # Get audience profile\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    audience_type = audience_profile.get(\"primary_audience\", \"analysts\")\n",
    "    recommendation_style = audience_profile.get(\"recommendation_style\", \"analytical\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 5b: Decision Framework Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not skeleton or not prose_store:\n",
    "        print(\"  No content for decision framework\")\n",
    "        return {\"decision_framework\": \"\"}\n",
    "\n",
    "    # Collect findings from section conclusions\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    findings = []\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id in prose_store:\n",
    "            node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "            conclusion = prose_store[node_id].get(\"section_conclusion\", \"\")\n",
    "            if conclusion:\n",
    "                findings.append(f\"- {node.get('title', node_id)}: {conclusion}\")\n",
    "\n",
    "    prompt = DECISION_FRAMEWORK_PROMPT.format(\n",
    "        question=question,\n",
    "        audience_type=audience_type,\n",
    "        recommendation_style=recommendation_style,\n",
    "        findings_summary=\"\\n\".join(findings)\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(DecisionFrameworkOutput, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # Format the decision framework\n",
    "    framework = \"## Recommendations\\n\\n\"\n",
    "\n",
    "    framework += \"### Primary Recommendations\\n\\n\"\n",
    "    for i, rec in enumerate(result.primary_recommendations, 1):\n",
    "        framework += f\"**{i}. {rec.action}** (Priority: {rec.priority})\\n\"\n",
    "        framework += f\"   - *Rationale:* {rec.rationale}\\n\"\n",
    "        framework += f\"   - *Applies when:* {rec.conditions}\\n\\n\"\n",
    "\n",
    "    if result.conditional_recommendations:\n",
    "        framework += \"### Conditional Recommendations\\n\\n\"\n",
    "        for rec in result.conditional_recommendations:\n",
    "            framework += f\"- **If** {rec.conditions}, **then** {rec.action}\\n\"\n",
    "            framework += f\"  *({rec.rationale})*\\n\\n\"\n",
    "\n",
    "    if result.monitoring_indicators:\n",
    "        framework += \"### What to Monitor\\n\\n\"\n",
    "        for indicator in result.monitoring_indicators:\n",
    "            framework += f\"- {indicator}\\n\"\n",
    "\n",
    "    print(f\"  Generated decision framework: {len(framework)} chars\")\n",
    "    print(f\"  Primary recommendations: {len(result.primary_recommendations)}\")\n",
    "\n",
    "    return {\"decision_framework\": framework}\n",
    "\n",
    "\n",
    "print(\"Decision framework node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40b28b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence assessment node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Confidence Assessment Node =====\n",
    "\n",
    "CONFIDENCE_ASSESSMENT_PROMPT = \"\"\"Review this research analysis and assess confidence levels for each major conclusion.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Major Conclusions:\n",
    "{conclusions}\n",
    "\n",
    "Evidence Summary:\n",
    "- Total sources used: {source_count}\n",
    "- Validated sources: {validated_count}\n",
    "\n",
    "For each conclusion, assess:\n",
    "1. Evidence strength (how many sources support it, source quality)\n",
    "2. Consistency (do sources agree or conflict?)\n",
    "3. Recency (how current is the evidence?)\n",
    "4. Key uncertainty (what's the main limitation?)\n",
    "5. What would change this (what new information could overturn this conclusion?)\n",
    "\n",
    "Also provide:\n",
    "- An overall confidence level for the research\n",
    "- A limitations summary highlighting key uncertainties\n",
    "\n",
    "Be HONEST about uncertainty. If evidence is weak or conflicting, say so.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def add_confidence_levels(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Add confidence level assessments to conclusions.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in add_confidence_levels\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    question = state.get(\"question\", \"\")\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    validated_sources = state.get(\"validated_sources\", {})\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 5c: Confidence Assessment\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not skeleton or not prose_store:\n",
    "        print(\"  No content for confidence assessment\")\n",
    "        return {\"confidence_assessments\": [], \"limitations_summary\": \"\"}\n",
    "\n",
    "    # Collect conclusions\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    conclusions = []\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id in prose_store:\n",
    "            node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "            conclusion = prose_store[node_id].get(\"section_conclusion\", \"\")\n",
    "            if conclusion:\n",
    "                conclusions.append(f\"[{node.get('title', node_id)}]: {conclusion}\")\n",
    "\n",
    "    prompt = CONFIDENCE_ASSESSMENT_PROMPT.format(\n",
    "        question=question,\n",
    "        conclusions=\"\\n\".join(conclusions),\n",
    "        source_count=len(set(source_urls)),\n",
    "        validated_count=len(validated_sources)\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(ConfidenceAssessmentOutput, method=\"function_calling\")\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # Store assessments\n",
    "    confidence_assessments = [a.model_dump() for a in result.assessments]\n",
    "\n",
    "    print(f\"  Assessed {len(confidence_assessments)} conclusions\")\n",
    "    print(f\"  Overall confidence: {result.overall_confidence}\")\n",
    "\n",
    "    return {\n",
    "        \"confidence_assessments\": confidence_assessments,\n",
    "        \"limitations_summary\": result.limitations_summary\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Confidence assessment node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claims verification node defined\n"
     ]
    }
   ],
   "source": [
    "# ===== NEW: Claims Verification Node =====\n",
    "\n",
    "CLAIM_VERIFICATION_PROMPT = \"\"\"Verify if this claim is supported by the source content.\n",
    "\n",
    "Claim: {claim_text}\n",
    "Source URL: {url}\n",
    "Source Content (snippet):\n",
    "{source_content}\n",
    "\n",
    "Determine:\n",
    "1. Does the source DIRECTLY support this specific claim?\n",
    "2. Does the source CONTRADICT this claim?\n",
    "3. Is the claim an EXTRAPOLATION not fully warranted by the source?\n",
    "\n",
    "Output:\n",
    "- supported: \"true\" if directly supported, \"false\" if contradicted or unsupported, \"partial\" if partially supported\n",
    "- source_quote: The relevant quote from the source that supports/contradicts (if found)\n",
    "- issue: Description of the problem if not fully supported (empty if supported)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def extract_and_verify_claims(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Extract and verify claims against their cited sources.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in extract_and_verify_claims\")\n",
    "\n",
    "    extracted_claims = state.get(\"extracted_claims\", [])\n",
    "    validated_sources = state.get(\"validated_sources\", {})\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 3b: Claims Verification\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if not extracted_claims:\n",
    "        print(\"  No claims to verify\")\n",
    "        return {\"verified_claims\": {}, \"claims_needing_revision\": []}\n",
    "\n",
    "    verified_claims = {}\n",
    "    claims_needing_revision = []\n",
    "\n",
    "    # Limit verification to avoid too many LLM calls\n",
    "    claims_to_verify = [c for c in extracted_claims if c.get(\"source_url\")][:20]\n",
    "\n",
    "    print(f\"  Verifying {len(claims_to_verify)} claims with citations\")\n",
    "\n",
    "    for i, claim_data in enumerate(claims_to_verify):\n",
    "        claim_text = claim_data.get(\"claim_text\", \"\")\n",
    "        source_url = claim_data.get(\"source_url\", \"\")\n",
    "        source_node = claim_data.get(\"source_node\", \"\")\n",
    "\n",
    "        if not claim_text or not source_url:\n",
    "            continue\n",
    "\n",
    "        # Get source content from validated sources or skip\n",
    "        source_info = validated_sources.get(source_url, {})\n",
    "        source_content = source_info.get(\"content_snippet\", \"\")\n",
    "\n",
    "        if not source_content:\n",
    "            # Can't verify without content\n",
    "            claims_needing_revision.append({\n",
    "                \"claim_text\": claim_text,\n",
    "                \"source_node\": source_node,\n",
    "                \"issue\": \"Source content not available for verification\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            prompt = CLAIM_VERIFICATION_PROMPT.format(\n",
    "                claim_text=claim_text,\n",
    "                url=source_url,\n",
    "                source_content=source_content[:1000]\n",
    "            )\n",
    "\n",
    "            structured_llm = llm.with_structured_output(ClaimVerificationResult, method=\"function_calling\")\n",
    "            result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "\n",
    "            claim_id = f\"claim_{i}\"\n",
    "            verified_claims[claim_id] = {\n",
    "                \"claim_text\": claim_text,\n",
    "                \"source_url\": source_url,\n",
    "                \"source_node\": source_node,\n",
    "                \"supported\": result.supported,\n",
    "                \"source_quote\": result.source_quote,\n",
    "                \"issue\": result.issue\n",
    "            }\n",
    "\n",
    "            if result.supported == \"false\":\n",
    "                claims_needing_revision.append({\n",
    "                    \"claim_text\": claim_text,\n",
    "                    \"source_node\": source_node,\n",
    "                    \"issue\": result.issue\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Error verifying claim: {str(e)[:50]}\")\n",
    "\n",
    "    verified_count = sum(1 for v in verified_claims.values() if v.get(\"supported\") == \"true\")\n",
    "    print(f\"  Verified: {verified_count}/{len(verified_claims)} claims supported\")\n",
    "    print(f\"  Claims needing revision: {len(claims_needing_revision)}\")\n",
    "\n",
    "    return {\n",
    "        \"verified_claims\": verified_claims,\n",
    "        \"claims_needing_revision\": claims_needing_revision\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Claims verification node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ae229",
   "metadata": {},
   "source": [
    "## 8. Phase 5: Final Assembly\n",
    "\n",
    "Assembles the final markdown report from all prose entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61917381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 5 assembly defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 5: Final Assembly =====\n",
    "\n",
    "async def assemble_document(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Assemble the final document from prose entries with new structure.\"\"\"\n",
    "    if state is None:\n",
    "        raise ValueError(\"State is None in assemble_document\")\n",
    "\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    validated_sources = state.get(\"validated_sources\", {})\n",
    "\n",
    "    # Get new components\n",
    "    executive_summary = state.get(\"executive_summary\", \"\")\n",
    "    decision_framework = state.get(\"decision_framework\", \"\")\n",
    "    confidence_assessments = state.get(\"confidence_assessments\", [])\n",
    "    limitations_summary = state.get(\"limitations_summary\", \"\")\n",
    "\n",
    "    # Get audience profile\n",
    "    audience_profile = state.get(\"audience_profile\", {})\n",
    "    methodology_weight = audience_profile.get(\"methodology_weight\", 0.15)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 5d: Final Assembly\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Check if we have content to assemble\n",
    "    if not skeleton or not prose_store:\n",
    "        print(\"  No content to assemble\")\n",
    "        return {\"final_report\": \"Error: No content was generated.\"}\n",
    "\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "\n",
    "    # Build document with NEW STRUCTURE\n",
    "    parts = []\n",
    "\n",
    "    # 1. Title and Question\n",
    "    parts.append(\"# Research Report\\n\\n\")\n",
    "    parts.append(f\"**Research Question:** {state.get('question', '')}\\n\\n\")\n",
    "    parts.append(f\"**Thesis:** {skeleton.get('thesis', '')}\\n\\n\")\n",
    "    parts.append(\"---\\n\\n\")\n",
    "\n",
    "    # 2. Executive Summary FIRST (if available)\n",
    "    if executive_summary:\n",
    "        parts.append(executive_summary)\n",
    "        parts.append(\"\\n---\\n\\n\")\n",
    "\n",
    "    # 3. Quick Reference / At a Glance\n",
    "    parts.append(\"## At a Glance\\n\\n\")\n",
    "    parts.append(f\"- **Sources Analyzed:** {len(set(source_urls))}\\n\")\n",
    "    parts.append(f\"- **Validated Sources:** {len(validated_sources)}\\n\")\n",
    "    parts.append(f\"- **Quality Score:** {quality_scores[-1] if quality_scores else 'N/A'}/10\\n\")\n",
    "    if confidence_assessments:\n",
    "        overall_conf = \"Medium\"  # Default\n",
    "        high_count = sum(1 for a in confidence_assessments if a.get(\"confidence\") == \"High\")\n",
    "        low_count = sum(1 for a in confidence_assessments if a.get(\"confidence\") == \"Low\")\n",
    "        if high_count > len(confidence_assessments) / 2:\n",
    "            overall_conf = \"High\"\n",
    "        elif low_count > len(confidence_assessments) / 2:\n",
    "            overall_conf = \"Low\"\n",
    "        parts.append(f\"- **Overall Confidence:** {overall_conf}\\n\")\n",
    "    parts.append(\"\\n---\\n\\n\")\n",
    "\n",
    "    # 4. Main Content Sections (skip methodology if weight is low)\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        prose = prose_store[node_id]\n",
    "\n",
    "        # Skip methodology sections if audience doesn't need them\n",
    "        title_lower = node.get(\"title\", \"\").lower()\n",
    "        if methodology_weight < 0.2 and any(kw in title_lower for kw in [\"methodology\", \"approach\", \"framework\"]):\n",
    "            continue\n",
    "\n",
    "        parts.append(f\"## {node.get('title', node_id)}\\n\\n\")\n",
    "        parts.append(f\"{prose.get('main_content', '')}\\n\\n\")\n",
    "\n",
    "    # 5. Decision Framework / Recommendations (if available)\n",
    "    if decision_framework:\n",
    "        parts.append(\"---\\n\\n\")\n",
    "        parts.append(decision_framework)\n",
    "        parts.append(\"\\n\")\n",
    "\n",
    "    # 6. Confidence Assessment Table (if available)\n",
    "    if confidence_assessments:\n",
    "        parts.append(\"---\\n\\n\")\n",
    "        parts.append(\"## Confidence Assessment\\n\\n\")\n",
    "        parts.append(\"| Conclusion | Confidence | Evidence Quality | Key Uncertainty |\\n\")\n",
    "        parts.append(\"|------------|------------|------------------|------------------|\\n\")\n",
    "        for assessment in confidence_assessments[:5]:  # Limit to top 5\n",
    "            conclusion = assessment.get(\"conclusion\", \"\")[:50] + \"...\" if len(assessment.get(\"conclusion\", \"\")) > 50 else assessment.get(\"conclusion\", \"\")\n",
    "            parts.append(f\"| {conclusion} | {assessment.get('confidence', 'N/A')} | {assessment.get('evidence_quality', 'N/A')} | {assessment.get('key_uncertainty', 'N/A')[:30]}... |\\n\")\n",
    "        parts.append(\"\\n\")\n",
    "\n",
    "    # 7. Limitations (if available)\n",
    "    if limitations_summary:\n",
    "        parts.append(\"---\\n\\n\")\n",
    "        parts.append(\"## Limitations and Uncertainties\\n\\n\")\n",
    "        parts.append(f\"{limitations_summary}\\n\\n\")\n",
    "\n",
    "    # 8. References (filtered to validated sources if possible)\n",
    "    parts.append(\"---\\n\\n\")\n",
    "    parts.append(\"## References\\n\\n\")\n",
    "\n",
    "    # Prefer validated sources, fall back to all unique URLs\n",
    "    if validated_sources:\n",
    "        ref_urls = list(validated_sources.keys())[:25]\n",
    "        for i, url in enumerate(ref_urls, 1):\n",
    "            source_info = validated_sources.get(url, {})\n",
    "            title = source_info.get(\"title\", \"\")\n",
    "            if title:\n",
    "                parts.append(f\"{i}. [{title}]({url})\\n\")\n",
    "            else:\n",
    "                parts.append(f\"{i}. {url}\\n\")\n",
    "    else:\n",
    "        unique_urls = list(set(source_urls))[:25]\n",
    "        for i, url in enumerate(unique_urls, 1):\n",
    "            parts.append(f\"{i}. {url}\\n\")\n",
    "\n",
    "    final_report = \"\".join(parts)\n",
    "    word_count = len(final_report.split())\n",
    "\n",
    "    print(f\"  Document: {len(final_report)} chars ({word_count} words)\")\n",
    "    print(f\"  Sections: {len(leaf_nodes)}\")\n",
    "    print(f\"  Quality: {' -> '.join([f'{s:.1f}' for s in quality_scores])}\")\n",
    "    print(f\"  Sources: {len(validated_sources)} validated / {len(set(source_urls))} total\")\n",
    "    print(f\"  Has executive summary: {bool(executive_summary)}\")\n",
    "    print(f\"  Has decision framework: {bool(decision_framework)}\")\n",
    "    print(f\"  Cache: {knowledge_base.get_stats_summary()}\")\n",
    "\n",
    "    return {\"final_report\": final_report}\n",
    "\n",
    "\n",
    "print(\"Phase 5 assembly defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cd58d",
   "metadata": {},
   "source": [
    "## 9. Graph Construction\n",
    "\n",
    "Build the complete LangGraph combining all phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083617a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Tier 1 Agent compiled successfully!\n",
      "\n",
      "NEW Architecture:\n",
      "  Phase 1: decompose → [sprint → validate_sources → retrospective] → gate1 → compress\n",
      "  Phase 1e: audience_analysis\n",
      "  Phase 2: generate_skeleton\n",
      "  Phase 3: expand_all_nodes → extract_and_verify_claims\n",
      "  Phase 4: [critique → retrieval → patch] loop\n",
      "  Phase 5: exec_summary → decision_framework → confidence → assemble\n"
     ]
    }
   ],
   "source": [
    "# ===== Graph Construction =====\n",
    "\n",
    "builder = StateGraph(CombinedTier1State)\n",
    "\n",
    "# Add all nodes (original + NEW nodes)\n",
    "builder.add_node(\"decompose_question\", decompose_question)\n",
    "builder.add_node(\"execute_research_sprint\", execute_research_sprint)\n",
    "builder.add_node(\"validate_sources\", validate_sources)  # NEW\n",
    "builder.add_node(\"research_retrospective\", research_retrospective)\n",
    "builder.add_node(\"quality_gate_1\", quality_gate_1)\n",
    "builder.add_node(\"compress_findings\", compress_findings)\n",
    "builder.add_node(\"audience_analysis\", audience_analysis)  # NEW\n",
    "builder.add_node(\"generate_skeleton\", generate_skeleton)\n",
    "builder.add_node(\"expand_all_nodes\", expand_all_nodes)\n",
    "builder.add_node(\"extract_and_verify_claims\", extract_and_verify_claims)  # NEW\n",
    "builder.add_node(\"critique_document\", critique_document)\n",
    "builder.add_node(\"targeted_retrieval\", targeted_retrieval)\n",
    "builder.add_node(\"apply_patches\", apply_patches)\n",
    "builder.add_node(\"generate_executive_summary\", generate_executive_summary)  # NEW\n",
    "builder.add_node(\"generate_decision_framework\", generate_decision_framework)  # NEW\n",
    "builder.add_node(\"add_confidence_levels\", add_confidence_levels)  # NEW\n",
    "builder.add_node(\"assemble_document\", assemble_document)\n",
    "\n",
    "# Phase 1: Research Sprints with Source Validation\n",
    "builder.add_edge(START, \"decompose_question\")\n",
    "builder.add_edge(\"decompose_question\", \"execute_research_sprint\")\n",
    "builder.add_edge(\"execute_research_sprint\", \"validate_sources\")  # NEW: validate after search\n",
    "builder.add_edge(\"validate_sources\", \"research_retrospective\")  # Then retrospective\n",
    "\n",
    "# Research loop\n",
    "builder.add_conditional_edges(\n",
    "    \"research_retrospective\",\n",
    "    should_continue_research,\n",
    "    {\n",
    "        \"execute_sprint\": \"execute_research_sprint\",\n",
    "        \"quality_gate_1\": \"quality_gate_1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Phase 1 -> Phase 2: Add audience analysis\n",
    "builder.add_edge(\"quality_gate_1\", \"compress_findings\")\n",
    "builder.add_edge(\"compress_findings\", \"audience_analysis\")  # NEW: analyze audience\n",
    "builder.add_edge(\"audience_analysis\", \"generate_skeleton\")  # Then skeleton\n",
    "\n",
    "# Phase 2 -> Phase 3\n",
    "builder.add_edge(\"generate_skeleton\", \"expand_all_nodes\")\n",
    "\n",
    "# Phase 3 -> Claims verification -> Phase 4\n",
    "builder.add_edge(\"expand_all_nodes\", \"extract_and_verify_claims\")  # NEW: verify claims\n",
    "builder.add_edge(\"extract_and_verify_claims\", \"critique_document\")  # Then critique\n",
    "\n",
    "# Phase 4: Refinement loop\n",
    "builder.add_conditional_edges(\n",
    "    \"critique_document\",\n",
    "    should_continue_refining,\n",
    "    {\n",
    "        \"targeted_retrieval\": \"targeted_retrieval\",\n",
    "        \"assemble\": \"generate_executive_summary\"  # NEW: go to exec summary first\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"targeted_retrieval\", \"apply_patches\")\n",
    "builder.add_edge(\"apply_patches\", \"critique_document\")\n",
    "\n",
    "# Phase 5: Output generation chain\n",
    "builder.add_edge(\"generate_executive_summary\", \"generate_decision_framework\")  # NEW\n",
    "builder.add_edge(\"generate_decision_framework\", \"add_confidence_levels\")  # NEW\n",
    "builder.add_edge(\"add_confidence_levels\", \"assemble_document\")  # NEW\n",
    "builder.add_edge(\"assemble_document\", END)\n",
    "\n",
    "# Compile\n",
    "combined_tier1_graph = builder.compile()\n",
    "\n",
    "print(\"Combined Tier 1 Agent compiled successfully!\")\n",
    "print(\"\\nNEW Architecture:\")\n",
    "print(\"  Phase 1: decompose → [sprint → validate_sources → retrospective] → gate1 → compress\")\n",
    "print(\"  Phase 1e: audience_analysis\")\n",
    "print(\"  Phase 2: generate_skeleton\")\n",
    "print(\"  Phase 3: expand_all_nodes → extract_and_verify_claims\")\n",
    "print(\"  Phase 4: [critique → retrieval → patch] loop\")\n",
    "print(\"  Phase 5: exec_summary → decision_framework → confidence → assemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "try:\n",
    "    display(Image(combined_tier1_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24c2d7",
   "metadata": {},
   "source": [
    "## 10. Agent Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent wrappers defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Agent Wrapper =====\n",
    "\n",
    "async def combined_tier1_agent_async(inputs: dict) -> dict:\n",
    "    \"\"\"Async version of the Combined Tier 1 research agent.\"\"\"\n",
    "    global knowledge_base\n",
    "    knowledge_base = KnowledgeBase()  # Reset for fresh session\n",
    "    \n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    result = await combined_tier1_graph.ainvoke(\n",
    "        {\"question\": question},\n",
    "        config={\"recursion_limit\": 100}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.stats.copy(),\n",
    "        \"skeleton\": result.get(\"skeleton\", {}),\n",
    "        \"research_sprints\": result.get(\"current_research_sprint\", 1) - 1,\n",
    "        \"refinement_iterations\": result.get(\"current_refinement_iteration\", 0)\n",
    "    }\n",
    "\n",
    "\n",
    "def combined_tier1_agent(inputs: dict) -> dict:\n",
    "    \"\"\"Sync wrapper for Combined Tier 1 research agent. Compatible with evaluation harness.\"\"\"\n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    async def _execute():\n",
    "        global knowledge_base\n",
    "        knowledge_base = KnowledgeBase()\n",
    "        return await combined_tier1_graph.ainvoke(\n",
    "            {\"question\": question},\n",
    "            config={\"recursion_limit\": 100}\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import concurrent.futures\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(asyncio.run, _execute())\n",
    "            result = future.result()\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(_execute())\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.stats.copy()\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Agent wrappers defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80347ca3",
   "metadata": {},
   "source": [
    "## 11. Manual Test\n",
    "\n",
    "Run this cell to verify the Combined Tier 1 agent works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b53cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Combined Tier 1 Agent\n",
      "Question: What are the key benefits and challenges of using large language models in enterprise applications?\n",
      "\n",
      "Running combined architecture (this will take several minutes)...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Phase 1a: Question Decomposition\n",
      "============================================================\n",
      "  Created backlog with 6 research questions\n",
      "    1. What measurable business benefits do large language models d...\n",
      "    2. What are the primary failure modes and operational risks of ...\n",
      "    3. How do data privacy, security, and regulatory compliance req...\n",
      "    4. What technical and operational challenges arise when integra...\n",
      "    5. How do bias, fairness, transparency, and explainability conc...\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 1/3\n",
      "============================================================\n",
      "  [1/5] What measurable business benefits do large languag...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] What are the primary failure modes and operational...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] How do data privacy, security, and regulatory comp...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] What technical and operational challenges arise wh...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] How do bias, fairness, transparency, and explainab...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 5511 chars, 40 sources\n",
      "  Collected 40 raw results for validation\n",
      "\n",
      "============================================================\n",
      "Phase 1b.1: Source Validation\n",
      "============================================================\n",
      "  Processing 40 unique new sources\n",
      "  Validated: 39 sources\n",
      "  Rejected: 1 sources\n",
      "  Sample rejections:\n",
      "    - https://www.dbta.com/Authors/Stephanie-Simone-6842... : Tavily score too low (0.00 < 0.3)\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 1 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 7\n",
      "  Continuing to sprint 2.\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 2/3\n",
      "============================================================\n",
      "  [1/5] Economic & organizational considerations: TCO, ven...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] Governance & operating model: define policies, rol...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] Vendor contracting & procurement playbook: require...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] Pilot design & measurement plan: A/B test design, ...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] Vertical/regulatory mappings: sector‑specific cons...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 6676 chars, 40 sources\n",
      "  Collected 40 raw results for validation\n",
      "\n",
      "============================================================\n",
      "Phase 1b.1: Source Validation\n",
      "============================================================\n",
      "  Processing 40 unique new sources\n",
      "  Validated: 49 sources\n",
      "  Rejected: 30 sources\n",
      "  Sample rejections:\n",
      "    - https://www.dbta.com/Authors/Stephanie-Simone-6842... : Tavily score too low (0.00 < 0.3)\n",
      "    - https://www.weforum.org/stories/2025/01/reimaginin... : Tavily score too low (0.02 < 0.3)\n",
      "    - https://www.weforum.org/meetings/world-economic-fo... : Tavily score too low (0.01 < 0.3)\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 2 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 7\n",
      "  Continuing to sprint 3.\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 3/3\n",
      "============================================================\n",
      "  [1/5] Staffing & training roadmap: role definitions, hir...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] Incident cost modeling: build low/medium/high scen...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] Measurement & benchmark plan for failure modes: de...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] Vendor/legal comparison: assess SLAs, DPA/data res...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] Integration & migration scoping: estimate effort/c...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 5441 chars, 27 sources\n",
      "  Collected 27 raw results for validation\n",
      "\n",
      "============================================================\n",
      "Phase 1b.1: Source Validation\n",
      "============================================================\n",
      "  Processing 54 unique new sources\n",
      "  Validated: 60 sources\n",
      "  Rejected: 43 sources\n",
      "  Sample rejections:\n",
      "    - https://www.dbta.com/Authors/Stephanie-Simone-6842... : Tavily score too low (0.00 < 0.3)\n",
      "    - https://www.weforum.org/stories/2025/01/reimaginin... : Tavily score too low (0.02 < 0.3)\n",
      "    - https://www.weforum.org/meetings/world-economic-fo... : Tavily score too low (0.01 < 0.3)\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 3 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 6\n",
      "  Max sprints reached. Moving to Quality Gate 1.\n",
      "\n",
      "============================================================\n",
      "Quality Gate 1: Source Sufficiency\n",
      "============================================================\n",
      "  Unique sources: 103 (min: 15)\n",
      "  Unique domains: 86 (min: 5)\n",
      "  Gate 1 PASSED\n",
      "\n",
      "============================================================\n",
      "Phase 1d: Compressing Research Brief\n",
      "============================================================\n",
      "  Compressed to 4091 chars\n",
      "\n",
      "============================================================\n",
      "Phase 1e: Audience Analysis\n",
      "============================================================\n",
      "  Audience: Executives/decision-makers\n",
      "  Methodology weight: 0.2\n",
      "  Recommendation style: prescriptive\n",
      "\n",
      "============================================================\n",
      "Phase 2: Skeleton Generation\n",
      "============================================================\n",
      "  Audience: Executives/decision-makers, Methodology weight: 0.2\n",
      "  Thesis: Large language models can deliver substantial enterprise productivity and custom...\n",
      "  Sections: 7\n",
      "  Valid: True\n",
      "\n",
      "============================================================\n",
      "Phase 3: Node Expansion\n",
      "============================================================\n",
      "  Audience: Executives/decision-makers\n",
      "  [1/7] sec:exec_summary: Executive Summary\n",
      "      Generated 2112 chars, 6 claims\n",
      "  [2/7] sec:background: Background and Essential Context\n",
      "      Generated 1518 chars, 4 claims\n",
      "  [3/7] sec:business_value_and_metrics: Business Value, Reported Gains, and Measurement\n",
      "      Generated 3288 chars, 7 claims\n",
      "  [4/7] sec:risks_and_mitigations: Safety, Privacy, and Security Failure Modes and Effective Controls\n",
      "      Generated 3170 chars, 6 claims\n",
      "  [5/7] sec:operational_scaling_and_tco: Operational Scaling, Architecture Choices, and Total Cost of Ownership\n",
      "      Generated 3338 chars, 5 claims\n",
      "  [6/7] sec:synthesis: Synthesis and Strategic Discussion\n",
      "      Generated 2352 chars, 4 claims\n",
      "  [7/7] sec:recommendations: Recommendations and Executive Next‑Steps\n",
      "      Generated 2321 chars, 4 claims\n",
      "  Total claims extracted: 36\n",
      "\n",
      "============================================================\n",
      "Phase 3b: Claims Verification\n",
      "============================================================\n",
      "  Verifying 20 claims with citations\n",
      "  Verified: 0/0 claims supported\n",
      "  Claims needing revision: 20\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Critique (Iteration 0)\n",
      "============================================================\n",
      "  Audience: Executives/decision-makers\n",
      "  Quality Score: 0.0/10\n",
      "  Issues: 0\n",
      "  Nodes to patch: 0\n",
      "\n",
      "--- Quality Gate 2 ---\n",
      "  Iteration: 0/2\n",
      "  Score: 0.0/7.5\n",
      "  No issues. Finalizing.\n",
      "\n",
      "============================================================\n",
      "Phase 5a: Executive Summary Generation\n",
      "============================================================\n",
      "  Generated executive summary: 1486 chars\n",
      "  Key takeaways: 4\n",
      "\n",
      "============================================================\n",
      "Phase 5b: Decision Framework Generation\n",
      "============================================================\n",
      "  Generated decision framework: 4747 chars\n",
      "  Primary recommendations: 3\n",
      "\n",
      "============================================================\n",
      "Phase 5c: Confidence Assessment\n",
      "============================================================\n",
      "  Assessed 7 conclusions\n",
      "  Overall confidence: Medium\n",
      "\n",
      "============================================================\n",
      "Phase 5d: Final Assembly\n",
      "============================================================\n",
      "  Document: 30060 chars (3580 words)\n",
      "  Sections: 7\n",
      "  Quality: 0.0\n",
      "  Sources: 60 validated / 103 total\n",
      "  Has executive summary: True\n",
      "  Has decision framework: True\n",
      "  Cache: Total: 15 queries, 0 avoided (0.0% hit rate), 144 chunks cached\n",
      "\n",
      "================================================================================\n",
      "FINAL REPORT\n",
      "================================================================================\n",
      "# Research Report\n",
      "\n",
      "**Research Question:** What are the key benefits and challenges of using large language models in enterprise applications?\n",
      "\n",
      "**Thesis:** Large language models can deliver substantial enterprise productivity and customer‑experience gains, but realizing and validating that value requires rigorous risk controls, governance, and TCO-aware operational practices to mitigate safety, privacy, and compliance gaps before scale.\n",
      "\n",
      "---\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "**Main Finding:** Large language models can deliver substantial enterprise productivity and customer‑experience improvements, but realizing net ROI requires disciplined, KPI‑driven pilots plus robust governance, risk controls, and TCO‑aware operational practices to mitigate safety, privacy, and compliance gaps before scaling.\n",
      "\n",
      "**Key Takeaways:**\n",
      "- LLMs can generate significant productivity and CX gains across knowledge work and front‑line interactions, but validated business value depends on KPI‑driven A/B pilots and full TCO accounting. (Confidence: High)\n",
      "- Critical failure modes—hallucinations, privacy leaks, prompt injection, bias, poisoning, theft, and shadow use—pose material operational and regulatory risk if left uncontrolled. (Confidence: High)\n",
      "- Pragmatic defenses—runtime guardrails, retrieval‑augmented generation with provenance, human‑in‑the‑loop review, red‑teaming, strong access controls, and contractual DPAs—are necessary to contain risk before scaling. (Confidence: High)\n",
      "- Enterprise scaling demands explicit hybrid deployment decisions and investment in model‑ops, telemetry, and TCO budgeting (compute, integration, security, and recurring vendor fees) to balance latency, cost, and control. (Confidence: Medium)\n",
      "\n",
      "**Bottom Line:** Execute short, KPI‑driven pilots with procurement, governance, hybrid architecture, RAG grounding, HITL, and telemetry to validate ROI and contain safety, privacy, and compliance risks before scaling.\n",
      "\n",
      "---\n",
      "\n",
      "## At a Glance\n",
      "\n",
      "- **Sources Analyzed:** 103\n",
      "- **Validated Sources:** 60\n",
      "- **Quality Score:** 0.0/10\n",
      "- **Overall Confidence:** Medium\n",
      "\n",
      "---\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Large language models (LLMs) — neural-network systems trained on massive text corpora to generate and interpret natural language — can deliver material productivity and customer-experience gains, but those upside claims depend on guarded, instrumented deployments that control safety, privacy, and compliance risk.\n",
      "\n",
      "Enterprise pilots and vendor case write-ups report sizable operational wins: roughly a 40% reduction in content-creation time, “60% faster” document processing in marketing/knowledge workflows, and continuous multilingual support that reduces manual staffing for 24/7 coverage (reported by multiple vendor case studies).\n",
      "\n",
      "Total cost of ownership (TCO) extends beyond license fees: material drivers include inference compute (cloud or on‑prem), integration and engineering, monitoring and fine‑tuning, security/compliance tooling, vendor support, and staff retraining; hidden recurring costs commonly surface during scale-up.\n",
      "\n",
      "Primary failure modes are factual: hallucinations (confident but incorrect outputs), toxic or biased language, prompt injection, PII/data leakage, data‑poisoning and model‑theft risks, and shadow (unsanctioned) usage. Frequency and impact vary by use case; high‑risk workflows require different controls than low‑risk chat assistants.\n",
      "\n",
      "Mitigations that materially reduce residual risk include runtime guardrails (input validation, PII detectors, output filters), retrieval‑augmented generation (RAG) to ground responses with provenance, red‑teaming and prompt‑injection simulations, human‑in‑the‑loop for high‑risk outputs, strict access controls, and CI/CD/MLOps risk gates with continuous telemetry.\n",
      "\n",
      "Governance and procurement must be decision‑critical: require policy‑as‑code, named accountable owners, immutable audit trails, three decision zones (autonomous, human‑approval, immediate escalation), and contract clauses for DPAs, audit rights, data‑resid...\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "Report length: 30060 characters\n",
      "Research sprints: 3\n",
      "Refinement iterations: 0\n",
      "Quality scores: [0.0]\n",
      "Unique sources: 103\n",
      "\n",
      "Cache Performance:\n",
      "  Total queries: 15\n",
      "  Cache hits: 0 (0.0%)\n",
      "  L1 hits: 0\n",
      "  L2 HIGH: 0\n",
      "\n",
      "Agent test PASSED\n"
     ]
    }
   ],
   "source": [
    "# Manual Test\n",
    "test_question = \"What are the key benefits and challenges of using large language models in enterprise applications?\"\n",
    "\n",
    "print(f\"Testing Combined Tier 1 Agent\")\n",
    "print(f\"Question: {test_question}\")\n",
    "print(\"\\nRunning combined architecture (this will take several minutes)...\\n\")\n",
    "\n",
    "try:\n",
    "    result = await combined_tier1_agent_async({\"question\": test_question})\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result[\"output\"][:4000] + \"...\" if len(result[\"output\"]) > 4000 else result[\"output\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Report length: {len(result['output'])} characters\")\n",
    "    print(f\"Research sprints: {result.get('research_sprints', 'N/A')}\")\n",
    "    print(f\"Refinement iterations: {result.get('refinement_iterations', 'N/A')}\")\n",
    "    print(f\"Quality scores: {result.get('quality_scores', [])}\")\n",
    "    print(f\"Unique sources: {len(result.get('source_urls', []))}\")\n",
    "    \n",
    "    stats = result.get(\"cache_stats\", {})\n",
    "    total = stats.get(\"total_queries\", 0)\n",
    "    avoided = stats.get(\"web_searches_avoided\", 0)\n",
    "    hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nCache Performance:\")\n",
    "    print(f\"  Total queries: {total}\")\n",
    "    print(f\"  Cache hits: {avoided} ({hit_rate:.1f}%)\")\n",
    "    print(f\"  L1 hits: {stats.get('l1_hits', 0)}\")\n",
    "    print(f\"  L2 HIGH: {stats.get('l2_high', 0)}\")\n",
    "    \n",
    "    print(\"\\nAgent test PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Agent test FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db5fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report\n",
       "\n",
       "**Research Question:** What are the key benefits and challenges of using large language models in enterprise applications?\n",
       "\n",
       "**Thesis:** Large language models can deliver substantial enterprise productivity and customer‑experience gains, but realizing and validating that value requires rigorous risk controls, governance, and TCO-aware operational practices to mitigate safety, privacy, and compliance gaps before scale.\n",
       "\n",
       "---\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "**Main Finding:** Large language models can deliver substantial enterprise productivity and customer‑experience improvements, but realizing net ROI requires disciplined, KPI‑driven pilots plus robust governance, risk controls, and TCO‑aware operational practices to mitigate safety, privacy, and compliance gaps before scaling.\n",
       "\n",
       "**Key Takeaways:**\n",
       "- LLMs can generate significant productivity and CX gains across knowledge work and front‑line interactions, but validated business value depends on KPI‑driven A/B pilots and full TCO accounting. (Confidence: High)\n",
       "- Critical failure modes—hallucinations, privacy leaks, prompt injection, bias, poisoning, theft, and shadow use—pose material operational and regulatory risk if left uncontrolled. (Confidence: High)\n",
       "- Pragmatic defenses—runtime guardrails, retrieval‑augmented generation with provenance, human‑in‑the‑loop review, red‑teaming, strong access controls, and contractual DPAs—are necessary to contain risk before scaling. (Confidence: High)\n",
       "- Enterprise scaling demands explicit hybrid deployment decisions and investment in model‑ops, telemetry, and TCO budgeting (compute, integration, security, and recurring vendor fees) to balance latency, cost, and control. (Confidence: Medium)\n",
       "\n",
       "**Bottom Line:** Execute short, KPI‑driven pilots with procurement, governance, hybrid architecture, RAG grounding, HITL, and telemetry to validate ROI and contain safety, privacy, and compliance risks before scaling.\n",
       "\n",
       "---\n",
       "\n",
       "## At a Glance\n",
       "\n",
       "- **Sources Analyzed:** 103\n",
       "- **Validated Sources:** 60\n",
       "- **Quality Score:** 0.0/10\n",
       "- **Overall Confidence:** Medium\n",
       "\n",
       "---\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "Large language models (LLMs) — neural-network systems trained on massive text corpora to generate and interpret natural language — can deliver material productivity and customer-experience gains, but those upside claims depend on guarded, instrumented deployments that control safety, privacy, and compliance risk.\n",
       "\n",
       "Enterprise pilots and vendor case write-ups report sizable operational wins: roughly a 40% reduction in content-creation time, “60% faster” document processing in marketing/knowledge workflows, and continuous multilingual support that reduces manual staffing for 24/7 coverage (reported by multiple vendor case studies).\n",
       "\n",
       "Total cost of ownership (TCO) extends beyond license fees: material drivers include inference compute (cloud or on‑prem), integration and engineering, monitoring and fine‑tuning, security/compliance tooling, vendor support, and staff retraining; hidden recurring costs commonly surface during scale-up.\n",
       "\n",
       "Primary failure modes are factual: hallucinations (confident but incorrect outputs), toxic or biased language, prompt injection, PII/data leakage, data‑poisoning and model‑theft risks, and shadow (unsanctioned) usage. Frequency and impact vary by use case; high‑risk workflows require different controls than low‑risk chat assistants.\n",
       "\n",
       "Mitigations that materially reduce residual risk include runtime guardrails (input validation, PII detectors, output filters), retrieval‑augmented generation (RAG) to ground responses with provenance, red‑teaming and prompt‑injection simulations, human‑in‑the‑loop for high‑risk outputs, strict access controls, and CI/CD/MLOps risk gates with continuous telemetry.\n",
       "\n",
       "Governance and procurement must be decision‑critical: require policy‑as‑code, named accountable owners, immutable audit trails, three decision zones (autonomous, human‑approval, immediate escalation), and contract clauses for DPAs, audit rights, data‑residency and liability. Executives capture LLM value only when pilots are A/B‑instrumented against business KPIs and model‑risk metrics, and when TCO and compliance tradeoffs inform vendor selection and scale plans.\n",
       "\n",
       "## Background and Essential Context\n",
       "\n",
       "A large language model (LLM) is a type of neural network trained on very large text corpora to predict and generate natural language; in enterprise terms LLMs are used as APIs or embedded services for summarization, question‑answering, content generation, search augmentation and conversational agents. (Definition and limitations discussed in a major LLM technical report.) (Source: https://cdn.openai.com/papers/gpt-4.pdf)\n",
       "\n",
       "Regulatory constraints focus on personal and health data. The EU General Data Protection Regulation (GDPR) restricts processing of personal data and requires lawful basis, data‑processing agreements (DPAs) and data‑protection measures including minimization and audit rights. U.S. HIPAA rules limit use of protected health information and require safeguards, breach notification, and business‑associate agreements for third‑party processors. (Sources: GDPR text; HHS HIPAA guidance.) (Source: https://eur-lex.europa.eu/eli/reg/2016/679/oj) (Source: https://www.hhs.gov/hipaa/index.html)\n",
       "\n",
       "Practical validation relies on business KPIs and TCO-aware measures. Recommended KPIs include FTE hours per task, cycle time, cost per transaction, accuracy/error rate, CSAT/NPS, time‑to‑market and revenue lift; compute and integration costs (inference, fine‑tuning, monitoring, security and change management) must be included in ROI calculations. Controlled pilots or A/B experiments with both business and model‑risk telemetry are the pragmatic way to validate claims (analysis, not a primary source).\n",
       "\n",
       "## Business Value, Reported Gains, and Measurement\n",
       "\n",
       "Vendors and case write‑ups report large, concentrated productivity gains from LLMs in content and document workflows: multiple vendor case studies cite roughly a 40% reduction in content‑creation time and “60% faster” document processing in marketing and knowledge‑management pipelines, plus continuous multilingual support that reduces live‑agent load (Source: https://www.assemblyai.com/, https://www.notyouridea.com/, https://www.webtrack.io/). These claims should be treated as vendor‑reported outcomes requiring independent validation.\n",
       "\n",
       "Value from LLMs materializes in three measurable streams: reduced labor (FTE hours saved), accelerated time‑to‑market (faster product/content cycles), and improved customer experience (CSAT/NPS gains). Concrete revenue lift often follows when faster cycles enable earlier launches or higher personalization, but revenue impact is use‑case dependent and requires attribution design rather than simple before/after comparisons (Source: https://www.crispidea.com/, https://www.terralogic.com/).\n",
       "\n",
       "Recommended KPIs for validating ROI include: FTE hours per task, cycle time (seconds/minutes/days), cost per transaction, CSAT/NPS, accuracy/error rate (false positives/negatives), incidence of PII leakage, and revenue per cohort. Define ROI here as return on investment: saved labor + value of speed‑to‑market − recurring inference and engineering costs. Use both business KPIs and model‑risk KPIs to avoid falsely optimistic automation gains (Analysis; benchmarking recommendations: https://www.trootech.com/, https://www.crispidea.com/).\n",
       "\n",
       "Run controlled pilots (A/B tests) that randomize traffic or users between the LLM automation arm and a control arm; instrument both sides for the full KPI set and log model‑risk events (hallucinations, PII leaks, error rates). A pragmatic pilot cadence is a short discovery (2–4 weeks) to tune prompts and guardrails, followed by a measurement window (4–8 weeks) for statistically meaningful signal; expected sample sizes depend on baseline event rates and detectable lift (analysis informed by industry practice: https://www.crispidea.com/).\n",
       "\n",
       "Include Total Cost of Ownership (TCO) in ROI calculations: license/acquisition, compute (inference and training), integration, security/compliance, monitoring, fine‑tuning, vendor support, and change management/retraining. Hidden recurring costs (per‑query billing, unanticipated engineering for provenance and monitoring) commonly erode headline savings unless budgeted up front (Source: https://www.pactly.com/, https://www.atlassystems.com/).\n",
       "\n",
       "Sample pilot KPIs and measurement cadence: weekly FTE hours saved; cycle time median and 90th percentile; cost per transaction and inference cost per 1,000 queries; CSAT delta measured after a two‑week acclimation window; error/hallucination rate per 1,000 outputs; PII leakage incidents (count). Pair quantitative KPIs with qualitative reviews (human‑in‑the‑loop assessments) to validate unseen failure modes (Source: https://coralogix.com/, https://www.fairnow.ai/).\n",
       "\n",
       "Concrete conclusion: vendor case studies show large potential productivity and CX gains, but validated ROI requires KPI‑driven A/B pilots that instrument both business outcomes and model‑risk metrics and that include full TCO accounting before scale.\n",
       "\n",
       "## Safety, Privacy, and Security Failure Modes and Effective Controls\n",
       "\n",
       "Primary failure modes for large language models (LLMs) include hallucinations (confident-sounding but incorrect or fabricated outputs), prompt injection (malicious inputs that coerce model behavior), personally identifiable information (PII) leakage, biased or toxic outputs, data poisoning (malicious training data), model extraction/theft, and shadow use (unsanctioned employee workflows). Define: Retrieval-Augmented Generation (RAG) is a technique that combines an LLM with an external document retriever to ground responses; Human-in-the-Loop (HITL) refers to human review or approval in the model decision path.\n",
       "\n",
       "Hallucinations are common and high‑impact where factual accuracy matters: even low-frequency errors can cause regulatory, financial, or reputational damage because LLMs present mistakes confidently. The likelihood of hallucination depends on prompt specificity, domain grounding, and retriever quality; mission‑critical use cases (legal, clinical, financial) require near-zero tolerance for silent errors.\n",
       "\n",
       "PII leakage and regulatory constraints produce hard limits on model selection and deployment. Data protection regimes such as GDPR and health privacy laws such as HIPAA restrict sending personal or health data to third‑party inference services without explicit safeguards and contractual terms (Source: https://gdpr.eu/, https://www.hhs.gov/hipaa/).\n",
       "\n",
       "Prompt injection — where user inputs or retrieved documents manipulate model prompts — is an active attack vector that has been systematically documented and mitigated in industry guidance. Effective technical controls include input sanitation, context‑length management, and runtime policy filters that detect and neutralize malicious instructions (Source: https://owasp.org/www-project-llm-security/).\n",
       "\n",
       "RAG with provenance (returning source citations and confidence scores) measurably reduces hallucination risk in knowledge tasks by anchoring assertions to retrievable documents; practitioners should instrument retrieval precision and citation fidelity as model‑risk metrics (Source: https://arxiv.org/abs/2005.11401). High‑risk outputs should flow to HITL review workflows with clear SLAs for human verification (analysis supported by NIST guidance on AI risk management) (Source: https://www.nist.gov/ai/nist-artificial-intelligence-risk-management-framework).\n",
       "\n",
       "Model extraction and data‑poisoning attacks threaten IP and training data confidentiality. Published demonstrations show model‑extraction techniques can recover model behavior from API access; mitigations include rate limiting, query auditing, anomaly detection, and cryptographic protections on training data (Source: https://arxiv.org/abs/1609.02943).\n",
       "\n",
       "Operationalizing these controls requires layered defenses: runtime guardrails (PII detectors, output filters), red‑teaming and prompt‑injection simulations, provenance‑based RAG, HITL for high‑risk flows, strict access controls and audit trails, and contract clauses (DPAs, audit rights) for third‑party models. When combined and instrumented into pilots and CI/CD gates, these controls materially reduce enterprise exposure while preserving measurable business upside.\n",
       "\n",
       "\n",
       "## Operational Scaling, Architecture Choices, and Total Cost of Ownership\n",
       "\n",
       "Inference (model runtime compute per query) is the recurring cost driver for production LLMs: high QPS (queries per second) workloads translate directly into cloud GPU/CPU expenditure and can dwarf one‑time integration or license fees. Plan capacity by measuring expected QPS, average token length, and acceptable tail latency; use per‑query cost estimates to forecast monthly spend as part of an ROI model.\n",
       "\n",
       "Latency must be balanced against throughput. Techniques that reduce cost often increase latency (batching, cold‑start consolidation), while low‑latency designs use reserved instances, smaller distilled models, or edge proxies. Quantization (reducing numeric precision to compress model weights) and distillation (training a smaller model to mimic a larger one) lower compute costs but can increase error rates; measure task‑level accuracy after any compression.\n",
       "\n",
       "Model versioning and MLOps requirements are operational constraints, not optional features. A model registry with immutability, artifact hashing, and deployment manifests supports reproducible rollbacks. Define continuous evaluation gates that test for hallucination rates, top‑k token distributions, latency, and cost‑per‑query before promoting a model to production to prevent silent regressions.\n",
       "\n",
       "Hybrid deployment (mixing cloud and on‑prem) is the principal architecture pattern for regulated workloads: sensitive or resident‑restricted data stays on‑premise while non‑sensitive inference and heavy fine‑tuning run in cloud capacity. GDPR (the EU data protection regulation) and HIPAA (US health privacy rules) impose residency, consent, and security obligations that materially affect where models and logs can run and be stored (Source: https://eur-lex.europa.eu/eli/reg/2016/679/oj; Source: https://www.hhs.gov/hipaa/index.html).\n",
       "\n",
       "Vendor convenience can mask recurring hidden costs: egress fees, higher per‑token charges at scale, premium support tiers, charged access to audit logs, and incremental fees for fine‑tuning or private deployment images. Budget contractual concessions (audit rights, DPA clauses, data‑residency guarantees) and model exportability clauses to avoid vendor lock‑in.\n",
       "\n",
       "Recommended TCO categories to budget and measure: licensing/acquisition, inference compute (reserved vs on‑demand), training/fine‑tuning, storage and backups, networking/egress, integration and engineering, security/compliance controls, monitoring/observability, and change management/personnel retraining. Track metrics such as cost per successful transaction, cost per automated FTE‑hour saved, and time‑to‑recovery after model regression.\n",
       "\n",
       "Operational controls to contain risk at scale include telemetry for input/output provenance (the source of retrieved context), anomaly detection on model outputs, prompt‑injection fuzzing in CI, and human‑in‑the‑loop approval flows for high‑risk categories. Treat provenance (the traceable source of returned evidence) as a first‑class telemetry item for audits and dispute resolution.\n",
       "\n",
       "Conclusion: Operational scaling requires explicit tradeoffs among latency, cost, and control—reserve cloud GPUs where throughput and innovation matter, keep sensitive inference on‑prem, instrument every production call for provenance and drift, and budget full TCO categories so ROI calculations reflect both visible and hidden costs.\n",
       "\n",
       "## Synthesis and Strategic Discussion\n",
       "\n",
       "Enterprises face a central tension: large language models (LLMs) can unlock rapid productivity and customer‑experience gains, yet they also produce silent, confident errors known as hallucinations (an output that is plausible but false). Evidence of systemic truthfulness failures has been documented in model evaluations, underscoring the need to treat LLM outputs as probabilistic artifacts rather than authoritative facts (Source: https://arxiv.org/abs/2109.07958).\n",
       "\n",
       "Choosing vendor‑managed convenience reduces engineering overhead and time‑to‑value but increases exposure to data‑control and compliance risks. Regulatory regimes such as the EU General Data Protection Regulation (GDPR) and U.S. HIPAA set limits on how personal and health data may be processed by third parties, creating hard boundaries for using hosted models with sensitive data (Source: https://eur-lex.europa.eu/eli/reg/2016/679/oj; Source: https://www.hhs.gov/hipaa/for-professionals/privacy/index.html).\n",
       "\n",
       "Claims of large productivity lifts in vendor case studies coexist with widespread operational and governance gaps. Analytical reconciliation: these case studies are conditional — realized ROI depends on rigorous, KPI‑driven pilots that measure both business outcomes (FTE hours, cycle time, CSAT) and model‑risk metrics (error rate, provenance coverage) before committing to scale. This is an analysis recommendation, not a primary-source claim.\n",
       "\n",
       "Mitigating the tension requires a composite controls package: retrieval‑augmented generation (RAG) with provenance to ground outputs, human‑in‑the‑loop (HITL) for high‑risk decisions, runtime input/output guardrails, red‑teaming including prompt‑injection tests, and strict access and audit controls. RAG (retrieval‑augmented generation) has been proposed and studied as a method to reduce hallucination by combining retrieval and generation (Source: https://arxiv.org/abs/2005.11401).\n",
       "\n",
       "Strategic choice is therefore tradeoff management: accept some vendor convenience only when contracts, telemetry, and TCO models preserve auditability and residual risk budgets; opt for hybrid or on‑prem deployments where regulatory or IP risk is material. The established conclusion: LLMs can deliver outsized business value, but realizing that value requires explicit, measurable risk controls and TCO‑aware governance before scaling.\n",
       "\n",
       "## Recommendations and Executive Next‑Steps\n",
       "\n",
       "Start one or two targeted pilots with clear success thresholds: controlled A/B tests that compare business KPIs (FTE hours per task, cycle time, cost per transaction, CSAT/NPS, revenue lift) and model‑risk metrics (error rate, hallucination incidents, PII exposures). Design pilots for 6–12 weeks and route 5–15% of live traffic or a statistically powered sample; require a pre‑registered analysis plan and a go/no‑go decision tied to ROI and safety gates.\n",
       "\n",
       "Embed procurement and governance guardrails before any production rollout. Require a Data Processing Agreement (DPA) with audit rights and data‑residency clauses (Source: https://gdpr.eu/). Assign a named accountable owner and codify policies as policy‑as‑code with three decision zones: autonomous, human approval, immediate escalation.\n",
       "\n",
       "Choose a hybrid technology stack for sensitive workloads: on‑prem or private cloud for regulated data and cloud‑hosted models for low‑risk tasks. Use Retrieval‑Augmented Generation (RAG) — retrieval of external documents to ground model outputs — to reduce hallucinations (Source: https://arxiv.org/abs/2005.11401). Capture provenance (living citations) for every generated answer.\n",
       "\n",
       "Staff the program with a small cross‑functional core: 1 AI product lead, 2 ML engineers, 1 MLOps/infra engineer, 1 security/compliance lead, and fractional legal support. Budget TCO across licensing, inference compute, integration, monitoring, and change management; expect a 3–6 month iterative validation phase before scale.\n",
       "\n",
       "Operationalize risk controls: runtime guardrails (input validation, PII detectors, output filters), human‑in‑the‑loop (HITL — human review for high‑risk outputs), red‑teaming and CI/CD risk gates tied to telemetry and immutable audit logs. Track hallucination and safety incidents as operational KPIs (analysis: LLMs commonly produce confident falsehoods; see TruthfulQA) (Source: https://arxiv.org/abs/2109.07958).\n",
       "\n",
       "Immediate executive next steps: select a single high‑value pilot, define success KPIs and sample plan, sign the DPA and procurement guardrails, allocate the cross‑functional team and a 6–12 week budget, and require a documented go/no‑go decision that accounts for both ROI and safety metrics. This establishes an executable validation path that balances business upside with enforceable controls.\n",
       "\n",
       "---\n",
       "\n",
       "## Recommendations\n",
       "\n",
       "### Primary Recommendations\n",
       "\n",
       "**1. Run short, KPI-driven pilots with instrumentation: design A/B or randomized pilots (6–12 weeks) that measure business KPIs (productivity, handle time, NPS, cost per transaction) and model-risk metrics (hallucination rate, sensitive-data exposures) and include full TCO accounting.** (Priority: High)\n",
       "   - *Rationale:* Validated ROI and safe adoption require empirical measurement of both business impact and model risk; pilots limit exposure while producing decision-quality evidence.\n",
       "   - *Applies when:* Always applicable when evaluating LLM adoption or new LLM-driven features.\n",
       "\n",
       "**2. Establish model-risk governance and contractual controls: create an LLM-specific governance playbook (roles: exec sponsor, CISO, CPO, legal), require DPAs and SLAs from vendors, define audit rights, enforce access controls and red-teaming before production, and mandate runtime guardrails and HITL for high-risk outputs.** (Priority: High)\n",
       "   - *Rationale:* LLMs create safety, privacy, and compliance gaps (hallucinations, leaks, prompt injection); contractual and operational controls are necessary to contain these risks before scaling.\n",
       "   - *Applies when:* Always applicable for any production use of LLMs, especially when data protection regulations (GDPR/HIPAA) or sensitive data are involved.\n",
       "\n",
       "**3. Adopt a hybrid architecture and explicit TCO plan: decide deployment posture (cloud SaaS, hosted, or on-prem/managed) based on regulatory constraints; implement RAG with enterprise-controlled knowledge stores, model-ops telemetry, and budget for compute, integration, security, and recurring vendor fees.** (Priority: Medium)\n",
       "   - *Rationale:* Scaling LLMs requires balancing latency, cost, and control. Hybrid patterns and clear TCO prevent surprises and enable enterprise provenance and containment of model risk.\n",
       "   - *Applies when:* Applicable when moving from pilot to scaled deployment or when regulatory/data-residency requirements constrain vendor options.\n",
       "\n",
       "### Conditional Recommendations\n",
       "\n",
       "- **If** If handling regulated/sensitive data., **then** If you process regulated or sensitive data (PII, health, financial), then restrict model execution to private or on-prem environments or encrypted VPCs, require vendor DPAs, perform a DPIA, and store embeddings/knowledge bases in enterprise-controlled storage with strict IAM.\n",
       "  *(Data-protection laws (GDPR, HIPAA) and privacy risk make public SaaS use risky; enterprise-controlled storage and legal safeguards are necessary to meet compliance.)*\n",
       "\n",
       "- **If** If business value or error impact is uncertain., **then** If ROI is unclear or model errors materially affect outcomes, then run a statistically powered A/B pilot (6–12 weeks) with pre-defined success thresholds and rollback criteria, include HITL for verification of outputs, and track both business KPIs and model-risk metrics daily/weekly.\n",
       "  *(Validated, KPI-driven pilots with HITL and rollback limits ensure decisions are based on measurable benefit and prevent silent-error propagation into production.)*\n",
       "\n",
       "- **If** If leadership prefers SaaS but compliance/control needs exist., **then** If your organization favors vendor convenience (pure SaaS) but requires control, then negotiate hybrid controls: encrypted data-in-transit, contractual audit and deletion rights, API-level access controls, and push provenance and retrieval (RAG) into enterprise-managed components.\n",
       "  *(This preserves the speed of SaaS while retaining critical control points to reduce leakage and enable audits.)*\n",
       "\n",
       "- **If** If hallucinations or data-exposure incidents occur., **then** If hallucinations or data leaks are observed in pilots, then deploy pragmatic defenses: RAG with provenance and citation, runtime guardrails that block/flag low-confidence outputs, automated input/output logging, red-team tests, and escalate to legal/security for any leakage incident.\n",
       "  *(Hallucinations and leaks are frequent LLM failure modes; layered defenses plus incident escalation limit damage and produce forensic records for compliance.)*\n",
       "\n",
       "### What to Monitor\n",
       "\n",
       "- Business KPI delta versus control (productivity lift %, handle-time reduction, NPS/customer satisfaction changes) — primary measure of value.\n",
       "- Model-risk metrics: hallucination/error rate per 1,000 responses, number of sensitive-data exposures or red-team-identified vulnerabilities.\n",
       "- Usage and access telemetry: API call volumes, unusual query patterns, shadow-use detection, number of privileged model accesses.\n",
       "- Cost indicators: compute spend per request, latency SLAs missed, vendor recurring fees vs forecasted TCO.\n",
       "- Compliance/audit signals: DPA exceptions, regulator inquiries, internal audit findings, and incident response activations.\n",
       "\n",
       "---\n",
       "\n",
       "## Confidence Assessment\n",
       "\n",
       "| Conclusion | Confidence | Evidence Quality | Key Uncertainty |\n",
       "|------------|------------|------------------|------------------|\n",
       "| [Executive Summary]: LLMs can produce large produc... | Medium | moderate | Many supporting sources are ve... |\n",
       "| [Background and Essential Context]: LLMs are proba... | High | strong | Regulatory interpretation and ... |\n",
       "| [Business Value, Reported Gains, and Measurement]:... | Medium | moderate | Vendor case studies are prone ... |\n",
       "| [Safety, Privacy, and Security Failure Modes and E... | High | strong | New attack vectors and model b... |\n",
       "| [Operational Scaling, Architecture Choices, and To... | Medium | moderate | TCO depends heavily on workloa... |\n",
       "\n",
       "---\n",
       "\n",
       "## Limitations and Uncertainties\n",
       "\n",
       "Evidence set includes many vendor case studies and short pilots; only 60 of 103 sources were validated. There is limited long-term, independent, cross‑sector quantitative evidence on ROI and defense effectiveness at scale. Regulatory interpretations and attacker techniques are evolving, which may alter risk profiles and recommended controls.\n",
       "\n",
       "---\n",
       "\n",
       "## References\n",
       "\n",
       "1. [How Large Language Models Will Benefit Businesses in ...](https://webtracktechnologies.com/llm-business-benefits-2026/)\n",
       "2. [AI Applications in Business 2026: Trends, Opportunities & ...](https://terralogic.com/ai-applications-in-business-trends-opportunities-challenges-2026/)\n",
       "3. [Large Language Models in 2026: Strategy, Use Cases & ...](https://www.crispidea.com/large-language-models-in-2026/?srsltid=AfmBOorMeBxoXFr9NVsL7qlw2TKFFyAtPkV45roE43EwGvfOG-GhdmCG)\n",
       "4. [9 LLM enterprise applications advancements in 2026 for ...](https://lumenalta.com/insights/9-llm-enterprise-applications-advancements-in-2026-for-cios-and-ctos)\n",
       "5. [7 LLM use cases and applications in 2026](https://www.assemblyai.com/blog/llm-use-cases)\n",
       "6. [10 Benefits Of Using Large Language Models (LLMs) For ...](https://notyouridea.com/blog/benefits-of-using-large-language-models-for-business)\n",
       "7. [Generative AI for Data-Driven Decision Making](https://www.techment.com/how-generative-ai-is-transforming-data-driven-decision-making-in-2025/)\n",
       "8. [AI Development Cost in 2026: Enterprise Budgeting & ROI ...](https://www.trootech.com/blog/ai-use-cases-in-real-world)\n",
       "9. [An Executive's Guide to the Risks of Large Language Models (LLMs)](https://fairnow.ai/executives-guide-risks-of-llms/)\n",
       "10. [The Security Risks of Using LLMs in Enterprise Applications](https://coralogix.com/ai-blog/the-security-risks-of-using-llms-in-enterprise-applications/)\n",
       "11. [LLM Risks: Enterprise Threats and How to Secure Them](https://www.lasso.security/blog/llm-risks-enterprise-threats)\n",
       "12. [AI guardrails: the complete guide for LLMs in January 2026](https://www.openlayer.com/blog/post/ai-guardrails-llm-guide)\n",
       "13. [The 4 Ways LLMs Fail - LinkedIn](https://www.linkedin.com/pulse/4-ways-llms-fail-josh-clemm-cln7c)\n",
       "14. [What Are LLM Security Risks? And How to Mitigate Them](https://www.sentinelone.com/cybersecurity-101/data-and-ai/llm-security-risks/)\n",
       "15. [OWASP Top 10 Risk & Mitigations for LLMs and Gen AI Apps 2025](https://securityboulevard.com/2024/12/owasp-top-10-risk-mitigations-for-llms-and-gen-ai-apps-2025/)\n",
       "16. [Enterprise LLM Security: Risks, Frameworks, & Best Practices](https://www.superblocks.com/blog/enterprise-llm-security)\n",
       "17. [2026 Data Privacy Forecast](https://www.uslegalsupport.com/blog/data-privacy-in-litigation-support-2026/)\n",
       "18. [GDPR HIPAA SOX Compliance requirements for Enterprises](https://www.ceiamerica.com/compliance-requirements-guide/)\n",
       "19. [Data Security and Privacy Clauses: 2026's Detailed Guide](https://www.sirion.ai/de/library/contract-clauses/data-security-and-privacy-clauses/data-security-and-privacy-clauses/?source=blogpagedpbanner&src%3Dcareers%26p%3DeyJwYWdlVHlwZSI6ImpkIiwiY3ZTb3VyY2UiOiJjYXJlZXJzIiwicmVxSWQiOjcxOCwicmVxdWVzdGVyIjp7ImlkIjoiIiwiY29kZSI6IiIsIm5hbWUiOiIifSwicGFnZSI6ImNhcmVlcnMiLCJidWZpbHRlciI6LTEsImN1c3RvbUZpZWxkcyI6e319)\n",
       "20. [What Is Data Compliance? A Complete Guide for ...](https://controld.com/blog/what-is-data-compliance/)\n",
       "21. [Large Language Models (LLM) GDPR Compliance](https://gdprlocal.com/large-language-models-llm-gdpr/)\n",
       "22. [Advancing Compliance with HIPAA and GDPR in Healthcare](https://pmc.ncbi.nlm.nih.gov/articles/PMC12563691/)\n",
       "23. [The 2026 Privacy Law And Compliance State Of Play](https://richtfirm.com/the-2026-privacy-law-and-compliance-state-of-play-navigating-an-increasingly-complex-regulatory-landscape/)\n",
       "24. [Private LLMs Development: The Complete Guide](https://aiveda.io/blog/private-llms-development-the-complete-guide)\n",
       "25. [LLMs in Enterprise Systems: Architecture Patterns and Pitfalls](https://codestreamlab.com/blog/llms-in-enterprise-systems-architecture-patterns-and-pitfalls/)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727ed61",
   "metadata": {},
   "source": [
    "## 12. Evaluation Harness Integration\n",
    "\n",
    "Once the manual test passes, run full evaluation on all 20 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c854a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation harness\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from evaluation import (\n",
    "    ExperimentHarness,\n",
    "    fact_recall,\n",
    "    citation_precision,\n",
    "    coherence_judge,\n",
    "    depth_judge,\n",
    "    relevance_judge,\n",
    "    minimum_sources_check\n",
    ")\n",
    "\n",
    "harness = ExperimentHarness(\n",
    "    dataset_path=\"../data/deep_research_agent_test_dataset.yaml\",\n",
    "    langsmith_dataset_name=\"deep-research-golden-v2\"\n",
    ")\n",
    "\n",
    "print(\"Evaluation harness initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d534dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Evaluation - UNCOMMENT TO RUN\n",
    "# WARNING: This is expensive and takes 2-3 hours\n",
    "\n",
    "# evaluators = [\n",
    "#     fact_recall,\n",
    "#     citation_precision,\n",
    "#     minimum_sources_check,\n",
    "#     coherence_judge,\n",
    "#     depth_judge,\n",
    "#     relevance_judge,\n",
    "# ]\n",
    "# \n",
    "# print(\"Starting FULL evaluation on all 20 questions...\")\n",
    "# print(\"Combined Tier 1 Agent - estimated 2-3 hours\")\n",
    "# print(\"=\" * 80 + \"\\n\")\n",
    "# \n",
    "# results = harness.run_evaluation(\n",
    "#     agent_fn=combined_tier1_agent,\n",
    "#     evaluators=evaluators,\n",
    "#     experiment_name=\"combined_tier1_v1\",\n",
    "#     monte_carlo_runs=1,\n",
    "#     max_concurrency=2,\n",
    "#     description=\"Combined Tier 1 paradigms evaluation\"\n",
    "# )\n",
    "# \n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"FULL EVALUATION RESULTS\")\n",
    "# print(\"=\" * 80)\n",
    "# print(f\"Experiment: {results.experiment_name}\")\n",
    "# print(f\"Questions: {results.num_questions}\")\n",
    "# \n",
    "# print(f\"\\n{'Metric':<30} {'Mean':<10}\")\n",
    "# print(\"-\" * 40)\n",
    "# for metric in sorted(results.metrics.keys()):\n",
    "#     if not metric.endswith('_std'):\n",
    "#         print(f\"{metric:<30} {results.metrics[metric]:<10.3f}\")\n",
    "\n",
    "print(\"Full evaluation cell ready. Uncomment to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6799630",
   "metadata": {},
   "source": [
    "## Architecture Summary\n",
    "\n",
    "### Combined Paradigms\n",
    "\n",
    "This notebook unifies four Tier 1 paradigms:\n",
    "\n",
    "1. **Cascading Knowledge Cache** - Wraps ALL search operations\n",
    "   - Layer 1: Exact query match\n",
    "   - Layer 2: Semantic similarity\n",
    "   - Expected 30-50% cache hits by verification phase\n",
    "\n",
    "2. **Agile Sprints** - Research phase (Phase 1)\n",
    "   - Decompose question into backlog\n",
    "   - Sprint-based execution with retrospectives\n",
    "   - Dynamic re-prioritization\n",
    "\n",
    "3. **Iterative Refinement V2** - Document generation (Phases 2-4)\n",
    "   - Skeleton-based structure\n",
    "   - Per-node prose generation\n",
    "   - Patch-based refinement (not full regeneration)\n",
    "\n",
    "4. **Quality Gates** - Strategic checkpoints\n",
    "   - Gate 1: Source sufficiency after research\n",
    "   - Gate 2: Quality threshold for refinement exit\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "| Phase | Expected Cache Hits |\n",
    "|-------|---------------------|\n",
    "| Research Sprint 1 | 0% (cold cache) |\n",
    "| Research Sprint 2-3 | 10-25% |\n",
    "| Verification Sprint 1 | 30-40% |\n",
    "| Verification Sprint 2 | 40-60% |\n",
    "\n",
    "### Key Metrics to Track\n",
    "\n",
    "- Cache hit rate > 30%\n",
    "- Quality score >= 7.5\n",
    "- Report coherence and depth\n",
    "- Citation presence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d25c20",
   "metadata": {},
   "source": [
    "# Test Execution Section\n",
    "\n",
    "This section runs the 5-query test dataset against this notebook variant and saves outputs for comparison.\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "test_output/\n",
    "    question_1/\n",
    "        question_1_V08.md\n",
    "    question_2/\n",
    "        question_2_V08.md\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Instructions:**\n",
    "1. Run all cells above first to define the agent\n",
    "2. Run the cells below to execute tests\n",
    "3. Choose to run a single question or all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64939256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Setup and Configuration\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = Path('.').resolve()\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / 'test_output'\n",
    "DATASET_PATH = NOTEBOOK_DIR / 'test_dataset.yaml'\n",
    "\n",
    "# Notebook version (automatically set based on filename)\n",
    "CURRENT_VERSION = \"V08\"\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load test dataset\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    dataset = yaml.safe_load(f)\n",
    "\n",
    "questions = dataset.get('questions', [])\n",
    "\n",
    "# Create output directories for each question\n",
    "for i in range(1, len(questions) + 1):\n",
    "    question_dir = OUTPUT_DIR / f\"question_{i}\"\n",
    "    question_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Test Configuration:\")\n",
    "print(f\"  Version: {CURRENT_VERSION}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Loaded {len(questions)} test questions\")\n",
    "print(f\"\\nTest Questions:\")\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"  {i}. [{q['category']}] {q['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(question_num: int, version: str, result: dict, question_data: dict) -> Path:\n",
    "    \"\"\"Save the output to a markdown file.\"\"\"\n",
    "    output_dir = OUTPUT_DIR / f\"question_{question_num}\"\n",
    "    output_file = output_dir / f\"question_{question_num}_{version}.md\"\n",
    "    \n",
    "    question_text = question_data.get('question', '')\n",
    "    question_title = question_data.get('title', 'Untitled')\n",
    "    question_id = question_data.get('id', f'Q{question_num}')\n",
    "    \n",
    "    content = f\"\"\"# Question {question_num} - {version}\n",
    "\n",
    "                **Question ID:** {question_id}  \n",
    "                **Title:** {question_title}  \n",
    "                **Category:** {question_data.get('category', 'N/A')}  \n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Original Question\n",
    "\n",
    "                {question_text}\n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Research Report\n",
    "\n",
    "                {result.get('output', 'No output generated')}\n",
    "\n",
    "                \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0328bb3",
   "metadata": {},
   "source": [
    "## Run All Questions Test\n",
    "\n",
    "Run ALL 5 questions for comprehensive testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598db355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ALL questions for the current version\n",
    "\n",
    "print(f\"Running ALL {len(questions)} questions with {CURRENT_VERSION}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "results_summary = []\n",
    "overall_start = datetime.now()\n",
    "\n",
    "for i, question_data in enumerate(questions, 1):\n",
    "    question_text = question_data.get('question', '')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}/{len(questions)}: {question_data['title']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        result = await combined_tier1_agent_async({\"question\": question_text})\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        output_file = save_output(i, CURRENT_VERSION, result, question_data)\n",
    "        \n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": len(result.get('output', '')),\n",
    "            \"sources\": len(result.get('source_urls', [])),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Completed in {elapsed:.1f}s - {summary['output_chars']} chars, {summary['sources']} sources\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": 0,\n",
    "            \"sources\": 0,\n",
    "            \"status\": f\"error: {str(e)}\"\n",
    "        }\n",
    "        print(f\"FAILED: {e}\")\n",
    "    \n",
    "    results_summary.append(summary)\n",
    "\n",
    "# Save summary\n",
    "overall_elapsed = (datetime.now() - overall_start).total_seconds()\n",
    "\n",
    "summary_file = OUTPUT_DIR / f\"summary_{CURRENT_VERSION}.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"run_time\": datetime.now().isoformat(),\n",
    "        \"version\": CURRENT_VERSION,\n",
    "        \"total_elapsed_seconds\": overall_elapsed,\n",
    "        \"questions_tested\": len(questions),\n",
    "        \"results\": results_summary\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL TESTS COMPLETE for {CURRENT_VERSION}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total time: {overall_elapsed:.1f} seconds ({overall_elapsed/60:.1f} minutes)\")\n",
    "print(f\"Summary saved: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
