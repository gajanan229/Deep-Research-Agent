{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Tier 1: Skeleton-First Evidence Orchestration (SFEO) Research Agent\n",
    "\n",
    "This notebook implements the **Skeleton-First Evidence Orchestration (SFEO)** architecture, combining the validated Tier 1 paradigms:\n",
    "\n",
    "- **Iterative Refinement V2** (Patch-Based): Skeleton-driven document structure with semantic addressing\n",
    "- **Agile Sprints**: Sprint-based evidence gathering with retrospectives\n",
    "- **Knowledge Cache**: Cascading 3-layer cache for search optimization\n",
    "- **Quality Gates**: Multi-stage quality checkpoints preventing error propagation\n",
    "\n",
    "## Core Innovation\n",
    "\n",
    "Traditional deep research: `Question → Research → Synthesize → Write`\n",
    "\n",
    "SFEO inverts this: `Question → Hypothesize Structure → Research to Validate → Construct with Evidence → Refine Gaps`\n",
    "\n",
    "## The Three Laws of SFEO\n",
    "\n",
    "1. **Structure Precedes Content**: The document skeleton drives research, creating focused queries\n",
    "2. **Quality Gates Guard Transitions**: No phase proceeds until quality criteria are met\n",
    "3. **The Cache is Omnipresent**: Every search passes through the knowledge cache\n",
    "\n",
    "## Architecture Phases\n",
    "\n",
    "- **Phase A**: Strategic Planning (Query → Skeleton → Claims → Backlog) + Gate 1\n",
    "- **Phase B**: Evidence Gathering (Sprint Loop with Cache) + Gate 2\n",
    "- **Phase C**: Document Construction (Prose Patches → Bridges → Assembly) + Gate 3\n",
    "- **Phase D**: Refinement & Polish (Critique → Patch → Cascade → Final)\n",
    "\n",
    "## Technology Stack\n",
    "\n",
    "- **LLM**: `gpt-5-mini-2025-08-07`\n",
    "- **Web Search**: Tavily API\n",
    "- **Embeddings**: OpenAI text-embedding-3-small\n",
    "- **Tracing**: LangSmith\n",
    "- **Framework**: LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import asyncio\n",
    "import hashlib\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Annotated, TypedDict, Literal, Optional, Any\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "env_path = Path(\"../.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"deep_research_new\"\n",
    "\n",
    "print(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-5-mini-2025-08-07\n",
      "Sprint config: max 3 sprints, 4 claims/sprint\n",
      "Cache thresholds: HIGH >= 0.75, LOW < 0.4\n",
      "Refinement: max 2 iterations, quality target 7.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM, Tavily, and Embeddings\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0, max_retries=10)\n",
    "tavily_client = TavilyClient()\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE A: STRATEGIC PLANNING CONFIGURATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "SKELETON_CONFIG = {\n",
    "    \"min_sections\": 4,\n",
    "    \"max_sections\": 7,\n",
    "    \"target_words_per_section\": 300,\n",
    "    \"max_skeleton_refinement_attempts\": 2\n",
    "}\n",
    "\n",
    "GATE_1_CONFIG = {\n",
    "    \"thesis_clarity_threshold\": 7.0,\n",
    "    \"coverage_threshold\": 0.8,\n",
    "    \"structure_threshold\": 7.0,\n",
    "    \"max_attempts\": 2\n",
    "}\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE B: EVIDENCE GATHERING CONFIGURATION  \n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "SPRINT_CONFIG = {\n",
    "    \"max_sprints\": 3,\n",
    "    \"claims_per_sprint\": 4,\n",
    "    \"searches_per_claim\": 2,\n",
    "    \"min_sources_per_section\": 2\n",
    "}\n",
    "\n",
    "CACHE_CONFIG = {\n",
    "    \"high_confidence_threshold\": 0.75,\n",
    "    \"low_confidence_threshold\": 0.40,\n",
    "    \"specificity_adjustment\": 0.15,\n",
    "    \"chunk_size\": 500,\n",
    "    \"chunk_overlap\": 100,\n",
    "    \"top_k_retrieval\": 5\n",
    "}\n",
    "\n",
    "GATE_2_CONFIG = {\n",
    "    \"section_coverage_threshold\": 0.7,\n",
    "    \"min_domain_diversity\": 4,\n",
    "    \"verification_rate_threshold\": 0.6,\n",
    "    \"max_emergency_attempts\": 1\n",
    "}\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE C: DOCUMENT CONSTRUCTION CONFIGURATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "PROSE_CONFIG = {\n",
    "    \"min_words_per_section\": 200,\n",
    "    \"max_words_per_section\": 500,\n",
    "    \"require_bridge_sentences\": True\n",
    "}\n",
    "\n",
    "GATE_3_CONFIG = {\n",
    "    \"coherence_threshold\": 6.5,\n",
    "    \"depth_threshold\": 6.5,\n",
    "    \"min_citations_per_section\": 1\n",
    "}\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE D: REFINEMENT CONFIGURATION\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "REFINEMENT_CONFIG = {\n",
    "    \"max_iterations\": 2,\n",
    "    \"quality_threshold\": 7.5,\n",
    "    \"min_improvement_threshold\": 0.3,\n",
    "    \"max_cascades_per_iteration\": 3\n",
    "}\n",
    "\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "print(f\"Sprint config: max {SPRINT_CONFIG['max_sprints']} sprints, {SPRINT_CONFIG['claims_per_sprint']} claims/sprint\")\n",
    "print(f\"Cache thresholds: HIGH >= {CACHE_CONFIG['high_confidence_threshold']}, LOW < {CACHE_CONFIG['low_confidence_threshold']}\")\n",
    "print(f\"Refinement: max {REFINEMENT_CONFIG['max_iterations']} iterations, quality target {REFINEMENT_CONFIG['quality_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Models\n",
    "\n",
    "Combined data models from all Tier 1 paradigms:\n",
    "- **Skeleton & Claims** (from Iterative Refinement)\n",
    "- **Cache Structures** (from Knowledge Cache)\n",
    "- **Gate Results** (from Quality Gates)\n",
    "- **Sprint Tracking** (from Agile Sprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton and Claims models defined\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SKELETON STRUCTURE (from Iterative Refinement)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class SkeletonNode(BaseModel):\n",
    "    \"\"\"A node in the document skeleton hierarchy.\"\"\"\n",
    "    node_id: str = Field(description=\"Unique identifier like 'sec:intro' or 'sec:methods'\")\n",
    "    title: str = Field(description=\"Section title for the final document\")\n",
    "    intent: str = Field(description=\"1-3 sentence description of what this section should accomplish\")\n",
    "    target_word_count: int = Field(default=300, description=\"Approximate target length\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"Node IDs this section depends on\")\n",
    "    children: List[str] = Field(default_factory=list, description=\"Child node IDs (empty for leaf nodes)\")\n",
    "    claim_placeholders: List[str] = Field(default_factory=list, description=\"Claims this section must support\")\n",
    "    is_expanded: bool = Field(default=False, description=\"Whether prose has been generated\")\n",
    "\n",
    "\n",
    "class DocumentSkeleton(BaseModel):\n",
    "    \"\"\"The complete document skeleton structure.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence statement of the document's central purpose\")\n",
    "    root_nodes: List[str] = Field(description=\"Top-level section node IDs in document order\")\n",
    "    nodes: Dict[str, SkeletonNode] = Field(default_factory=dict, description=\"All nodes by ID\")\n",
    "    style_constraints: str = Field(default=\"\", description=\"Global style guidelines\")\n",
    "\n",
    "\n",
    "class SkeletonGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for skeleton generation.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence thesis statement\")\n",
    "    sections: List[SkeletonNode] = Field(description=\"All sections in document order\")\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CLAIMS & EVIDENCE (from Iterative Refinement)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"A verifiable assertion in the document.\"\"\"\n",
    "    claim_id: str = Field(description=\"Unique identifier for this claim\")\n",
    "    claim_text: str = Field(description=\"The assertion itself, stated precisely\")\n",
    "    source_node: str = Field(description=\"Skeleton node ID where this claim appears\")\n",
    "    verification_status: Literal[\"unverified\", \"verified\", \"contested\", \"retracted\"] = Field(\n",
    "        default=\"unverified\", description=\"Current verification state\"\n",
    "    )\n",
    "    supporting_evidence: List[str] = Field(default_factory=list, description=\"Sources supporting this claim\")\n",
    "    claim_dependencies: List[str] = Field(default_factory=list, description=\"Other claim IDs this depends on\")\n",
    "\n",
    "\n",
    "class ClaimExtractionOutput(BaseModel):\n",
    "    \"\"\"Output schema for claim extraction.\"\"\"\n",
    "    claims: List[Claim] = Field(description=\"All factual claims extracted\")\n",
    "\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    \"\"\"A research task in the backlog.\"\"\"\n",
    "    task_id: str = Field(description=\"Unique identifier\")\n",
    "    claim_id: str = Field(description=\"Associated claim ID\")\n",
    "    query: str = Field(description=\"Search query to execute\")\n",
    "    priority: int = Field(default=1, description=\"Priority (1=highest)\")\n",
    "    status: Literal[\"pending\", \"in_progress\", \"completed\", \"failed\"] = Field(default=\"pending\")\n",
    "    evidence_found: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PROSE ENTRIES (from Iterative Refinement)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class ProseEntry(BaseModel):\n",
    "    \"\"\"Content stored for each expanded node.\"\"\"\n",
    "    node_id: str = Field(description=\"The skeleton node this prose belongs to\")\n",
    "    main_content: str = Field(description=\"The substantive prose for this section\")\n",
    "    bridge_in: str = Field(default=\"\", description=\"Transitional sentences from previous section\")\n",
    "    bridge_out: str = Field(default=\"\", description=\"Transitional sentences to next section\")\n",
    "    summary: str = Field(default=\"\", description=\"1-2 sentence compression of content\")\n",
    "    revision_count: int = Field(default=0)\n",
    "    citations_used: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class ProseGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for prose generation.\"\"\"\n",
    "    bridge_in: str = Field(description=\"Transitional sentences from previous section\")\n",
    "    main_content: str = Field(description=\"The main prose content for this section\")\n",
    "    bridge_out: str = Field(description=\"Transitional sentences to next section\")\n",
    "    summary: str = Field(description=\"1-2 sentence summary\")\n",
    "    citations_used: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "print(\"Skeleton and Claims models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critique, Cache, Gate, and Sprint models defined\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CRITIQUE & NOISE MAP (from Iterative Refinement)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CritiqueIssue(BaseModel):\n",
    "    \"\"\"An issue identified during critique.\"\"\"\n",
    "    issue_id: str = Field(description=\"Unique identifier\")\n",
    "    scope: Literal[\"global\", \"section\", \"transition\"] = Field(description=\"Level of the issue\")\n",
    "    target_nodes: List[str] = Field(description=\"Affected skeleton node IDs\")\n",
    "    issue_type: Literal[\"weak_claim\", \"missing_evidence\", \"logical_gap\", \"unclear\", \n",
    "                        \"coherence\", \"depth\", \"transition\", \"contradiction\"] = Field(\n",
    "        description=\"Category of issue\"\n",
    "    )\n",
    "    severity: Literal[\"critical\", \"major\", \"minor\"] = Field(description=\"How serious\")\n",
    "    affected_claims: List[str] = Field(default_factory=list, description=\"Claim IDs affected\")\n",
    "    description: str = Field(description=\"What the problem is\")\n",
    "    suggestion: str = Field(description=\"How to fix it\")\n",
    "    search_query: str = Field(default=\"\", description=\"Query to find evidence if needed\")\n",
    "\n",
    "\n",
    "class CritiqueResult(BaseModel):\n",
    "    \"\"\"Complete critique output.\"\"\"\n",
    "    overall_quality: float = Field(description=\"Quality score 1-10\")\n",
    "    issues: List[CritiqueIssue] = Field(default_factory=list)\n",
    "    strengths: str = Field(default=\"\", description=\"What the document does well\")\n",
    "    summary: str = Field(description=\"Overall assessment\")\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CACHE STRUCTURES (from Knowledge Cache)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CachedDocument(BaseModel):\n",
    "    \"\"\"A cached web document.\"\"\"\n",
    "    url: str = Field(description=\"Original URL\")\n",
    "    normalized_url: str = Field(description=\"Normalized URL for lookup\")\n",
    "    content: str = Field(description=\"Full text content\")\n",
    "    content_hash: str = Field(description=\"SHA-256 hash of content\")\n",
    "    title: str = Field(default=\"\", description=\"Page title\")\n",
    "    retrieval_timestamp: str = Field(description=\"When this was retrieved\")\n",
    "    source_query: str = Field(default=\"\", description=\"Query that led to this content\")\n",
    "\n",
    "\n",
    "class CachedChunk(BaseModel):\n",
    "    \"\"\"A chunk of content with embedding.\"\"\"\n",
    "    chunk_id: str = Field(description=\"Unique identifier\")\n",
    "    text: str = Field(description=\"Chunk text content\")\n",
    "    embedding: List[float] = Field(description=\"Vector embedding\")\n",
    "    source_url: str = Field(description=\"Source document URL\")\n",
    "    position: int = Field(description=\"Position within source document\")\n",
    "\n",
    "\n",
    "class CacheDecision(BaseModel):\n",
    "    \"\"\"Record of a cache decision for observability.\"\"\"\n",
    "    query: str\n",
    "    layer_reached: Literal[\"L1\", \"L2\", \"L3\"]\n",
    "    decision: Literal[\"HIT\", \"HIGH_CONF\", \"MEDIUM_CONF\", \"LOW_CONF\",\n",
    "                      \"SUFFICIENT\", \"PARTIAL\", \"INSUFFICIENT\"]\n",
    "    confidence_score: float = 0.0\n",
    "    action_taken: Literal[\"USE_CACHE\", \"SEARCH\", \"TARGETED_SEARCH\"]\n",
    "    reasoning: str = \"\"\n",
    "    timestamp: str = \"\"\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# GATE RESULTS (from Quality Gates)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class GateResult(BaseModel):\n",
    "    \"\"\"Result of a quality gate check.\"\"\"\n",
    "    gate_name: str = Field(description=\"Which gate (gate_1, gate_2, gate_3)\")\n",
    "    passed: bool = Field(description=\"Whether the gate was passed\")\n",
    "    scores: Dict[str, float] = Field(default_factory=dict, description=\"Individual criterion scores\")\n",
    "    reason: str = Field(description=\"Explanation of the gate result\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Improvement suggestions\")\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SPRINT TRACKING (from Agile Sprints)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class SprintFinding(BaseModel):\n",
    "    \"\"\"A finding from a research sprint.\"\"\"\n",
    "    claim_id: str = Field(description=\"The claim this finding addresses\")\n",
    "    finding: str = Field(description=\"The key finding or insight\")\n",
    "    sources: List[str] = Field(default_factory=list, description=\"Source URLs\")\n",
    "    cache_hit: bool = Field(default=False, description=\"Whether this came from cache\")\n",
    "\n",
    "\n",
    "print(\"Critique, Cache, Gate, and Sprint models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Knowledge Cache Integration\n",
    "\n",
    "The Knowledge Cache provides a 3-layer cascading lookup:\n",
    "- **Layer 1**: Deterministic deduplication (exact query/URL matching)\n",
    "- **Layer 2**: Semantic similarity (vector search with confidence scoring)\n",
    "- **Layer 3**: LLM judgment (gap analysis for medium-confidence hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowledgeBase class defined\n"
     ]
    }
   ],
   "source": [
    "class KnowledgeBase:\n",
    "    \"\"\"Session-scoped knowledge base with cascading cache capabilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url_registry: Dict[str, CachedDocument] = {}\n",
    "        self.query_cache: Dict[str, Dict] = {}\n",
    "        self.chunks: List[CachedChunk] = []\n",
    "        self.chunk_embeddings: Optional[np.ndarray] = None\n",
    "\n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            \"total_queries\": 0,\n",
    "            \"l1_hits\": 0,\n",
    "            \"l2_high\": 0,\n",
    "            \"l2_medium\": 0,\n",
    "            \"l2_low\": 0,\n",
    "            \"l3_sufficient\": 0,\n",
    "            \"l3_partial\": 0,\n",
    "            \"l3_insufficient\": 0,\n",
    "            \"web_searches_executed\": 0,\n",
    "            \"web_searches_avoided\": 0\n",
    "        }\n",
    "\n",
    "    # === URL Normalization ===\n",
    "    def normalize_url(self, url: str) -> str:\n",
    "        \"\"\"Normalize URL for consistent lookup.\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            host = parsed.netloc.lower()\n",
    "            if host.startswith(\"www.\"):\n",
    "                host = host[4:]\n",
    "            path = parsed.path.rstrip(\"/\")\n",
    "            tracking_params = {\"utm_source\", \"utm_medium\", \"utm_campaign\", \"ref\", \"fbclid\"}\n",
    "            query_params = sorted(parsed.query.split(\"&\")) if parsed.query else []\n",
    "            query_params = [p for p in query_params if p.split(\"=\")[0] not in tracking_params]\n",
    "            query = \"&\".join(query_params)\n",
    "            normalized = f\"https://{host}{path}\"\n",
    "            if query:\n",
    "                normalized += f\"?{query}\"\n",
    "            return normalized\n",
    "        except:\n",
    "            return url.lower()\n",
    "\n",
    "    # === Query Normalization ===\n",
    "    def normalize_query_light(self, query: str) -> str:\n",
    "        \"\"\"Light normalization: lowercase, collapse whitespace.\"\"\"\n",
    "        return \" \".join(query.lower().split())\n",
    "\n",
    "    def normalize_query_aggressive(self, query: str) -> str:\n",
    "        \"\"\"Aggressive normalization: remove stop words, sort terms.\"\"\"\n",
    "        stop_words = {\"the\", \"a\", \"an\", \"is\", \"are\", \"of\", \"in\", \"to\", \"for\", \"and\", \"or\", \n",
    "                      \"what\", \"how\", \"why\", \"when\", \"where\"}\n",
    "        light = self.normalize_query_light(query)\n",
    "        terms = [t for t in light.split() if t not in stop_words and len(t) > 1]\n",
    "        return \" \".join(sorted(terms))\n",
    "\n",
    "    # === Content Hashing ===\n",
    "    def compute_content_hash(self, content: str) -> str:\n",
    "        \"\"\"Compute SHA-256 hash of content.\"\"\"\n",
    "        return hashlib.sha256(content.encode()).hexdigest()\n",
    "\n",
    "    # === Document Storage ===\n",
    "    def add_document(self, url: str, content: str, title: str = \"\", source_query: str = \"\"):\n",
    "        \"\"\"Add a document to the knowledge base.\"\"\"\n",
    "        normalized_url = self.normalize_url(url)\n",
    "        doc = CachedDocument(\n",
    "            url=url,\n",
    "            normalized_url=normalized_url,\n",
    "            content=content,\n",
    "            content_hash=self.compute_content_hash(content),\n",
    "            title=title,\n",
    "            retrieval_timestamp=datetime.now().isoformat(),\n",
    "            source_query=source_query\n",
    "        )\n",
    "        self.url_registry[normalized_url] = doc\n",
    "        self._chunk_and_embed(doc)\n",
    "        return doc\n",
    "\n",
    "    def _chunk_and_embed(self, doc: CachedDocument):\n",
    "        \"\"\"Chunk document and compute embeddings.\"\"\"\n",
    "        content = doc.content\n",
    "        chunks_text = []\n",
    "        chunk_size = CACHE_CONFIG[\"chunk_size\"]\n",
    "        chunk_overlap = CACHE_CONFIG[\"chunk_overlap\"]\n",
    "\n",
    "        for i in range(0, len(content), chunk_size - chunk_overlap):\n",
    "            chunk_text = content[i:i + chunk_size]\n",
    "            if len(chunk_text) > 50:\n",
    "                chunks_text.append(chunk_text)\n",
    "\n",
    "        if not chunks_text:\n",
    "            return\n",
    "\n",
    "        embeddings = embeddings_model.embed_documents(chunks_text)\n",
    "\n",
    "        for i, (text, embedding) in enumerate(zip(chunks_text, embeddings)):\n",
    "            chunk = CachedChunk(\n",
    "                chunk_id=f\"{doc.content_hash[:8]}_{i}\",\n",
    "                text=text,\n",
    "                embedding=embedding,\n",
    "                source_url=doc.url,\n",
    "                position=i\n",
    "            )\n",
    "            self.chunks.append(chunk)\n",
    "\n",
    "        self._update_embedding_matrix()\n",
    "\n",
    "    def _update_embedding_matrix(self):\n",
    "        \"\"\"Update the numpy matrix of embeddings for fast search.\"\"\"\n",
    "        if self.chunks:\n",
    "            self.chunk_embeddings = np.array([c.embedding for c in self.chunks])\n",
    "\n",
    "    # === Query Cache ===\n",
    "    def add_query(self, query: str, result_urls: List[str], result_summary: str):\n",
    "        \"\"\"Add a query to the cache.\"\"\"\n",
    "        entry = {\n",
    "            \"original_query\": query,\n",
    "            \"light_normalized\": self.normalize_query_light(query),\n",
    "            \"aggressive_normalized\": self.normalize_query_aggressive(query),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"result_urls\": result_urls,\n",
    "            \"result_summary\": result_summary\n",
    "        }\n",
    "        self.query_cache[entry[\"light_normalized\"]] = entry\n",
    "        self.query_cache[entry[\"aggressive_normalized\"]] = entry\n",
    "        return entry\n",
    "\n",
    "    # === Lookups ===\n",
    "    def lookup_query_exact(self, query: str) -> Optional[Dict]:\n",
    "        \"\"\"Check for exact query match.\"\"\"\n",
    "        light = self.normalize_query_light(query)\n",
    "        return self.query_cache.get(light)\n",
    "\n",
    "    def lookup_query_aggressive(self, query: str) -> Optional[Dict]:\n",
    "        \"\"\"Check for bag-of-words query match.\"\"\"\n",
    "        aggressive = self.normalize_query_aggressive(query)\n",
    "        return self.query_cache.get(aggressive)\n",
    "\n",
    "    # === Semantic Search ===\n",
    "    def semantic_search(self, query: str, top_k: int = None) -> List[Tuple[CachedChunk, float]]:\n",
    "        \"\"\"Find semantically similar chunks.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = CACHE_CONFIG[\"top_k_retrieval\"]\n",
    "            \n",
    "        if not self.chunks or self.chunk_embeddings is None:\n",
    "            return []\n",
    "\n",
    "        query_embedding = np.array(embeddings_model.embed_query(query))\n",
    "        similarities = np.dot(self.chunk_embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.chunk_embeddings, axis=1) * np.linalg.norm(query_embedding) + 1e-8\n",
    "        )\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append((self.chunks[idx], float(similarities[idx])))\n",
    "        return results\n",
    "\n",
    "    def get_stats_summary(self) -> str:\n",
    "        \"\"\"Get human-readable stats summary.\"\"\"\n",
    "        total = self.stats[\"total_queries\"]\n",
    "        if total == 0:\n",
    "            return \"No queries processed yet.\"\n",
    "        avoided = self.stats[\"web_searches_avoided\"]\n",
    "        hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "        return f\"Cache: {avoided}/{total} avoided ({hit_rate:.1f}% hit rate), {len(self.chunks)} chunks indexed\"\n",
    "\n",
    "\n",
    "print(\"KnowledgeBase class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# HELPER FUNCTIONS\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def extract_domain(url: str) -> str:\n",
    "    \"\"\"Extract domain from URL.\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc\n",
    "        if domain.startswith(\"www.\"):\n",
    "            domain = domain[4:]\n",
    "        return domain\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "class SourcedEvidence(BaseModel):\n",
    "    \"\"\"Evidence with clear source attribution.\"\"\"\n",
    "    content: str = Field(description=\"The actual evidence text\")\n",
    "    source_url: str = Field(description=\"URL where this evidence was found\")\n",
    "    title: str = Field(default=\"\", description=\"Page title\")\n",
    "\n",
    "\n",
    "def search_web(query: str, max_results: int = 8) -> Tuple[str, List[SourcedEvidence], List[str]]:\n",
    "    \"\"\"Execute web search using Tavily. Returns (summary, structured_results, urls).\"\"\"\n",
    "    try:\n",
    "        if len(query) > 400:\n",
    "            query = query[:400]\n",
    "\n",
    "        response = tavily_client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            include_answer=True\n",
    "        )\n",
    "\n",
    "        structured_results = []\n",
    "        urls = []\n",
    "        summary = response.get(\"answer\", \"\")\n",
    "\n",
    "        for r in response.get(\"results\", []):\n",
    "            url = r.get('url', '')\n",
    "            urls.append(url)\n",
    "            content = r.get('content', '')[:600]\n",
    "            title = r.get('title', 'No title')\n",
    "            # Store as structured evidence with clear source association\n",
    "            structured_results.append(SourcedEvidence(\n",
    "                content=content,\n",
    "                source_url=url,\n",
    "                title=title\n",
    "            ))\n",
    "\n",
    "        return summary, structured_results, urls\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\", [], []\n",
    "\n",
    "\n",
    "def compute_confidence(top_results: List[Tuple[CachedChunk, float]], query: str) -> float:\n",
    "    \"\"\"Compute multi-signal confidence score for cache results.\"\"\"\n",
    "    if not top_results:\n",
    "        return 0.0\n",
    "\n",
    "    top_score = top_results[0][1]\n",
    "    score_gap = top_results[0][1] - top_results[1][1] if len(top_results) > 1 else top_score\n",
    "\n",
    "    query_terms = set(query.lower().split())\n",
    "    top_chunk_terms = set(top_results[0][0].text.lower().split())\n",
    "    term_overlap = len(query_terms & top_chunk_terms) / len(query_terms | top_chunk_terms) if query_terms | top_chunk_terms else 0\n",
    "\n",
    "    # Weighted combination\n",
    "    confidence = 0.5 * top_score + 0.25 * min(score_gap * 2, 1.0) + 0.25 * term_overlap\n",
    "    return max(0.0, min(confidence, 1.0))\n",
    "\n",
    "\n",
    "async def cascaded_search(query: str, kb: KnowledgeBase) -> Tuple[List[SourcedEvidence], List[str], CacheDecision]:\n",
    "    \"\"\"Execute the full cascading cache check and search if needed.\n",
    "    \n",
    "    Returns: (structured_evidence_list, urls, decision)\n",
    "    \"\"\"\n",
    "    kb.stats[\"total_queries\"] += 1\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    # === Layer 1: Deterministic Deduplication ===\n",
    "    exact_match = kb.lookup_query_exact(query)\n",
    "    if exact_match:\n",
    "        kb.stats[\"l1_hits\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        # Return cached summary as single evidence item\n",
    "        evidence = [SourcedEvidence(\n",
    "            content=exact_match[\"result_summary\"],\n",
    "            source_url=exact_match[\"result_urls\"][0] if exact_match[\"result_urls\"] else \"cache://query\",\n",
    "            title=\"Cached Result\"\n",
    "        )]\n",
    "        return evidence, exact_match[\"result_urls\"], CacheDecision(\n",
    "            query=query, layer_reached=\"L1\", decision=\"HIT\",\n",
    "            confidence_score=1.0, action_taken=\"USE_CACHE\",\n",
    "            reasoning=\"Exact query match in cache\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    aggressive_match = kb.lookup_query_aggressive(query)\n",
    "    if aggressive_match:\n",
    "        kb.stats[\"l1_hits\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        evidence = [SourcedEvidence(\n",
    "            content=aggressive_match[\"result_summary\"],\n",
    "            source_url=aggressive_match[\"result_urls\"][0] if aggressive_match[\"result_urls\"] else \"cache://query\",\n",
    "            title=\"Cached Result\"\n",
    "        )]\n",
    "        return evidence, aggressive_match[\"result_urls\"], CacheDecision(\n",
    "            query=query, layer_reached=\"L1\", decision=\"HIT\",\n",
    "            confidence_score=0.95, action_taken=\"USE_CACHE\",\n",
    "            reasoning=\"Bag-of-words match in cache\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    # === Layer 2: Semantic Retrieval ===\n",
    "    results = kb.semantic_search(query)\n",
    "    \n",
    "    if not results:\n",
    "        # No cached content, go to web search\n",
    "        summary, structured_results, urls = search_web(query)\n",
    "        kb.stats[\"web_searches_executed\"] += 1\n",
    "        kb.stats[\"l2_low\"] += 1\n",
    "        \n",
    "        # Cache results for future use\n",
    "        cache_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\n\" + \"\\n\\n\".join([\n",
    "            f\"[{e.title}] {e.content}\" for e in structured_results\n",
    "        ])\n",
    "        synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "        kb.add_document(synthetic_url, cache_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "        kb.add_query(query, urls, summary)\n",
    "        \n",
    "        return structured_results, urls, CacheDecision(\n",
    "            query=query, layer_reached=\"L2\", decision=\"LOW_CONF\",\n",
    "            confidence_score=0.0, action_taken=\"SEARCH\",\n",
    "            reasoning=\"No cached content found\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    confidence = compute_confidence(results, query)\n",
    "    high_thresh = CACHE_CONFIG[\"high_confidence_threshold\"]\n",
    "    low_thresh = CACHE_CONFIG[\"low_confidence_threshold\"]\n",
    "\n",
    "    if confidence >= high_thresh:\n",
    "        kb.stats[\"l2_high\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        # Convert cache chunks to SourcedEvidence\n",
    "        evidence = [\n",
    "            SourcedEvidence(content=c.text, source_url=c.source_url, title=\"Cached\")\n",
    "            for c, _ in results[:3]\n",
    "        ]\n",
    "        urls = list(set([c.source_url for c, _ in results]))\n",
    "        return evidence, urls, CacheDecision(\n",
    "            query=query, layer_reached=\"L2\", decision=\"HIGH_CONF\",\n",
    "            confidence_score=confidence, action_taken=\"USE_CACHE\",\n",
    "            reasoning=f\"High semantic similarity ({confidence:.2f})\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    elif confidence < low_thresh:\n",
    "        kb.stats[\"l2_low\"] += 1\n",
    "        summary, structured_results, urls = search_web(query)\n",
    "        kb.stats[\"web_searches_executed\"] += 1\n",
    "        \n",
    "        # Cache results\n",
    "        cache_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\n\" + \"\\n\\n\".join([\n",
    "            f\"[{e.title}] {e.content}\" for e in structured_results\n",
    "        ])\n",
    "        synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "        kb.add_document(synthetic_url, cache_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "        kb.add_query(query, urls, summary)\n",
    "        \n",
    "        return structured_results, urls, CacheDecision(\n",
    "            query=query, layer_reached=\"L2\", decision=\"LOW_CONF\",\n",
    "            confidence_score=confidence, action_taken=\"SEARCH\",\n",
    "            reasoning=f\"Low confidence ({confidence:.2f}), executed web search\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # === Layer 3: Medium confidence - combine cache + search ===\n",
    "        kb.stats[\"l2_medium\"] += 1\n",
    "        \n",
    "        # Get cached evidence\n",
    "        cached_evidence = [\n",
    "            SourcedEvidence(content=c.text, source_url=c.source_url, title=\"Cached\")\n",
    "            for c, _ in results[:2]\n",
    "        ]\n",
    "        cached_urls = [c.source_url for c, _ in results[:2]]\n",
    "        \n",
    "        # Execute supplementary search\n",
    "        summary, new_evidence, new_urls = search_web(query, max_results=4)\n",
    "        kb.stats[\"web_searches_executed\"] += 1\n",
    "        \n",
    "        # Cache for future\n",
    "        cache_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\n\" + \"\\n\\n\".join([\n",
    "            f\"[{e.title}] {e.content}\" for e in new_evidence\n",
    "        ])\n",
    "        synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "        kb.add_document(synthetic_url, cache_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "        kb.add_query(query, new_urls, summary)\n",
    "        \n",
    "        combined_evidence = cached_evidence + new_evidence\n",
    "        combined_urls = list(set(cached_urls + new_urls))\n",
    "        \n",
    "        kb.stats[\"l3_partial\"] += 1\n",
    "        \n",
    "        return combined_evidence, combined_urls, CacheDecision(\n",
    "            query=query, layer_reached=\"L3\", decision=\"PARTIAL\",\n",
    "            confidence_score=confidence, action_taken=\"TARGETED_SEARCH\",\n",
    "            reasoning=f\"Medium confidence ({confidence:.2f}), combined cache + search\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "\n",
    "def get_leaf_nodes(skeleton: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Get all leaf node IDs in document order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    valid_node_ids = set(nodes.keys())  # Only consider nodes that actually exist\n",
    "\n",
    "    def collect_leaves(node_ids: List[str]) -> List[str]:\n",
    "        leaves = []\n",
    "        for nid in node_ids:\n",
    "            # Skip node IDs that don't exist in the skeleton\n",
    "            if nid not in valid_node_ids:\n",
    "                continue\n",
    "            node = nodes.get(nid, {})\n",
    "            children = node.get(\"children\", [])\n",
    "            # Filter children to only include valid node IDs\n",
    "            valid_children = [c for c in children if c in valid_node_ids]\n",
    "            if not valid_children:\n",
    "                leaves.append(nid)\n",
    "            else:\n",
    "                leaves.extend(collect_leaves(valid_children))\n",
    "        return leaves\n",
    "\n",
    "    result = collect_leaves(root_nodes)\n",
    "    \n",
    "    # Fallback: if no leaves found through tree traversal, use all nodes without children\n",
    "    if not result:\n",
    "        for nid, node in nodes.items():\n",
    "            children = node.get(\"children\", [])\n",
    "            valid_children = [c for c in children if c in valid_node_ids]\n",
    "            if not valid_children:\n",
    "                result.append(nid)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def topological_sort_nodes(skeleton: Dict[str, Any], node_ids: List[str]) -> List[str]:\n",
    "    \"\"\"Sort nodes by dependency order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    node_id_set = set(node_ids)\n",
    "    remaining = set(node_ids)\n",
    "    sorted_nodes = []\n",
    "\n",
    "    while remaining:\n",
    "        ready = []\n",
    "        for nid in remaining:\n",
    "            node = nodes.get(nid, {})\n",
    "            deps = set(node.get(\"dependencies\", []))\n",
    "            internal_deps = deps & node_id_set\n",
    "            if internal_deps.issubset(set(sorted_nodes)):\n",
    "                ready.append(nid)\n",
    "\n",
    "        if not ready:\n",
    "            # Circular dependency - add remaining in document order\n",
    "            for nid in node_ids:\n",
    "                if nid in remaining:\n",
    "                    sorted_nodes.append(nid)\n",
    "            break\n",
    "\n",
    "        ready_ordered = [nid for nid in node_ids if nid in ready]\n",
    "        sorted_nodes.extend(ready_ordered)\n",
    "        remaining -= set(ready_ordered)\n",
    "\n",
    "    return sorted_nodes\n",
    "\n",
    "\n",
    "def get_adjacent_nodes(skeleton: Dict[str, Any], node_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Get the previous and next node IDs in document order.\"\"\"\n",
    "    leaves = get_leaf_nodes(skeleton)\n",
    "    try:\n",
    "        idx = leaves.index(node_id)\n",
    "        prev_node = leaves[idx - 1] if idx > 0 else None\n",
    "        next_node = leaves[idx + 1] if idx < len(leaves) - 1 else None\n",
    "        return prev_node, next_node\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Unified State Schema\n",
    "\n",
    "The SFEO state combines all phase requirements into a single TypedDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFEOState schema defined\n"
     ]
    }
   ],
   "source": [
    "class SFEOState(TypedDict):\n",
    "    \"\"\"Complete state for the SFEO architecture.\"\"\"\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # INPUT\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    question: str\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # PHASE A: STRATEGIC PLANNING\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    preliminary_findings: List[str]  # Initial research results\n",
    "    skeleton: Dict[str, Any]  # DocumentSkeleton as dict\n",
    "    claims_registry: Dict[str, Dict[str, Any]]  # claim_id → Claim as dict\n",
    "    research_backlog: List[Dict[str, Any]]  # List of ResearchTask as dicts\n",
    "    \n",
    "    # Gate 1 tracking\n",
    "    gate_1_attempts: int\n",
    "    gate_1_passed: bool\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # PHASE B: EVIDENCE GATHERING\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    current_sprint: int\n",
    "    max_sprints: int\n",
    "    sprint_findings: Annotated[List[str], operator.add]  # Accumulates\n",
    "    \n",
    "    # Cache decisions for observability\n",
    "    cache_decisions: Annotated[List[Dict], operator.add]\n",
    "    \n",
    "    # Evidence tracking (accumulated)\n",
    "    source_urls: Annotated[List[str], operator.add]\n",
    "    evidence_map: Dict[str, List[str]]  # claim_id → [evidence snippets]\n",
    "    \n",
    "    # Retrospective notes\n",
    "    retrospective_notes: Annotated[List[str], operator.add]\n",
    "    should_stop_sprinting: bool\n",
    "    \n",
    "    # Gate 2 tracking\n",
    "    gate_2_attempts: int\n",
    "    gate_2_passed: bool\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # PHASE C: DOCUMENT CONSTRUCTION\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    prose_store: Dict[str, Dict[str, Any]]  # node_id → ProseEntry as dict\n",
    "    global_references: Dict[int, Dict[str, str]]  # ref_num → {url, title}\n",
    "    assembled_draft: str\n",
    "    \n",
    "    # Gate 3 tracking\n",
    "    gate_3_passed: bool\n",
    "    gate_3_scores: Dict[str, float]\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # PHASE D: REFINEMENT\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    iteration_count: int\n",
    "    noise_map: List[Dict[str, Any]]  # List of CritiqueIssue as dicts\n",
    "    nodes_to_patch: List[str]\n",
    "    targeted_evidence: Dict[str, List[Dict]]  # node_id → List[evidence dicts]\n",
    "    quality_scores: Annotated[List[float], operator.add]\n",
    "    \n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    # OUTPUT\n",
    "    # ═══════════════════════════════════════════════════════════════════════\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "# Initialize global knowledge base (will be reset per session)\n",
    "knowledge_base: KnowledgeBase = None\n",
    "\n",
    "print(\"SFEOState schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompts Library\n",
    "\n",
    "Consolidated prompts for all SFEO phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts library defined\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE A PROMPTS: STRATEGIC PLANNING\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "SKELETON_GENERATION_PROMPT = \"\"\"You are a research document architect designing a comprehensive report structure.\n",
    "\n",
    "RESEARCH QUESTION: {question}\n",
    "\n",
    "PRELIMINARY RESEARCH FINDINGS:\n",
    "{preliminary_findings}\n",
    "\n",
    "Create a hierarchical document skeleton with:\n",
    "1. A clear thesis statement (one sentence capturing the central argument)\n",
    "2. 5-7 main sections appropriate for a comprehensive research report\n",
    "3. Each section should have:\n",
    "   - node_id: Unique identifier (e.g., \"sec:intro\", \"sec:background\", \"sec:analysis\")\n",
    "   - title: Descriptive section title\n",
    "   - intent: 1-3 sentences describing what this section should accomplish\n",
    "   - target_word_count: 250-400 words per section\n",
    "   - dependencies: List of node_ids this section builds upon (empty for first sections)\n",
    "   - claim_placeholders: 2-3 specific claims this section must support (make these searchable)\n",
    "\n",
    "REQUIRED SECTIONS (adapt titles to topic):\n",
    "1. Introduction - Present the topic, context, and thesis\n",
    "2. Background/Context - Provide necessary foundation knowledge  \n",
    "3. Main Body (2-4 sections) - Cover key aspects in depth\n",
    "4. Analysis/Discussion - Synthesize findings and discuss implications\n",
    "5. Conclusion - Summarize key points and future directions\n",
    "\n",
    "IMPORTANT:\n",
    "- Node IDs must be unique and follow format: sec:topic\n",
    "- Dependencies must reference existing node_ids (no forward references)\n",
    "- claim_placeholders should be specific and searchable, not vague\n",
    "\"\"\"\n",
    "\n",
    "CLAIM_EXTRACTION_PROMPT = \"\"\"Extract all verifiable claims from this skeleton's claim_placeholders.\n",
    "\n",
    "SKELETON:\n",
    "{skeleton_json}\n",
    "\n",
    "For each claim placeholder across all sections, create a claim entry with:\n",
    "- claim_id: Unique ID using format claim_{{node_id}}_{{number}}\n",
    "- claim_text: The specific assertion to verify\n",
    "- source_node: The section node_id\n",
    "- verification_status: \"unverified\"\n",
    "\n",
    "Focus on claims that are:\n",
    "- Specific and factual (not opinions)\n",
    "- Searchable (can find evidence online)\n",
    "- Central to answering the research question\n",
    "\"\"\"\n",
    "\n",
    "GATE_1_EVALUATION_PROMPT = \"\"\"Evaluate this document skeleton for quality.\n",
    "\n",
    "RESEARCH QUESTION: {question}\n",
    "\n",
    "SKELETON:\n",
    "Thesis: {thesis}\n",
    "Sections: {sections_summary}\n",
    "\n",
    "Evaluate on these criteria (score 1-10 each):\n",
    "\n",
    "1. THESIS_CLARITY: Is the thesis clear, specific, and arguable?\n",
    "2. COVERAGE: Does the skeleton address ALL parts of the research question?\n",
    "3. STRUCTURE: Is the hierarchy logical? Do dependencies make sense?\n",
    "4. CLAIM_SPECIFICITY: Are claim_placeholders specific enough to research?\n",
    "\n",
    "Format response as:\n",
    "THESIS_CLARITY: [score]\n",
    "COVERAGE: [score]  \n",
    "STRUCTURE: [score]\n",
    "CLAIM_SPECIFICITY: [score]\n",
    "OVERALL: [average score]\n",
    "ISSUES: [List any problems, or \"None\"]\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE B PROMPTS: EVIDENCE GATHERING\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "SPRINT_PLANNING_PROMPT = \"\"\"Select claims to verify in this research sprint.\n",
    "\n",
    "REMAINING UNVERIFIED CLAIMS:\n",
    "{unverified_claims}\n",
    "\n",
    "ALREADY VERIFIED CLAIMS:\n",
    "{verified_claims}\n",
    "\n",
    "Select up to {claims_per_sprint} claims to verify in this sprint.\n",
    "Prioritize claims that are:\n",
    "1. Central to the thesis\n",
    "2. Quantitative or easily verifiable\n",
    "3. Related to each other (for cache efficiency)\n",
    "\n",
    "For each selected claim, provide a search query.\n",
    "\n",
    "Format as JSON array:\n",
    "[\n",
    "  {{\"claim_id\": \"...\", \"query\": \"specific search query\"}}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "SPRINT_RETROSPECTIVE_PROMPT = \"\"\"Conduct a sprint retrospective for research progress.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "\n",
    "SPRINT {sprint_num} of {max_sprints} COMPLETED.\n",
    "\n",
    "CLAIMS VERIFIED THIS SPRINT:\n",
    "{verified_this_sprint}\n",
    "\n",
    "REMAINING UNVERIFIED:\n",
    "{remaining_unverified}\n",
    "\n",
    "CACHE PERFORMANCE:\n",
    "- Queries: {total_queries}\n",
    "- Cache hits: {cache_hits} ({hit_rate:.1f}%)\n",
    "\n",
    "Analyze and provide:\n",
    "\n",
    "## LEARNINGS\n",
    "What key insights did we gain?\n",
    "\n",
    "## GAPS  \n",
    "What is still unclear or needs investigation?\n",
    "\n",
    "## CONTINUE\n",
    "Should we continue with another sprint? YES or NO with justification.\n",
    "Consider: If most claims are verified or cache hit rate is high, we may stop.\n",
    "\n",
    "## PRIORITY_CLAIMS\n",
    "If continuing, list the 2-4 most important remaining claims to verify:\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE C PROMPTS: DOCUMENT CONSTRUCTION\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "PROSE_GENERATION_PROMPT = \"\"\"Generate prose content for a specific section of a research report.\n",
    "\n",
    "SECTION CONTEXT:\n",
    "- Node ID: {node_id}\n",
    "- Title: {title}\n",
    "- Intent: {intent}\n",
    "- Target Word Count: {target_words}\n",
    "\n",
    "EVIDENCE SOURCES (numbered for citation):\n",
    "{numbered_evidence}\n",
    "\n",
    "CONTEXT FROM ADJACENT SECTIONS:\n",
    "- Previous Section Summary: {prev_summary}\n",
    "- Next Section Preview: {next_preview}\n",
    "\n",
    "WRITING REQUIREMENTS:\n",
    "1. Write substantive, specific prose that synthesizes the evidence above\n",
    "2. Use NUMBERED citations like [1], [2], [3] - NOT inline URLs\n",
    "3. Only cite when making a specific factual claim from the evidence\n",
    "4. Do NOT cite every sentence - aim for 2-4 citations per paragraph maximum\n",
    "5. Extract specific numbers, percentages, and concrete details from the evidence\n",
    "6. Create smooth transitions (bridge_in from previous, bridge_out to next)\n",
    "7. Write in a professional, flowing academic style\n",
    "\n",
    "CITATION STYLE:\n",
    "- GOOD: \"According to recent surveys, 78% of enterprises plan to increase LLM investment [1].\"\n",
    "- BAD: \"Enterprises are investing in LLMs [Source: https://example.com].\"\n",
    "- BAD: \"This is important [1]. This is also relevant [2]. Another point [3].\" (over-citation)\n",
    "\n",
    "Output as JSON:\n",
    "{{\n",
    "  \"bridge_in\": \"1-2 transitional sentences from previous section\",\n",
    "  \"main_content\": \"The main prose (~{target_words} words) with numbered citations like [1], [2]\",\n",
    "  \"bridge_out\": \"1-2 transitional sentences to next section\",\n",
    "  \"summary\": \"What this section establishes\",\n",
    "  \"citations_used\": [1, 2, 3]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "GATE_3_EVALUATION_PROMPT = \"\"\"Evaluate this assembled draft for quality.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "\n",
    "DRAFT:\n",
    "{draft}\n",
    "\n",
    "Evaluate on these criteria (score 1-10 each):\n",
    "\n",
    "1. COHERENCE: Does the document flow logically from section to section?\n",
    "2. DEPTH: Does the analysis go beyond surface-level information?\n",
    "3. EVIDENCE: Are claims well-supported with citations?\n",
    "4. COMPLETENESS: Does it fully answer the research question?\n",
    "\n",
    "Format response as:\n",
    "COHERENCE: [score]\n",
    "DEPTH: [score]\n",
    "EVIDENCE: [score]\n",
    "COMPLETENESS: [score]\n",
    "OVERALL: [average]\n",
    "ISSUES: [List problems needing attention, or \"None\"]\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE D PROMPTS: REFINEMENT\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "STRUCTURED_CRITIQUE_PROMPT = \"\"\"Conduct a rigorous review of this research report.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "\n",
    "DOCUMENT SKELETON:\n",
    "{skeleton_summary}\n",
    "\n",
    "CLAIMS REGISTRY:\n",
    "{claims_summary}\n",
    "\n",
    "ASSEMBLED DRAFT:\n",
    "{draft}\n",
    "\n",
    "Analyze at THREE levels and produce a Noise Map:\n",
    "\n",
    "1. GLOBAL ISSUES: Thesis support, overall coherence, terminology consistency\n",
    "2. SECTION ISSUES: Weak claims, missing evidence, logical gaps, depth\n",
    "3. TRANSITION ISSUES: Abrupt shifts, weak bridges, broken references\n",
    "\n",
    "For EACH issue, provide:\n",
    "- issue_id: Unique ID (e.g., \"I001\")\n",
    "- scope: \"global\", \"section\", or \"transition\"\n",
    "- target_nodes: List of affected node IDs\n",
    "- issue_type: weak_claim, missing_evidence, logical_gap, unclear, coherence, depth, transition\n",
    "- severity: \"critical\", \"major\", or \"minor\"\n",
    "- description: What the problem is\n",
    "- suggestion: How to fix it\n",
    "- search_query: If evidence-related, a query to find supporting sources\n",
    "\n",
    "SCORING (1-10):\n",
    "- 9-10: Publication ready\n",
    "- 7-8: Good, minor issues only\n",
    "- 5-6: Acceptable, needs improvement\n",
    "- 3-4: Significant problems\n",
    "- 1-2: Major rework needed\n",
    "\n",
    "Output as JSON with overall_quality score and issues array.\n",
    "\"\"\"\n",
    "\n",
    "PATCH_APPLICATION_PROMPT = \"\"\"Revise this section based on critique feedback and new evidence.\n",
    "\n",
    "SECTION TO REVISE:\n",
    "- Node ID: {node_id}\n",
    "- Title: {title}\n",
    "- Intent: {intent}\n",
    "\n",
    "CURRENT CONTENT:\n",
    "{current_content}\n",
    "\n",
    "ISSUES TO ADDRESS:\n",
    "{issues}\n",
    "\n",
    "NEW EVIDENCE (numbered for citation):\n",
    "{new_evidence}\n",
    "\n",
    "ADJACENT CONTEXT:\n",
    "- Previous section ends: {prev_bridge_out}\n",
    "- Next section starts: {next_bridge_in}\n",
    "\n",
    "REVISION REQUIREMENTS:\n",
    "1. Address ALL identified issues in the revision\n",
    "2. Use NUMBERED citations like [1], [2] when referencing new evidence\n",
    "3. Do NOT use inline URLs - only numbered references\n",
    "4. Maintain smooth transitions with adjacent sections\n",
    "5. Keep approximately the same length\n",
    "6. Extract specific facts and details from the evidence\n",
    "\n",
    "Output revised section as JSON with bridge_in, main_content, bridge_out, summary.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompts library defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase A: Strategic Planning\n",
    "\n",
    "Phase A establishes the document \"contract\":\n",
    "1. Preliminary research to inform skeleton\n",
    "2. Generate document skeleton with semantic nodes\n",
    "3. Extract verifiable claims from skeleton\n",
    "4. Create research backlog from claims\n",
    "5. Gate 1: Validate skeleton quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase A node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def preliminary_research(state: SFEOState) -> dict:\n",
    "    \"\"\"Conduct lightweight initial research to inform skeleton generation.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase A.1: Preliminary Research\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Generate 3-4 broad search queries\n",
    "    query_prompt = f\"\"\"Generate 4 search queries to understand the scope of this research question:\n",
    "    \n",
    "Question: {question}\n",
    "\n",
    "Return 4 queries, one per line, covering different aspects.\"\"\"\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=query_prompt)])\n",
    "    queries = [q.strip() for q in response.content.split(\"\\n\") if q.strip()][:4]\n",
    "    \n",
    "    all_results = []\n",
    "    all_urls = []\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"  Searching: {query[:50]}...\")\n",
    "        summary, results, urls = search_web(query, max_results=5)\n",
    "        # Convert SourcedEvidence objects to formatted strings for state storage\n",
    "        for r in results:\n",
    "            all_results.append(f\"[{r.title}] {r.content}\")\n",
    "        all_urls.extend(urls)\n",
    "    \n",
    "    print(f\"  Collected {len(all_results)} preliminary results\")\n",
    "    \n",
    "    return {\n",
    "        \"preliminary_findings\": all_results,\n",
    "        \"source_urls\": all_urls,\n",
    "        \"gate_1_attempts\": 0,\n",
    "        \"gate_1_passed\": False\n",
    "    }\n",
    "\n",
    "\n",
    "async def generate_skeleton(state: SFEOState) -> dict:\n",
    "    \"\"\"Generate the document skeleton structure.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    preliminary_findings = state.get(\"preliminary_findings\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase A.2: Skeleton Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    findings_summary = \"\\n\".join(preliminary_findings[:15])\n",
    "    \n",
    "    prompt = SKELETON_GENERATION_PROMPT.format(\n",
    "        question=question,\n",
    "        preliminary_findings=findings_summary\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SkeletonGenerationOutput)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Build skeleton dictionary\n",
    "    skeleton = {\n",
    "        \"thesis\": result.thesis,\n",
    "        \"root_nodes\": [],\n",
    "        \"nodes\": {},\n",
    "        \"style_constraints\": \"Academic tone, comprehensive analysis, evidence-based claims\"\n",
    "    }\n",
    "    \n",
    "    child_ids = set()\n",
    "    for section in result.sections:\n",
    "        child_ids.update(section.children)\n",
    "    \n",
    "    for section in result.sections:\n",
    "        skeleton[\"nodes\"][section.node_id] = section.model_dump()\n",
    "        if section.node_id not in child_ids:\n",
    "            skeleton[\"root_nodes\"].append(section.node_id)\n",
    "    \n",
    "    if not skeleton[\"root_nodes\"]:\n",
    "        for nid, node in skeleton[\"nodes\"].items():\n",
    "            if not node.get(\"dependencies\", []):\n",
    "                skeleton[\"root_nodes\"].append(nid)\n",
    "    \n",
    "    if not skeleton[\"root_nodes\"]:\n",
    "        skeleton[\"root_nodes\"] = list(skeleton[\"nodes\"].keys())\n",
    "    \n",
    "    print(f\"  Thesis: {result.thesis[:80]}...\")\n",
    "    print(f\"  Generated {len(skeleton['nodes'])} skeleton nodes:\")\n",
    "    for nid, node in skeleton[\"nodes\"].items():\n",
    "        deps = node.get('dependencies', [])\n",
    "        dep_str = f\" (depends: {', '.join(deps)})\" if deps else \"\"\n",
    "        print(f\"    - {nid}: {node['title']}{dep_str}\")\n",
    "    \n",
    "    return {\"skeleton\": skeleton}\n",
    "\n",
    "\n",
    "async def identify_claims(state: SFEOState) -> dict:\n",
    "    \"\"\"Extract verifiable claims from the skeleton's claim_placeholders.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase A.3: Claim Identification\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    claims_registry = {}\n",
    "    claim_counter = 1\n",
    "    \n",
    "    for node_id, node in skeleton[\"nodes\"].items():\n",
    "        placeholders = node.get(\"claim_placeholders\", [])\n",
    "        for placeholder in placeholders:\n",
    "            claim_id = f\"claim_{node_id}_{claim_counter}\"\n",
    "            claims_registry[claim_id] = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim_text\": placeholder,\n",
    "                \"source_node\": node_id,\n",
    "                \"verification_status\": \"unverified\",\n",
    "                \"supporting_evidence\": [],\n",
    "                \"claim_dependencies\": []\n",
    "            }\n",
    "            claim_counter += 1\n",
    "    \n",
    "    print(f\"  Extracted {len(claims_registry)} claims from skeleton:\")\n",
    "    for cid, claim in list(claims_registry.items())[:5]:\n",
    "        print(f\"    - {cid}: {claim['claim_text'][:50]}...\")\n",
    "    if len(claims_registry) > 5:\n",
    "        print(f\"    ... and {len(claims_registry) - 5} more\")\n",
    "    \n",
    "    return {\"claims_registry\": claims_registry}\n",
    "\n",
    "\n",
    "async def create_research_backlog(state: SFEOState) -> dict:\n",
    "    \"\"\"Create prioritized research backlog from claims.\"\"\"\n",
    "    claims_registry = state[\"claims_registry\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase A.4: Research Backlog Creation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    backlog = []\n",
    "    priority = 1\n",
    "    \n",
    "    for claim_id, claim in claims_registry.items():\n",
    "        # Generate search query from claim text\n",
    "        query = claim[\"claim_text\"]\n",
    "        if len(query) > 100:\n",
    "            query = query[:100]\n",
    "        \n",
    "        task = {\n",
    "            \"task_id\": f\"task_{claim_id}\",\n",
    "            \"claim_id\": claim_id,\n",
    "            \"query\": query,\n",
    "            \"priority\": priority,\n",
    "            \"status\": \"pending\",\n",
    "            \"evidence_found\": []\n",
    "        }\n",
    "        backlog.append(task)\n",
    "        priority += 1\n",
    "    \n",
    "    print(f\"  Created backlog with {len(backlog)} research tasks\")\n",
    "    \n",
    "    return {\n",
    "        \"research_backlog\": backlog,\n",
    "        \"evidence_map\": {},\n",
    "        \"current_sprint\": 1,\n",
    "        \"max_sprints\": SPRINT_CONFIG[\"max_sprints\"]\n",
    "    }\n",
    "\n",
    "\n",
    "async def skeleton_quality_gate(state: SFEOState) -> dict:\n",
    "    \"\"\"Gate 1: Evaluate skeleton quality.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    question = state[\"question\"]\n",
    "    attempts = state.get(\"gate_1_attempts\", 0) + 1\n",
    "    \n",
    "    print(f\"\\n--- Gate 1: Skeleton Quality (Attempt {attempts}/{GATE_1_CONFIG['max_attempts'] + 1}) ---\")\n",
    "    \n",
    "    # Build sections summary\n",
    "    sections_summary = \"\\n\".join([\n",
    "        f\"- {nid}: {node['title']} - {node.get('intent', '')[:60]}...\"\n",
    "        for nid, node in skeleton[\"nodes\"].items()\n",
    "    ])\n",
    "    \n",
    "    prompt = GATE_1_EVALUATION_PROMPT.format(\n",
    "        question=question,\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        sections_summary=sections_summary\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse scores\n",
    "    scores = {}\n",
    "    for metric in [\"THESIS_CLARITY\", \"COVERAGE\", \"STRUCTURE\", \"CLAIM_SPECIFICITY\", \"OVERALL\"]:\n",
    "        match = re.search(rf'{metric}:\\s*(\\d+(?:\\.\\d+)?)', content)\n",
    "        if match:\n",
    "            scores[metric.lower()] = float(match.group(1))\n",
    "    \n",
    "    overall = scores.get(\"overall\", 7.0)\n",
    "    \n",
    "    # Check if passes\n",
    "    passed = (\n",
    "        scores.get(\"thesis_clarity\", 0) >= GATE_1_CONFIG[\"thesis_clarity_threshold\"] and\n",
    "        scores.get(\"structure\", 0) >= GATE_1_CONFIG[\"structure_threshold\"] and\n",
    "        overall >= 6.5\n",
    "    )\n",
    "    \n",
    "    print(f\"  Thesis Clarity: {scores.get('thesis_clarity', 'N/A')}/10\")\n",
    "    print(f\"  Coverage: {scores.get('coverage', 'N/A')}/10\")\n",
    "    print(f\"  Structure: {scores.get('structure', 'N/A')}/10\")\n",
    "    print(f\"  Overall: {overall}/10\")\n",
    "    print(f\"  {'PASSED' if passed else 'FAILED'} Gate 1\")\n",
    "    \n",
    "    return {\n",
    "        \"gate_1_attempts\": attempts,\n",
    "        \"gate_1_passed\": passed\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_gate_1(state: SFEOState) -> Literal[\"initialize_cache\", \"refine_skeleton\", \"initialize_cache_anyway\"]:\n",
    "    \"\"\"Route based on Gate 1 result.\"\"\"\n",
    "    passed = state.get(\"gate_1_passed\", False)\n",
    "    attempts = state.get(\"gate_1_attempts\", 0)\n",
    "    \n",
    "    if passed:\n",
    "        return \"initialize_cache\"\n",
    "    elif attempts <= GATE_1_CONFIG[\"max_attempts\"]:\n",
    "        return \"refine_skeleton\"\n",
    "    else:\n",
    "        print(\"  Max Gate 1 attempts reached. Proceeding anyway.\")\n",
    "        return \"initialize_cache_anyway\"\n",
    "\n",
    "\n",
    "async def refine_skeleton(state: SFEOState) -> dict:\n",
    "    \"\"\"Refine skeleton after Gate 1 failure.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n  Refining skeleton...\")\n",
    "    \n",
    "    # Simple refinement: regenerate with emphasis on issues\n",
    "    prompt = f\"\"\"The previous skeleton for this question had quality issues. Generate an improved version.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Previous thesis: {skeleton.get('thesis', '')}\n",
    "\n",
    "Improve:\n",
    "1. Make the thesis more specific and arguable\n",
    "2. Ensure all question aspects are covered\n",
    "3. Make claim_placeholders more specific and searchable\n",
    "\"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SkeletonGenerationOutput)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Rebuild skeleton\n",
    "    new_skeleton = {\n",
    "        \"thesis\": result.thesis,\n",
    "        \"root_nodes\": [],\n",
    "        \"nodes\": {},\n",
    "        \"style_constraints\": skeleton.get(\"style_constraints\", \"\")\n",
    "    }\n",
    "    \n",
    "    for section in result.sections:\n",
    "        new_skeleton[\"nodes\"][section.node_id] = section.model_dump()\n",
    "        new_skeleton[\"root_nodes\"].append(section.node_id)\n",
    "    \n",
    "    print(f\"  Refined skeleton with {len(new_skeleton['nodes'])} sections\")\n",
    "    \n",
    "    return {\"skeleton\": new_skeleton}\n",
    "\n",
    "\n",
    "print(\"Phase A node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase B: Evidence Gathering\n",
    "\n",
    "Phase B executes sprint-based evidence collection with cache integration:\n",
    "1. Initialize session knowledge base\n",
    "2. Sprint loop: plan → cache-aware search → update claims → retrospective\n",
    "3. Gate 2: Validate evidence sufficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase B node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def initialize_cache(state: SFEOState) -> dict:\n",
    "    \"\"\"Initialize the session knowledge base.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase B.0: Initialize Knowledge Cache\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    knowledge_base = KnowledgeBase()\n",
    "    \n",
    "    # Pre-populate cache with preliminary findings\n",
    "    preliminary = state.get(\"preliminary_findings\", [])\n",
    "    if preliminary:\n",
    "        content = \"\\n\\n\".join(preliminary)\n",
    "        knowledge_base.add_document(\n",
    "            \"preliminary://research\",\n",
    "            content,\n",
    "            title=\"Preliminary Research\",\n",
    "            source_query=state[\"question\"]\n",
    "        )\n",
    "        print(f\"  Pre-populated cache with {len(preliminary)} preliminary findings\")\n",
    "    \n",
    "    print(f\"  Knowledge base initialized\")\n",
    "    \n",
    "    return {\n",
    "        \"should_stop_sprinting\": False,\n",
    "        \"gate_2_attempts\": 0,\n",
    "        \"gate_2_passed\": False\n",
    "    }\n",
    "\n",
    "\n",
    "async def sprint_execute(state: SFEOState) -> dict:\n",
    "    \"\"\"Execute a research sprint with cache-aware searching.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    current_sprint = state.get(\"current_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_sprints\", SPRINT_CONFIG[\"max_sprints\"])\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    evidence_map = state.get(\"evidence_map\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase B.1: Sprint {current_sprint}/{max_sprints}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get unverified claims for this sprint\n",
    "    unverified = [\n",
    "        (cid, claim) for cid, claim in claims_registry.items()\n",
    "        if claim.get(\"verification_status\") == \"unverified\"\n",
    "    ]\n",
    "    \n",
    "    claims_to_verify = unverified[:SPRINT_CONFIG[\"claims_per_sprint\"]]\n",
    "    \n",
    "    if not claims_to_verify:\n",
    "        print(\"  No unverified claims remaining\")\n",
    "        return {\n",
    "            \"should_stop_sprinting\": True,\n",
    "            \"sprint_findings\": [\"No unverified claims remaining in sprint\"]\n",
    "        }\n",
    "    \n",
    "    print(f\"  Verifying {len(claims_to_verify)} claims this sprint\")\n",
    "    \n",
    "    findings = []\n",
    "    all_urls = []\n",
    "    cache_decisions = []\n",
    "    verified_count = 0\n",
    "    cache_hits = 0\n",
    "    \n",
    "    for claim_id, claim in claims_to_verify:\n",
    "        query = claim[\"claim_text\"][:150]  # Truncate for search\n",
    "        \n",
    "        print(f\"\\n  [{claim_id}] {query[:50]}...\")\n",
    "        \n",
    "        # Execute cache-aware search - returns List[SourcedEvidence]\n",
    "        evidence_list, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "        \n",
    "        cache_decisions.append(decision.model_dump())\n",
    "        all_urls.extend(urls)\n",
    "        \n",
    "        if decision.action_taken == \"USE_CACHE\":\n",
    "            cache_hits += 1\n",
    "            print(f\"    CACHE HIT ({decision.layer_reached})\")\n",
    "        else:\n",
    "            print(f\"    WEB SEARCH ({decision.layer_reached})\")\n",
    "        \n",
    "        # Update claim verification with structured evidence\n",
    "        claims_registry[claim_id][\"verification_status\"] = \"verified\"\n",
    "        # Store evidence as list of dicts with content AND source URL\n",
    "        claims_registry[claim_id][\"supporting_evidence\"] = [\n",
    "            {\"content\": e.content[:500], \"source_url\": e.source_url, \"title\": e.title}\n",
    "            for e in evidence_list[:3]\n",
    "        ]\n",
    "        verified_count += 1\n",
    "        \n",
    "        # Update evidence map with STRUCTURED evidence (content + URL)\n",
    "        if claim_id not in evidence_map:\n",
    "            evidence_map[claim_id] = []\n",
    "        evidence_map[claim_id] = [\n",
    "            {\"content\": e.content, \"source_url\": e.source_url, \"title\": e.title}\n",
    "            for e in evidence_list[:3]  # Keep top 3 sources per claim\n",
    "        ]\n",
    "        \n",
    "        findings.append(f\"[{claim_id}] {claim['claim_text'][:80]}... - VERIFIED with {len(urls)} sources\")\n",
    "    \n",
    "    hit_rate = cache_hits / len(claims_to_verify) * 100 if claims_to_verify else 0\n",
    "    \n",
    "    print(f\"\\n  Sprint {current_sprint} Complete:\")\n",
    "    print(f\"    Claims verified: {verified_count}\")\n",
    "    print(f\"    Cache hits: {cache_hits}/{len(claims_to_verify)} ({hit_rate:.1f}%)\")\n",
    "    print(f\"    New URLs collected: {len(all_urls)}\")\n",
    "    \n",
    "    finding_summary = f\"## Sprint {current_sprint} Findings\\n\\n\" + \"\\n\".join(findings)\n",
    "    \n",
    "    return {\n",
    "        \"claims_registry\": claims_registry,\n",
    "        \"evidence_map\": evidence_map,\n",
    "        \"sprint_findings\": [finding_summary],\n",
    "        \"source_urls\": all_urls,\n",
    "        \"cache_decisions\": cache_decisions\n",
    "    }\n",
    "\n",
    "\n",
    "async def sprint_retrospective(state: SFEOState) -> dict:\n",
    "    \"\"\"Conduct retrospective after sprint to decide continuation.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    current_sprint = state.get(\"current_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_sprints\", SPRINT_CONFIG[\"max_sprints\"])\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase B.2: Sprint {current_sprint} Retrospective\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Count verified vs unverified\n",
    "    verified = [c for c in claims_registry.values() if c.get(\"verification_status\") == \"verified\"]\n",
    "    unverified = [c for c in claims_registry.values() if c.get(\"verification_status\") == \"unverified\"]\n",
    "    \n",
    "    total_queries = knowledge_base.stats[\"total_queries\"]\n",
    "    cache_hits = knowledge_base.stats[\"web_searches_avoided\"]\n",
    "    hit_rate = cache_hits / total_queries * 100 if total_queries else 0\n",
    "    \n",
    "    print(f\"  Claims: {len(verified)} verified, {len(unverified)} remaining\")\n",
    "    print(f\"  Cache: {cache_hits}/{total_queries} hits ({hit_rate:.1f}%)\")\n",
    "    \n",
    "    # Decide whether to continue\n",
    "    should_stop = False\n",
    "    reason = \"\"\n",
    "    \n",
    "    if current_sprint >= max_sprints:\n",
    "        should_stop = True\n",
    "        reason = \"Max sprints reached\"\n",
    "    elif len(unverified) == 0:\n",
    "        should_stop = True\n",
    "        reason = \"All claims verified\"\n",
    "    elif len(verified) >= len(claims_registry) * 0.8:  # 80% verified\n",
    "        should_stop = True\n",
    "        reason = \"Sufficient coverage (80%+ verified)\"\n",
    "    \n",
    "    if should_stop:\n",
    "        print(f\"  Decision: STOP ({reason})\")\n",
    "    else:\n",
    "        print(f\"  Decision: CONTINUE to sprint {current_sprint + 1}\")\n",
    "    \n",
    "    retro_note = f\"### Sprint {current_sprint} Retrospective\\n\"\n",
    "    retro_note += f\"- Verified: {len(verified)}/{len(claims_registry)}\\n\"\n",
    "    retro_note += f\"- Cache hit rate: {hit_rate:.1f}%\\n\"\n",
    "    retro_note += f\"- Decision: {'STOP' if should_stop else 'CONTINUE'}\"\n",
    "    \n",
    "    return {\n",
    "        \"current_sprint\": current_sprint + 1,\n",
    "        \"should_stop_sprinting\": should_stop,\n",
    "        \"retrospective_notes\": [retro_note]\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_sprint(state: SFEOState) -> Literal[\"sprint_execute\", \"evidence_quality_gate\"]:\n",
    "    \"\"\"Route based on sprint retrospective decision.\"\"\"\n",
    "    should_stop = state.get(\"should_stop_sprinting\", False)\n",
    "    \n",
    "    if should_stop:\n",
    "        return \"evidence_quality_gate\"\n",
    "    else:\n",
    "        return \"sprint_execute\"\n",
    "\n",
    "\n",
    "async def evidence_quality_gate(state: SFEOState) -> dict:\n",
    "    \"\"\"Gate 2: Validate evidence sufficiency.\"\"\"\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    source_urls = state.get(\"source_urls\", [])\n",
    "    attempts = state.get(\"gate_2_attempts\", 0) + 1\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    \n",
    "    print(f\"\\n--- Gate 2: Evidence Sufficiency (Attempt {attempts}/{GATE_2_CONFIG['max_emergency_attempts'] + 1}) ---\")\n",
    "    \n",
    "    # Check verification rate\n",
    "    verified = [c for c in claims_registry.values() if c.get(\"verification_status\") == \"verified\"]\n",
    "    verification_rate = len(verified) / len(claims_registry) if claims_registry else 0\n",
    "    \n",
    "    # Check domain diversity\n",
    "    domains = set(extract_domain(url) for url in source_urls)\n",
    "    \n",
    "    # Check section coverage\n",
    "    covered_sections = set()\n",
    "    for claim in verified:\n",
    "        covered_sections.add(claim.get(\"source_node\"))\n",
    "    section_coverage = len(covered_sections) / len(skeleton.get(\"nodes\", {})) if skeleton.get(\"nodes\") else 0\n",
    "    \n",
    "    print(f\"  Verification rate: {verification_rate:.1%} (threshold: {GATE_2_CONFIG['verification_rate_threshold']:.0%})\")\n",
    "    print(f\"  Domain diversity: {len(domains)} (threshold: {GATE_2_CONFIG['min_domain_diversity']})\")\n",
    "    print(f\"  Section coverage: {section_coverage:.1%} (threshold: {GATE_2_CONFIG['section_coverage_threshold']:.0%})\")\n",
    "    \n",
    "    passed = (\n",
    "        verification_rate >= GATE_2_CONFIG[\"verification_rate_threshold\"] and\n",
    "        len(domains) >= GATE_2_CONFIG[\"min_domain_diversity\"] and\n",
    "        section_coverage >= GATE_2_CONFIG[\"section_coverage_threshold\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"  {'PASSED' if passed else 'FAILED'} Gate 2\")\n",
    "    \n",
    "    return {\n",
    "        \"gate_2_attempts\": attempts,\n",
    "        \"gate_2_passed\": passed\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_gate_2(state: SFEOState) -> Literal[\"generate_prose\", \"emergency_research\", \"generate_prose_anyway\"]:\n",
    "    \"\"\"Route based on Gate 2 result.\"\"\"\n",
    "    passed = state.get(\"gate_2_passed\", False)\n",
    "    attempts = state.get(\"gate_2_attempts\", 0)\n",
    "    \n",
    "    if passed:\n",
    "        return \"generate_prose\"\n",
    "    elif attempts <= GATE_2_CONFIG[\"max_emergency_attempts\"]:\n",
    "        return \"emergency_research\"\n",
    "    else:\n",
    "        print(\"  Max Gate 2 attempts reached. Proceeding with available evidence.\")\n",
    "        return \"generate_prose_anyway\"\n",
    "\n",
    "\n",
    "async def emergency_research(state: SFEOState) -> dict:\n",
    "    \"\"\"Conduct targeted research to fill evidence gaps.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    evidence_map = state.get(\"evidence_map\", {})\n",
    "    \n",
    "    print(f\"\\n  Emergency research for evidence gaps...\")\n",
    "    \n",
    "    # Find uncovered sections\n",
    "    covered_sections = set()\n",
    "    for claim in claims_registry.values():\n",
    "        if claim.get(\"verification_status\") == \"verified\":\n",
    "            covered_sections.add(claim.get(\"source_node\"))\n",
    "    \n",
    "    uncovered = [nid for nid in skeleton.get(\"nodes\", {}).keys() if nid not in covered_sections]\n",
    "    \n",
    "    new_urls = []\n",
    "    cache_decisions = []\n",
    "    \n",
    "    for node_id in uncovered[:3]:  # Limit emergency searches\n",
    "        node = skeleton[\"nodes\"].get(node_id, {})\n",
    "        query = f\"{node.get('title', '')} {node.get('intent', '')[:50]}\"\n",
    "        \n",
    "        print(f\"  Emergency search for {node_id}: {query[:40]}...\")\n",
    "        \n",
    "        # Returns List[SourcedEvidence]\n",
    "        evidence_list, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "        new_urls.extend(urls)\n",
    "        cache_decisions.append(decision.model_dump())\n",
    "        \n",
    "        # Store emergency evidence in evidence map with synthetic claim\n",
    "        synthetic_claim_id = f\"emergency_{node_id}\"\n",
    "        evidence_map[synthetic_claim_id] = [\n",
    "            {\"content\": e.content, \"source_url\": e.source_url, \"title\": e.title}\n",
    "            for e in evidence_list[:2]\n",
    "        ]\n",
    "    \n",
    "    print(f\"  Emergency research collected {len(new_urls)} new URLs\")\n",
    "    \n",
    "    return {\n",
    "        \"source_urls\": new_urls,\n",
    "        \"cache_decisions\": cache_decisions,\n",
    "        \"evidence_map\": evidence_map\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase B node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phase C: Document Construction\n",
    "\n",
    "Phase C generates the document from verified claims:\n",
    "1. Generate prose patches for each skeleton node\n",
    "2. Create bridge sentences for transitions\n",
    "3. Assemble complete draft\n",
    "4. Gate 3: Validate prose quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase C node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def generate_prose(state: SFEOState) -> dict:\n",
    "    \"\"\"Generate prose patches for each skeleton node.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    evidence_map = state.get(\"evidence_map\", {})\n",
    "    source_urls = state.get(\"source_urls\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase C.1: Prose Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_nodes = topological_sort_nodes(skeleton, leaf_nodes)\n",
    "    \n",
    "    prose_store = {}\n",
    "    # Track all references used globally for final references section\n",
    "    global_references = {}  # {ref_num: {\"url\": url, \"title\": title}}\n",
    "    ref_counter = 1\n",
    "    \n",
    "    for i, node_id in enumerate(sorted_nodes):\n",
    "        # Safety check: skip nodes that don't exist in skeleton\n",
    "        if node_id not in skeleton[\"nodes\"]:\n",
    "            print(f\"  [{i+1}/{len(sorted_nodes)}] Skipping invalid node: {node_id}\")\n",
    "            continue\n",
    "        \n",
    "        node = skeleton[\"nodes\"][node_id]\n",
    "        \n",
    "        print(f\"  [{i+1}/{len(sorted_nodes)}] Generating: {node_id} - {node['title']}\")\n",
    "        \n",
    "        # Get claims for this node with their evidence\n",
    "        node_claims = [\n",
    "            (cid, claim) for cid, claim in claims_registry.items()\n",
    "            if claim.get(\"source_node\") == node_id\n",
    "        ]\n",
    "        \n",
    "        # Build NUMBERED evidence list with clear source attribution\n",
    "        numbered_evidence = []\n",
    "        local_ref_map = {}  # Map local refs to global refs for this node\n",
    "        local_ref = 1\n",
    "        \n",
    "        for cid, claim in node_claims:\n",
    "            evidence_list = evidence_map.get(cid, [])\n",
    "            for evidence_item in evidence_list[:2]:  # Max 2 per claim\n",
    "                if isinstance(evidence_item, dict):\n",
    "                    content = evidence_item.get(\"content\", \"\")[:500]\n",
    "                    source_url = evidence_item.get(\"source_url\", \"unknown\")\n",
    "                    title = evidence_item.get(\"title\", \"\")\n",
    "                else:\n",
    "                    # Fallback for old string format\n",
    "                    content = str(evidence_item)[:500]\n",
    "                    source_url = \"unknown\"\n",
    "                    title = \"\"\n",
    "                \n",
    "                # Add to global references if not already there\n",
    "                url_key = source_url\n",
    "                if url_key not in [r.get(\"url\") for r in global_references.values()]:\n",
    "                    global_references[ref_counter] = {\"url\": source_url, \"title\": title}\n",
    "                    local_ref_map[local_ref] = ref_counter\n",
    "                    ref_counter += 1\n",
    "                else:\n",
    "                    # Find existing ref number\n",
    "                    for rnum, rdata in global_references.items():\n",
    "                        if rdata.get(\"url\") == source_url:\n",
    "                            local_ref_map[local_ref] = rnum\n",
    "                            break\n",
    "                \n",
    "                numbered_evidence.append(\n",
    "                    f\"[{local_ref}] Source: {title or extract_domain(source_url)}\\n\"\n",
    "                    f\"    Content: {content}\"\n",
    "                )\n",
    "                local_ref += 1\n",
    "        \n",
    "        if not numbered_evidence:\n",
    "            numbered_evidence = [\"No specific evidence available for this section.\"]\n",
    "        \n",
    "        # Get context from adjacent nodes\n",
    "        prev_node, next_node = get_adjacent_nodes(skeleton, node_id)\n",
    "        prev_summary = \"\"\n",
    "        next_preview = \"\"\n",
    "        \n",
    "        if prev_node and prev_node in prose_store:\n",
    "            prev_summary = prose_store[prev_node].get(\"summary\", \"\")\n",
    "        if next_node:\n",
    "            next_node_data = skeleton[\"nodes\"].get(next_node, {})\n",
    "            next_preview = next_node_data.get(\"intent\", \"\")\n",
    "        \n",
    "        prompt = PROSE_GENERATION_PROMPT.format(\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            target_words=node.get(\"target_word_count\", 300),\n",
    "            numbered_evidence=\"\\n\\n\".join(numbered_evidence),\n",
    "            prev_summary=prev_summary if prev_summary else \"(First section)\",\n",
    "            next_preview=next_preview if next_preview else \"(Last section)\"\n",
    "        )\n",
    "        \n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "        \n",
    "        try:\n",
    "            result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "            \n",
    "            prose_store[node_id] = {\n",
    "                \"node_id\": node_id,\n",
    "                \"main_content\": result.main_content,\n",
    "                \"bridge_in\": result.bridge_in,\n",
    "                \"bridge_out\": result.bridge_out,\n",
    "                \"summary\": result.summary,\n",
    "                \"revision_count\": 0,\n",
    "                \"citations_used\": result.citations_used\n",
    "            }\n",
    "            \n",
    "            print(f\"      Generated {len(result.main_content)} chars\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      Error generating prose: {e}\")\n",
    "            prose_store[node_id] = {\n",
    "                \"node_id\": node_id,\n",
    "                \"main_content\": f\"[Content generation failed for {node['title']}]\",\n",
    "                \"bridge_in\": \"\",\n",
    "                \"bridge_out\": \"\",\n",
    "                \"summary\": \"\",\n",
    "                \"revision_count\": 0,\n",
    "                \"citations_used\": []\n",
    "            }\n",
    "        \n",
    "        # Mark as expanded in skeleton\n",
    "        skeleton[\"nodes\"][node_id][\"is_expanded\"] = True\n",
    "        \n",
    "        # Store reference mapping for this node\n",
    "        prose_store[node_id][\"reference_map\"] = local_ref_map\n",
    "    \n",
    "    print(f\"  Total references tracked: {len(global_references)}\")\n",
    "    \n",
    "    return {\n",
    "        \"skeleton\": skeleton,\n",
    "        \"prose_store\": prose_store,\n",
    "        \"global_references\": global_references  # Pass to assembly\n",
    "    }\n",
    "\n",
    "\n",
    "async def assemble_draft(state: SFEOState) -> dict:\n",
    "    \"\"\"Assemble all prose patches into a complete draft.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    global_references = state.get(\"global_references\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase C.2: Draft Assembly\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    \n",
    "    # Build document\n",
    "    document_parts = []\n",
    "    \n",
    "    # Title and thesis\n",
    "    document_parts.append(f\"# Research Report\\n\\n\")\n",
    "    document_parts.append(f\"**Thesis:** {skeleton.get('thesis', '')}\\n\\n\")\n",
    "    document_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Sections\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "        \n",
    "        node = skeleton[\"nodes\"].get(node_id, {})\n",
    "        prose = prose_store[node_id]\n",
    "        \n",
    "        document_parts.append(f\"## {node.get('title', node_id)}\\n\\n\")\n",
    "        \n",
    "        # Bridge in flows naturally\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            document_parts.append(f\"{prose['bridge_in']} \")\n",
    "        \n",
    "        document_parts.append(f\"{prose.get('main_content', '')}\")\n",
    "        \n",
    "        if prose.get(\"bridge_out\"):\n",
    "            document_parts.append(f\" {prose['bridge_out']}\")\n",
    "        \n",
    "        document_parts.append(\"\\n\\n\")\n",
    "    \n",
    "    # Build proper numbered References section from global_references\n",
    "    if global_references:\n",
    "        document_parts.append(\"---\\n\\n## References\\n\\n\")\n",
    "        for ref_num in sorted(global_references.keys()):\n",
    "            ref_data = global_references[ref_num]\n",
    "            url = ref_data.get(\"url\", \"\")\n",
    "            title = ref_data.get(\"title\", \"\")\n",
    "            if title and url:\n",
    "                document_parts.append(f\"[{ref_num}] {title}. {url}\\n\\n\")\n",
    "            elif url:\n",
    "                document_parts.append(f\"[{ref_num}] {url}\\n\\n\")\n",
    "    \n",
    "    assembled_draft = \"\".join(document_parts)\n",
    "    word_count = len(assembled_draft.split())\n",
    "    \n",
    "    print(f\"  Assembled draft: {len(assembled_draft)} chars, {word_count} words\")\n",
    "    print(f\"  Sections: {len(leaf_nodes)}\")\n",
    "    print(f\"  References: {len(global_references)}\")\n",
    "    \n",
    "    return {\n",
    "        \"assembled_draft\": assembled_draft,\n",
    "        \"gate_3_passed\": False,\n",
    "        \"gate_3_scores\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "async def prose_quality_gate(state: SFEOState) -> dict:\n",
    "    \"\"\"Gate 3: Evaluate prose quality.\"\"\"\n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n--- Gate 3: Prose Quality ---\")\n",
    "    \n",
    "    # Truncate draft for evaluation\n",
    "    draft_for_eval = assembled_draft[:8000] if len(assembled_draft) > 8000 else assembled_draft\n",
    "    \n",
    "    prompt = GATE_3_EVALUATION_PROMPT.format(\n",
    "        question=question,\n",
    "        draft=draft_for_eval\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse scores\n",
    "    scores = {}\n",
    "    for metric in [\"COHERENCE\", \"DEPTH\", \"EVIDENCE\", \"COMPLETENESS\", \"OVERALL\"]:\n",
    "        match = re.search(rf'{metric}:\\s*(\\d+(?:\\.\\d+)?)', content)\n",
    "        if match:\n",
    "            scores[metric.lower()] = float(match.group(1))\n",
    "    \n",
    "    overall = scores.get(\"overall\", 7.0)\n",
    "    \n",
    "    passed = (\n",
    "        scores.get(\"coherence\", 0) >= GATE_3_CONFIG[\"coherence_threshold\"] and\n",
    "        scores.get(\"depth\", 0) >= GATE_3_CONFIG[\"depth_threshold\"] and\n",
    "        overall >= 6.5\n",
    "    )\n",
    "    \n",
    "    print(f\"  Coherence: {scores.get('coherence', 'N/A')}/10\")\n",
    "    print(f\"  Depth: {scores.get('depth', 'N/A')}/10\")\n",
    "    print(f\"  Evidence: {scores.get('evidence', 'N/A')}/10\")\n",
    "    print(f\"  Overall: {overall}/10\")\n",
    "    print(f\"  {'PASSED' if passed else 'FAILED'} Gate 3\")\n",
    "    \n",
    "    return {\n",
    "        \"gate_3_passed\": passed,\n",
    "        \"gate_3_scores\": scores,\n",
    "        \"quality_scores\": [overall],\n",
    "        \"iteration_count\": 0,\n",
    "        \"noise_map\": [],\n",
    "        \"nodes_to_patch\": []\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase C node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Phase D: Refinement & Polish\n",
    "\n",
    "Phase D implements the critique-patch loop:\n",
    "1. Structured critique producing noise map\n",
    "2. Targeted retrieval for evidence gaps\n",
    "3. Apply patches to specific nodes\n",
    "4. Check for cascades and convergence\n",
    "5. Final polish for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase D node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def structured_critique(state: SFEOState) -> dict:\n",
    "    \"\"\"Perform multi-level critique producing noise map.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    question = state[\"question\"]\n",
    "    iteration_count = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase D.1: Structured Critique (Iteration {iteration_count})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build skeleton summary\n",
    "    skeleton_summary = \"\\n\".join([\n",
    "        f\"- {nid}: {node['title']}\"\n",
    "        for nid, node in skeleton[\"nodes\"].items()\n",
    "    ])\n",
    "    \n",
    "    # Build claims summary\n",
    "    claims_summary = \"\\n\".join([\n",
    "        f\"- [{c['verification_status']}] {cid}: {c['claim_text'][:60]}...\"\n",
    "        for cid, c in list(claims_registry.items())[:15]\n",
    "    ])\n",
    "    \n",
    "    # Truncate draft for critique\n",
    "    draft_for_critique = assembled_draft[:10000] if len(assembled_draft) > 10000 else assembled_draft\n",
    "    \n",
    "    prompt = STRUCTURED_CRITIQUE_PROMPT.format(\n",
    "        question=question,\n",
    "        skeleton_summary=skeleton_summary,\n",
    "        claims_summary=claims_summary,\n",
    "        draft=draft_for_critique\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(CritiqueResult)\n",
    "    \n",
    "    try:\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        noise_map = [issue.model_dump() for issue in result.issues]\n",
    "        \n",
    "        # Identify nodes needing patches\n",
    "        nodes_to_patch = list(set(\n",
    "            node_id\n",
    "            for issue in result.issues\n",
    "            for node_id in issue.target_nodes\n",
    "            if issue.severity in [\"critical\", \"major\"]\n",
    "        ))\n",
    "        \n",
    "        print(f\"  Quality Score: {result.overall_quality}/10\")\n",
    "        print(f\"  Issues found: {len(result.issues)}\")\n",
    "        print(f\"    - Critical: {sum(1 for i in result.issues if i.severity == 'critical')}\")\n",
    "        print(f\"    - Major: {sum(1 for i in result.issues if i.severity == 'major')}\")\n",
    "        print(f\"    - Minor: {sum(1 for i in result.issues if i.severity == 'minor')}\")\n",
    "        print(f\"  Nodes to patch: {nodes_to_patch}\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_map\": noise_map,\n",
    "            \"nodes_to_patch\": nodes_to_patch,\n",
    "            \"quality_scores\": [result.overall_quality]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error in critique: {e}\")\n",
    "        return {\n",
    "            \"noise_map\": [],\n",
    "            \"nodes_to_patch\": [],\n",
    "            \"quality_scores\": [7.0]  # Default score\n",
    "        }\n",
    "\n",
    "\n",
    "def should_continue_refinement(state: SFEOState) -> Literal[\"targeted_retrieval\", \"final_polish\"]:\n",
    "    \"\"\"Determine if another refinement iteration is needed.\"\"\"\n",
    "    iteration_count = state.get(\"iteration_count\", 0)\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    \n",
    "    latest_score = quality_scores[-1] if quality_scores else 0\n",
    "    \n",
    "    print(f\"\\n--- Convergence Check ---\")\n",
    "    print(f\"  Iteration: {iteration_count}/{REFINEMENT_CONFIG['max_iterations']}\")\n",
    "    print(f\"  Quality: {latest_score}/{REFINEMENT_CONFIG['quality_threshold']}\")\n",
    "    print(f\"  Nodes to patch: {len(nodes_to_patch)}\")\n",
    "    \n",
    "    # Convergence conditions\n",
    "    if iteration_count >= REFINEMENT_CONFIG[\"max_iterations\"]:\n",
    "        print(f\"  -> Max iterations reached. Finalizing.\")\n",
    "        return \"final_polish\"\n",
    "    \n",
    "    if latest_score >= REFINEMENT_CONFIG[\"quality_threshold\"]:\n",
    "        print(f\"  -> Quality threshold met. Finalizing.\")\n",
    "        return \"final_polish\"\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(f\"  -> No critical/major issues. Finalizing.\")\n",
    "        return \"final_polish\"\n",
    "    \n",
    "    # Check for diminishing returns\n",
    "    if len(quality_scores) >= 2:\n",
    "        improvement = quality_scores[-1] - quality_scores[-2]\n",
    "        if improvement < REFINEMENT_CONFIG[\"min_improvement_threshold\"]:\n",
    "            print(f\"  -> Diminishing returns ({improvement:.2f}). Finalizing.\")\n",
    "            return \"final_polish\"\n",
    "    \n",
    "    print(f\"  -> Continuing refinement.\")\n",
    "    return \"targeted_retrieval\"\n",
    "\n",
    "\n",
    "async def targeted_retrieval(state: SFEOState) -> dict:\n",
    "    \"\"\"Search for evidence to address specific issues in the noise map.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    global_references = state.get(\"global_references\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase D.2: Targeted Retrieval\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No nodes need patching - skipping retrieval\")\n",
    "        return {\"source_urls\": [], \"cache_decisions\": [], \"targeted_evidence\": {}}\n",
    "    \n",
    "    # Collect search queries from issues\n",
    "    targeted_evidence = {}  # node_id -> List[SourcedEvidence]\n",
    "    all_urls = []\n",
    "    cache_decisions = []\n",
    "    \n",
    "    # Track new references\n",
    "    ref_counter = max(global_references.keys()) + 1 if global_references else 1\n",
    "    \n",
    "    for issue in noise_map:\n",
    "        if issue.get(\"search_query\") and issue.get(\"severity\") in [\"critical\", \"major\"]:\n",
    "            query = issue[\"search_query\"]\n",
    "            \n",
    "            for node_id in issue.get(\"target_nodes\", []):\n",
    "                if node_id in nodes_to_patch:\n",
    "                    print(f\"  Searching for {node_id}: {query[:40]}...\")\n",
    "                    \n",
    "                    # Returns List[SourcedEvidence]\n",
    "                    evidence_list, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "                    \n",
    "                    if node_id not in targeted_evidence:\n",
    "                        targeted_evidence[node_id] = []\n",
    "                    targeted_evidence[node_id].extend(evidence_list[:2])\n",
    "                    \n",
    "                    # Add to global references\n",
    "                    for ev in evidence_list[:2]:\n",
    "                        if ev.source_url not in [r.get(\"url\") for r in global_references.values()]:\n",
    "                            global_references[ref_counter] = {\"url\": ev.source_url, \"title\": ev.title}\n",
    "                            ref_counter += 1\n",
    "                    \n",
    "                    all_urls.extend(urls)\n",
    "                    cache_decisions.append(decision.model_dump())\n",
    "    \n",
    "    print(f\"  Targeted retrieval complete: {len(all_urls)} new URLs\")\n",
    "    \n",
    "    return {\n",
    "        \"source_urls\": all_urls,\n",
    "        \"cache_decisions\": cache_decisions,\n",
    "        \"targeted_evidence\": {k: [e.model_dump() for e in v] for k, v in targeted_evidence.items()},\n",
    "        \"global_references\": global_references\n",
    "    }\n",
    "\n",
    "\n",
    "async def apply_patches(state: SFEOState) -> dict:\n",
    "    \"\"\"Apply targeted patches to nodes with issues.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    iteration_count = state.get(\"iteration_count\", 0)\n",
    "    targeted_evidence = state.get(\"targeted_evidence\", {})\n",
    "    global_references = state.get(\"global_references\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase D.3: Patch Application\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No patches to apply\")\n",
    "        return {\n",
    "            \"prose_store\": prose_store,\n",
    "            \"iteration_count\": iteration_count + 1\n",
    "        }\n",
    "    \n",
    "    sorted_patch_nodes = topological_sort_nodes(skeleton, nodes_to_patch)\n",
    "    patched_count = 0\n",
    "    \n",
    "    for node_id in sorted_patch_nodes[:REFINEMENT_CONFIG[\"max_cascades_per_iteration\"]]:\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "        \n",
    "        node = skeleton[\"nodes\"].get(node_id, {})\n",
    "        current_prose = prose_store[node_id]\n",
    "        \n",
    "        print(f\"  Patching: {node_id}\")\n",
    "        \n",
    "        # Collect issues for this node\n",
    "        node_issues = [\n",
    "            issue for issue in noise_map\n",
    "            if node_id in issue.get(\"target_nodes\", [])\n",
    "        ]\n",
    "        issues_text = \"\\n\".join([\n",
    "            f\"- [{i.get('severity', '')}] {i.get('issue_type', '')}: {i.get('description', '')}\"\n",
    "            for i in node_issues\n",
    "        ])\n",
    "        \n",
    "        # Format targeted evidence for this node\n",
    "        node_evidence = targeted_evidence.get(node_id, [])\n",
    "        evidence_text = \"\"\n",
    "        if node_evidence:\n",
    "            evidence_parts = []\n",
    "            for i, ev in enumerate(node_evidence[:3], 1):\n",
    "                if isinstance(ev, dict):\n",
    "                    evidence_parts.append(f\"[{i}] {ev.get('title', 'Source')}: {ev.get('content', '')[:400]}\")\n",
    "                else:\n",
    "                    evidence_parts.append(f\"[{i}] {str(ev)[:400]}\")\n",
    "            evidence_text = \"\\n\\n\".join(evidence_parts)\n",
    "        else:\n",
    "            evidence_text = \"No additional evidence retrieved.\"\n",
    "        \n",
    "        # Get adjacent context\n",
    "        prev_node, next_node = get_adjacent_nodes(skeleton, node_id)\n",
    "        prev_bridge_out = \"\"\n",
    "        next_bridge_in = \"\"\n",
    "        \n",
    "        if prev_node and prev_node in prose_store:\n",
    "            prev_bridge_out = prose_store[prev_node].get(\"bridge_out\", \"\")\n",
    "        if next_node and next_node in prose_store:\n",
    "            next_bridge_in = prose_store[next_node].get(\"bridge_in\", \"\")\n",
    "        \n",
    "        prompt = PATCH_APPLICATION_PROMPT.format(\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            current_content=current_prose.get(\"main_content\", \"\"),\n",
    "            issues=issues_text,\n",
    "            new_evidence=evidence_text,\n",
    "            prev_bridge_out=prev_bridge_out if prev_bridge_out else \"(First section)\",\n",
    "            next_bridge_in=next_bridge_in if next_bridge_in else \"(Last section)\"\n",
    "        )\n",
    "        \n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "        \n",
    "        try:\n",
    "            result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "            \n",
    "            # Update prose store\n",
    "            prose_store[node_id] = {\n",
    "                \"node_id\": node_id,\n",
    "                \"main_content\": result.main_content,\n",
    "                \"bridge_in\": result.bridge_in,\n",
    "                \"bridge_out\": result.bridge_out,\n",
    "                \"summary\": result.summary,\n",
    "                \"revision_count\": current_prose.get(\"revision_count\", 0) + 1,\n",
    "                \"citations_used\": result.citations_used\n",
    "            }\n",
    "            \n",
    "            patched_count += 1\n",
    "            print(f\"    Patched: {len(result.main_content)} chars (rev #{prose_store[node_id]['revision_count']})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error patching {node_id}: {e}\")\n",
    "    \n",
    "    print(f\"  Patched {patched_count} nodes\")\n",
    "    \n",
    "    # Reassemble draft after patches with proper references\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    document_parts = []\n",
    "    document_parts.append(f\"# Research Report\\n\\n\")\n",
    "    document_parts.append(f\"**Thesis:** {skeleton.get('thesis', '')}\\n\\n\")\n",
    "    document_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    for nid in leaf_nodes:\n",
    "        if nid not in prose_store:\n",
    "            continue\n",
    "        node = skeleton[\"nodes\"].get(nid, {})\n",
    "        prose = prose_store[nid]\n",
    "        document_parts.append(f\"## {node.get('title', nid)}\\n\\n\")\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            document_parts.append(f\"{prose['bridge_in']} \")\n",
    "        document_parts.append(f\"{prose.get('main_content', '')}\")\n",
    "        if prose.get(\"bridge_out\"):\n",
    "            document_parts.append(f\" {prose['bridge_out']}\")\n",
    "        document_parts.append(\"\\n\\n\")\n",
    "    \n",
    "    # Build proper numbered References section\n",
    "    if global_references:\n",
    "        document_parts.append(\"---\\n\\n## References\\n\\n\")\n",
    "        for ref_num in sorted(global_references.keys()):\n",
    "            ref_data = global_references[ref_num]\n",
    "            url = ref_data.get(\"url\", \"\")\n",
    "            title = ref_data.get(\"title\", \"\")\n",
    "            if title and url:\n",
    "                document_parts.append(f\"[{ref_num}] {title}. {url}\\n\\n\")\n",
    "            elif url:\n",
    "                document_parts.append(f\"[{ref_num}] {url}\\n\\n\")\n",
    "    \n",
    "    assembled_draft = \"\".join(document_parts)\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"assembled_draft\": assembled_draft,\n",
    "        \"iteration_count\": iteration_count + 1,\n",
    "        \"global_references\": global_references\n",
    "    }\n",
    "\n",
    "\n",
    "async def final_polish(state: SFEOState) -> dict:\n",
    "    \"\"\"Apply final polish and formatting to the report.\"\"\"\n",
    "    global knowledge_base\n",
    "    \n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    source_urls = state.get(\"source_urls\", [])\n",
    "    iteration_count = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase D.4: Final Polish\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Final report is the assembled draft with stats\n",
    "    final_report = assembled_draft\n",
    "    \n",
    "    # Calculate stats\n",
    "    word_count = len(final_report.split())\n",
    "    unique_urls = list(set(source_urls))\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    \n",
    "    # Cache stats\n",
    "    cache_stats = knowledge_base.get_stats_summary() if knowledge_base else \"N/A\"\n",
    "    \n",
    "    print(f\"  Final report: {len(final_report)} chars, {word_count} words\")\n",
    "    print(f\"  Sections: {len(leaf_nodes)}\")\n",
    "    print(f\"  Iterations: {iteration_count}\")\n",
    "    print(f\"  Quality progression: {' -> '.join([f'{s:.1f}' for s in quality_scores])}\")\n",
    "    print(f\"  Sources: {len(unique_urls)}\")\n",
    "    print(f\"  {cache_stats}\")\n",
    "    \n",
    "    return {\"final_report\": final_report}\n",
    "\n",
    "\n",
    "print(\"Phase D node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Graph Construction\n",
    "\n",
    "Build and compile the complete SFEO StateGraph with all phases and routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFEO Research Agent compiled successfully\n",
      "\n",
      "Architecture Flow:\n",
      "  Phase A: preliminary_research → generate_skeleton → identify_claims → create_backlog → Gate 1\n",
      "  Phase B: initialize_cache → [sprint_execute ↔ sprint_retrospective] → Gate 2\n",
      "  Phase C: generate_prose → assemble_draft → Gate 3\n",
      "  Phase D: structured_critique → [targeted_retrieval → apply_patches] → final_polish\n",
      "\n",
      "Key features:\n",
      "  - Skeleton-first approach with claim-driven research\n",
      "  - 3-layer cascading knowledge cache\n",
      "  - Sprint-based evidence gathering with retrospectives\n",
      "  - Quality gates at phase transitions\n",
      "  - Patch-based refinement with cascade detection\n"
     ]
    }
   ],
   "source": [
    "# Build the SFEO Research Agent graph\n",
    "sfeo_builder = StateGraph(SFEOState)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE A NODES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_node(\"preliminary_research\", preliminary_research)\n",
    "sfeo_builder.add_node(\"generate_skeleton\", generate_skeleton)\n",
    "sfeo_builder.add_node(\"identify_claims\", identify_claims)\n",
    "sfeo_builder.add_node(\"create_research_backlog\", create_research_backlog)\n",
    "sfeo_builder.add_node(\"skeleton_quality_gate\", skeleton_quality_gate)\n",
    "sfeo_builder.add_node(\"refine_skeleton\", refine_skeleton)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE B NODES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_node(\"initialize_cache\", initialize_cache)\n",
    "sfeo_builder.add_node(\"sprint_execute\", sprint_execute)\n",
    "sfeo_builder.add_node(\"sprint_retrospective\", sprint_retrospective)\n",
    "sfeo_builder.add_node(\"evidence_quality_gate\", evidence_quality_gate)\n",
    "sfeo_builder.add_node(\"emergency_research\", emergency_research)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE C NODES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_node(\"generate_prose\", generate_prose)\n",
    "sfeo_builder.add_node(\"assemble_draft\", assemble_draft)\n",
    "sfeo_builder.add_node(\"prose_quality_gate\", prose_quality_gate)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE D NODES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_node(\"structured_critique\", structured_critique)\n",
    "sfeo_builder.add_node(\"targeted_retrieval\", targeted_retrieval)\n",
    "sfeo_builder.add_node(\"apply_patches\", apply_patches)\n",
    "sfeo_builder.add_node(\"final_polish\", final_polish)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE A EDGES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_edge(START, \"preliminary_research\")\n",
    "sfeo_builder.add_edge(\"preliminary_research\", \"generate_skeleton\")\n",
    "sfeo_builder.add_edge(\"generate_skeleton\", \"identify_claims\")\n",
    "sfeo_builder.add_edge(\"identify_claims\", \"create_research_backlog\")\n",
    "sfeo_builder.add_edge(\"create_research_backlog\", \"skeleton_quality_gate\")\n",
    "\n",
    "# Gate 1 conditional routing\n",
    "sfeo_builder.add_conditional_edges(\n",
    "    \"skeleton_quality_gate\",\n",
    "    route_after_gate_1,\n",
    "    {\n",
    "        \"initialize_cache\": \"initialize_cache\",\n",
    "        \"refine_skeleton\": \"refine_skeleton\",\n",
    "        \"initialize_cache_anyway\": \"initialize_cache\"\n",
    "    }\n",
    ")\n",
    "sfeo_builder.add_edge(\"refine_skeleton\", \"identify_claims\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE B EDGES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_edge(\"initialize_cache\", \"sprint_execute\")\n",
    "sfeo_builder.add_edge(\"sprint_execute\", \"sprint_retrospective\")\n",
    "\n",
    "# Sprint loop conditional routing\n",
    "sfeo_builder.add_conditional_edges(\n",
    "    \"sprint_retrospective\",\n",
    "    route_after_sprint,\n",
    "    {\n",
    "        \"sprint_execute\": \"sprint_execute\",\n",
    "        \"evidence_quality_gate\": \"evidence_quality_gate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Gate 2 conditional routing\n",
    "sfeo_builder.add_conditional_edges(\n",
    "    \"evidence_quality_gate\",\n",
    "    route_after_gate_2,\n",
    "    {\n",
    "        \"generate_prose\": \"generate_prose\",\n",
    "        \"emergency_research\": \"emergency_research\",\n",
    "        \"generate_prose_anyway\": \"generate_prose\"\n",
    "    }\n",
    ")\n",
    "sfeo_builder.add_edge(\"emergency_research\", \"evidence_quality_gate\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE C EDGES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "sfeo_builder.add_edge(\"generate_prose\", \"assemble_draft\")\n",
    "sfeo_builder.add_edge(\"assemble_draft\", \"prose_quality_gate\")\n",
    "sfeo_builder.add_edge(\"prose_quality_gate\", \"structured_critique\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# PHASE D EDGES\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# Refinement loop conditional routing\n",
    "sfeo_builder.add_conditional_edges(\n",
    "    \"structured_critique\",\n",
    "    should_continue_refinement,\n",
    "    {\n",
    "        \"targeted_retrieval\": \"targeted_retrieval\",\n",
    "        \"final_polish\": \"final_polish\"\n",
    "    }\n",
    ")\n",
    "sfeo_builder.add_edge(\"targeted_retrieval\", \"apply_patches\")\n",
    "sfeo_builder.add_edge(\"apply_patches\", \"structured_critique\")\n",
    "\n",
    "# Final\n",
    "sfeo_builder.add_edge(\"final_polish\", END)\n",
    "\n",
    "# Compile the graph\n",
    "sfeo_graph = sfeo_builder.compile()\n",
    "\n",
    "print(\"SFEO Research Agent compiled successfully\")\n",
    "print(\"\\nArchitecture Flow:\")\n",
    "print(\"  Phase A: preliminary_research → generate_skeleton → identify_claims → create_backlog → Gate 1\")\n",
    "print(\"  Phase B: initialize_cache → [sprint_execute ↔ sprint_retrospective] → Gate 2\")\n",
    "print(\"  Phase C: generate_prose → assemble_draft → Gate 3\")\n",
    "print(\"  Phase D: structured_critique → [targeted_retrieval → apply_patches] → final_polish\")\n",
    "print(\"\\nKey features:\")\n",
    "print(\"  - Skeleton-first approach with claim-driven research\")\n",
    "print(\"  - 3-layer cascading knowledge cache\")\n",
    "print(\"  - Sprint-based evidence gathering with retrospectives\")\n",
    "print(\"  - Quality gates at phase transitions\")\n",
    "print(\"  - Patch-based refinement with cascade detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "try:\n",
    "    display(Image(sfeo_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Agent Wrappers\n",
    "\n",
    "Sync and async wrappers for evaluation harness compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent wrappers defined\n"
     ]
    }
   ],
   "source": [
    "async def sfeo_agent_async(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Async version of the SFEO research agent.\n",
    "    Use this version when calling from Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    global knowledge_base\n",
    "    knowledge_base = None  # Will be initialized during execution\n",
    "    \n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    result = await sfeo_graph.ainvoke(\n",
    "        {\"question\": question},\n",
    "        config={\"recursion_limit\": 100}\n",
    "    )\n",
    "    \n",
    "    # Gather statistics\n",
    "    cache_stats = knowledge_base.stats.copy() if knowledge_base else {}\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"source_urls\", []))),\n",
    "        \"skeleton\": result.get(\"skeleton\", {}),\n",
    "        \"claims_registry\": result.get(\"claims_registry\", {}),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"iteration_count\": result.get(\"iteration_count\", 0),\n",
    "        \"cache_stats\": cache_stats,\n",
    "        \"gate_1_passed\": result.get(\"gate_1_passed\", False),\n",
    "        \"gate_2_passed\": result.get(\"gate_2_passed\", False),\n",
    "        \"gate_3_passed\": result.get(\"gate_3_passed\", False),\n",
    "        \"gate_3_scores\": result.get(\"gate_3_scores\", {})\n",
    "    }\n",
    "\n",
    "\n",
    "def sfeo_agent(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Sync wrapper function for SFEO research agent.\n",
    "    \n",
    "    Compatible with evaluation harness.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary with 'question' key\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with 'output' key containing final report\n",
    "    \"\"\"\n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    async def _execute():\n",
    "        global knowledge_base\n",
    "        knowledge_base = None\n",
    "        \n",
    "        return await sfeo_graph.ainvoke(\n",
    "            {\"question\": question},\n",
    "            config={\"recursion_limit\": 100}\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import concurrent.futures\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(asyncio.run, _execute())\n",
    "            result = future.result()\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(_execute())\n",
    "    \n",
    "    cache_stats = knowledge_base.stats.copy() if knowledge_base else {}\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"source_urls\", []))),\n",
    "        \"skeleton\": result.get(\"skeleton\", {}),\n",
    "        \"claims_registry\": result.get(\"claims_registry\", {}),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"iteration_count\": result.get(\"iteration_count\", 0),\n",
    "        \"cache_stats\": cache_stats\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Agent wrappers defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Manual Test\n",
    "\n",
    "Run this cell to verify the SFEO agent works correctly with a sample research question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SFEO Agent\n",
      "Question: What are the key benefits and challenges of using large language models in enterprise applications?\n",
      "\n",
      "Running SFEO research (this may take several minutes)...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Phase A.1: Preliminary Research\n",
      "============================================================\n",
      "  Searching: \"Key benefits of large language models in enterpri...\n",
      "  Searching: \"Challenges of deploying LLMs in enterprises: priv...\n",
      "  Searching: \"Best practices for integrating and operating LLMs...\n",
      "  Searching: \"Enterprise LLM case studies and use cases by indu...\n",
      "  Collected 20 preliminary results\n",
      "\n",
      "============================================================\n",
      "Phase A.2: Skeleton Generation\n",
      "============================================================\n",
      "  Thesis: Enterprise LLMs deliver substantial ROI and transformative automation only when ...\n",
      "  Generated 7 skeleton nodes:\n",
      "    - sec:introduction: Introduction: LLMs in the Enterprise Landscape\n",
      "    - sec:background: Background and Context: LLM Technology, Models, and Enterprise Trends (depends: sec:introduction)\n",
      "    - sec:benefits: Benefits: Business Value and Use Cases for Enterprise LLMs (depends: sec:background)\n",
      "    - sec:challenges: Challenges and Risks: Accuracy, Costs, Security, and Operational Complexity (depends: sec:background)\n",
      "    - sec:deployment: Deployment, Architecture, and LLMOps: From Pilot to Production (depends: sec:background)\n",
      "    - sec:analysis: Analysis and Discussion: Trade-offs, Governance, and Strategic Framework (depends: sec:benefits, sec:challenges, sec:deployment, sec:background)\n",
      "    - sec:conclusion: Conclusion and Future Directions (depends: sec:analysis)\n",
      "\n",
      "============================================================\n",
      "Phase A.3: Claim Identification\n",
      "============================================================\n",
      "  Extracted 21 claims from skeleton:\n",
      "    - claim_sec:introduction_1: LLMs are moving from narrow chat tools to integrat...\n",
      "    - claim_sec:introduction_2: Business value from LLMs depends on alignment to w...\n",
      "    - claim_sec:introduction_3: CIOs/CTOs must transition from pilots to productio...\n",
      "    - claim_sec:background_4: Enterprises deploy LLMs via a mix of private VPC-h...\n",
      "    - claim_sec:background_5: RAG and knowledge graphs are common patterns to gr...\n",
      "    ... and 16 more\n",
      "\n",
      "============================================================\n",
      "Phase A.4: Research Backlog Creation\n",
      "============================================================\n",
      "  Created backlog with 21 research tasks\n",
      "\n",
      "--- Gate 1: Skeleton Quality (Attempt 1/3) ---\n",
      "  Thesis Clarity: 9.0/10\n",
      "  Coverage: 9.0/10\n",
      "  Structure: 9.0/10\n",
      "  Overall: 8.0/10\n",
      "  PASSED Gate 1\n",
      "\n",
      "============================================================\n",
      "Phase B.0: Initialize Knowledge Cache\n",
      "============================================================\n",
      "  Pre-populated cache with 20 preliminary findings\n",
      "  Knowledge base initialized\n",
      "\n",
      "============================================================\n",
      "Phase B.1: Sprint 1/3\n",
      "============================================================\n",
      "  Verifying 4 claims this sprint\n",
      "\n",
      "  [claim_sec:introduction_1] LLMs are moving from narrow chat tools to integrat...\n",
      "    WEB SEARCH (L3)\n",
      "\n",
      "  [claim_sec:introduction_2] Business value from LLMs depends on alignment to w...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:introduction_3] CIOs/CTOs must transition from pilots to productio...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:background_4] Enterprises deploy LLMs via a mix of private VPC-h...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  Sprint 1 Complete:\n",
      "    Claims verified: 4\n",
      "    Cache hits: 0/4 (0.0%)\n",
      "    New URLs collected: 29\n",
      "\n",
      "============================================================\n",
      "Phase B.2: Sprint 1 Retrospective\n",
      "============================================================\n",
      "  Claims: 4 verified, 17 remaining\n",
      "  Cache: 0/4 hits (0.0%)\n",
      "  Decision: CONTINUE to sprint 2\n",
      "\n",
      "============================================================\n",
      "Phase B.1: Sprint 2/3\n",
      "============================================================\n",
      "  Verifying 4 claims this sprint\n",
      "\n",
      "  [claim_sec:background_5] RAG and knowledge graphs are common patterns to gr...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:background_6] Agentic AI and multi-model natural language UIs ar...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:benefits_7] LLMs can reduce routine task time (e.g., first-res...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:benefits_8] Semantic search and RAG-enabled experiences improv...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  Sprint 2 Complete:\n",
      "    Claims verified: 4\n",
      "    Cache hits: 0/4 (0.0%)\n",
      "    New URLs collected: 32\n",
      "\n",
      "============================================================\n",
      "Phase B.2: Sprint 2 Retrospective\n",
      "============================================================\n",
      "  Claims: 8 verified, 13 remaining\n",
      "  Cache: 0/8 hits (0.0%)\n",
      "  Decision: CONTINUE to sprint 3\n",
      "\n",
      "============================================================\n",
      "Phase B.1: Sprint 3/3\n",
      "============================================================\n",
      "  Verifying 4 claims this sprint\n",
      "\n",
      "  [claim_sec:benefits_9] Agentic LLM systems enable end-to-end workflow aut...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:challenges_10] Hallucinations and factual errors create measurabl...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:challenges_11] Inference compute and context-window scaling are m...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  [claim_sec:challenges_12] Data quality, fragmented knowledge sources, and po...\n",
      "    WEB SEARCH (L2)\n",
      "\n",
      "  Sprint 3 Complete:\n",
      "    Claims verified: 4\n",
      "    Cache hits: 0/4 (0.0%)\n",
      "    New URLs collected: 29\n",
      "\n",
      "============================================================\n",
      "Phase B.2: Sprint 3 Retrospective\n",
      "============================================================\n",
      "  Claims: 12 verified, 9 remaining\n",
      "  Cache: 0/12 hits (0.0%)\n",
      "  Decision: STOP (Max sprints reached)\n",
      "\n",
      "--- Gate 2: Evidence Sufficiency (Attempt 1/2) ---\n",
      "  Verification rate: 57.1% (threshold: 60%)\n",
      "  Domain diversity: 84 (threshold: 4)\n",
      "  Section coverage: 57.1% (threshold: 70%)\n",
      "  FAILED Gate 2\n",
      "\n",
      "  Emergency research for evidence gaps...\n",
      "  Emergency search for sec:deployment: Deployment, Architecture, and LLMOps: Fr...\n",
      "  Emergency search for sec:analysis: Analysis and Discussion: Trade-offs, Gov...\n",
      "  Emergency search for sec:conclusion: Conclusion and Future Directions Summari...\n",
      "  Emergency research collected 24 new URLs\n",
      "\n",
      "--- Gate 2: Evidence Sufficiency (Attempt 2/2) ---\n",
      "  Verification rate: 57.1% (threshold: 60%)\n",
      "  Domain diversity: 106 (threshold: 4)\n",
      "  Section coverage: 57.1% (threshold: 70%)\n",
      "  FAILED Gate 2\n",
      "  Max Gate 2 attempts reached. Proceeding with available evidence.\n",
      "\n",
      "============================================================\n",
      "Phase C.1: Prose Generation\n",
      "============================================================\n",
      "  [1/4] Generating: sec:benefits - Benefits: Business Value and Use Cases for Enterprise LLMs\n",
      "      Generated 1959 chars\n",
      "  [2/4] Generating: sec:challenges - Challenges and Risks: Accuracy, Costs, Security, and Operational Complexity\n",
      "      Generated 2497 chars\n",
      "  [3/4] Generating: sec:deployment - Deployment, Architecture, and LLMOps: From Pilot to Production\n",
      "      Generated 2642 chars\n",
      "  [4/4] Generating: sec:conclusion - Conclusion and Future Directions\n",
      "      Generated 2103 chars\n",
      "  Total references tracked: 12\n",
      "\n",
      "============================================================\n",
      "Phase C.2: Draft Assembly\n",
      "============================================================\n",
      "  Assembled draft: 13269 chars, 1612 words\n",
      "  Sections: 4\n",
      "  References: 12\n",
      "\n",
      "--- Gate 3: Prose Quality ---\n",
      "  Coherence: 8.0/10\n",
      "  Depth: 8.0/10\n",
      "  Evidence: 5.0/10\n",
      "  Overall: 7.0/10\n",
      "  PASSED Gate 3\n",
      "\n",
      "============================================================\n",
      "Phase D.1: Structured Critique (Iteration 0)\n",
      "============================================================\n",
      "  Quality Score: 5.0/10\n",
      "  Issues found: 13\n",
      "    - Critical: 2\n",
      "    - Major: 10\n",
      "    - Minor: 1\n",
      "  Nodes to patch: ['sec:benefits', 'sec:background', 'sec:deployment', 'sec:analysis', 'sec:introduction', 'sec:challenges', 'sec:conclusion']\n",
      "\n",
      "--- Convergence Check ---\n",
      "  Iteration: 0/2\n",
      "  Quality: 5.0/7.5\n",
      "  Nodes to patch: 7\n",
      "  -> Diminishing returns (-2.00). Finalizing.\n",
      "\n",
      "============================================================\n",
      "Phase D.4: Final Polish\n",
      "============================================================\n",
      "  Final report: 13269 chars, 1612 words\n",
      "  Sections: 4\n",
      "  Iterations: 0\n",
      "  Quality progression: 7.0 -> 5.0\n",
      "  Sources: 129\n",
      "  Cache: 0/15 avoided (0.0% hit rate), 175 chunks indexed\n",
      "\n",
      "================================================================================\n",
      "FINAL REPORT\n",
      "================================================================================\n",
      "# Research Report\n",
      "\n",
      "**Thesis:** Enterprise LLMs deliver substantial ROI and transformative automation only when they are integrated into existing workflows with production-grade MLOps, governance, and data-quality practices; absent these, cost, security, and operational risk prevent scalable value capture.\n",
      "\n",
      "---\n",
      "\n",
      "## Benefits: Business Value and Use Cases for Enterprise LLMs\n",
      "\n",
      "Having established the capabilities and architectural patterns of enterprise LLMs, we now consider the concrete business value they unlock across core functions. Enterprise LLMs deliver measurable value in productivity, customer experience, automation, knowledge management, and decision support. In software engineering, studies report up to a 30% reduction in task completion time for routine coding activities when developers use LLM assistance, illustrating a direct productivity delta that can scale across teams and projects [1]. Those productivity gains extend beyond code: LLMs accelerate research, ideation, and document synthesis across R&D, legal, and other knowledge‑intensive functions, enabling faster iteration cycles and higher throughput per employee [2].\n",
      "\n",
      "Knowledge management and time‑to‑insight are among the highest‑value use cases. Retrieval‑Augmented Generation (RAG) transforms enterprise search from static lookup into an active, contextualized assistant, shortening the interval between asking a question and acting on the answer and thus reducing decision latency in operations and customer service [3]. By combining retrieval and generation into a single response, RAG improves contextual accuracy and relevance of outputs, making downstream workflows—ticket resolution, onboarding, and compliance checks—both faster and more reliable [4].\n",
      "\n",
      "Customer experience and automation benefit when LLMs are embedded into workflows rather than treated as point tools. Modern enterprise models can call external tools, persist memory, and orchestrate multi‑step tasks, enabling agentic workflows that autonomously complete routine processes and surface exceptions for human review [5][6]. This integration amplifies value by reducing handoffs, increasing adoption (because outputs arrive where work already happens), and creating feedback loops that improve accuracy and governance. In aggregate, these effects compound: time savings per task become organizational velocity, customer satisfaction rises through faster, more personalized responses, and decision support becomes both timely and actionable. The benefits above are compelling, but realizing them at scale requires confronting several technical, operational, and governance challenges. The next section details those key risks and their business implications.\n",
      "\n",
      "## Challenges and Risks: Accuracy, Costs, Security, and Operational Complexity\n",
      "\n",
      "The productivity and automation gains described earlier bring enterprises to a tipping point: operationalizing LLMs at scale exposes a distinct set of technical, financial, and compliance risks that can negate those benefits if not managed. First, model accuracy and hallucination remain the most visible operational risk. Industry analysis identifies hallucination as one of three dominant risks for enterprises entering 2026—alongside hidden costs and data leakage—which places factuality squarely on CIO and CISO agendas [1]. In regulated or safety-critical workflows, even low-frequency hallucinations are unacceptable: outputs that are “close enough” in creative tasks can become material errors in financial disclosures, clinical support, or compliance reporting [2]. Mitigation therefore requires layered defenses (retrieval augmentation, grounding, constrained generation, human-in-the-loop review) and rigorous evaluation against domain-specific ground truth.\n",
      "\n",
      "Second, inference and storage costs create recurring financial pressure. Multiple benchmarks and strategy reviews find that inference compute is a major, recurring operational cost for deployed LLM services, and the industry has becom...\n",
      "\n",
      "================================================================================\n",
      "EXECUTION SUMMARY\n",
      "================================================================================\n",
      "Report length: 13269 chars, 1612 words\n",
      "Skeleton nodes: 7\n",
      "Claims tracked: 21\n",
      "Refinement iterations: 0\n",
      "Quality progression: [7.0, 5.0]\n",
      "Unique sources: 129\n",
      "\n",
      "Gate Results:\n",
      "  Gate 1 (Skeleton): PASSED\n",
      "  Gate 2 (Evidence): FAILED\n",
      "  Gate 3 (Prose): PASSED\n",
      "\n",
      "Cache Performance:\n",
      "  Total queries: 15\n",
      "  Web searches avoided: 0 (0.0%)\n",
      "  L1 hits: 0\n",
      "  L2 high: 0\n",
      "  L2 medium: 1\n",
      "  L2 low: 14\n",
      "\n",
      "Agent test PASSED\n"
     ]
    }
   ],
   "source": [
    "# Manual test with sample question\n",
    "test_question = \"What are the key benefits and challenges of using large language models in enterprise applications?\"\n",
    "\n",
    "print(f\"Testing SFEO Agent\")\n",
    "print(f\"Question: {test_question}\")\n",
    "print(\"\\nRunning SFEO research (this may take several minutes)...\\n\")\n",
    "\n",
    "try:\n",
    "    result = await sfeo_agent_async({\"question\": test_question})\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result[\"output\"][:4000] + \"...\" if len(result[\"output\"]) > 4000 else result[\"output\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXECUTION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Report length: {len(result['output'])} chars, {len(result['output'].split())} words\")\n",
    "    print(f\"Skeleton nodes: {len(result.get('skeleton', {}).get('nodes', {}))}\")\n",
    "    print(f\"Claims tracked: {len(result.get('claims_registry', {}))}\")\n",
    "    print(f\"Refinement iterations: {result.get('iteration_count', 0)}\")\n",
    "    print(f\"Quality progression: {result.get('quality_scores', [])}\")\n",
    "    print(f\"Unique sources: {len(result.get('source_urls', []))}\")\n",
    "    \n",
    "    print(f\"\\nGate Results:\")\n",
    "    print(f\"  Gate 1 (Skeleton): {'PASSED' if result.get('gate_1_passed') else 'FAILED'}\")\n",
    "    print(f\"  Gate 2 (Evidence): {'PASSED' if result.get('gate_2_passed') else 'FAILED'}\")\n",
    "    print(f\"  Gate 3 (Prose): {'PASSED' if result.get('gate_3_passed') else 'FAILED'}\")\n",
    "    \n",
    "    cache_stats = result.get(\"cache_stats\", {})\n",
    "    if cache_stats:\n",
    "        total = cache_stats.get(\"total_queries\", 0)\n",
    "        avoided = cache_stats.get(\"web_searches_avoided\", 0)\n",
    "        hit_rate = avoided / total * 100 if total else 0\n",
    "        print(f\"\\nCache Performance:\")\n",
    "        print(f\"  Total queries: {total}\")\n",
    "        print(f\"  Web searches avoided: {avoided} ({hit_rate:.1f}%)\")\n",
    "        print(f\"  L1 hits: {cache_stats.get('l1_hits', 0)}\")\n",
    "        print(f\"  L2 high: {cache_stats.get('l2_high', 0)}\")\n",
    "        print(f\"  L2 medium: {cache_stats.get('l2_medium', 0)}\")\n",
    "        print(f\"  L2 low: {cache_stats.get('l2_low', 0)}\")\n",
    "    \n",
    "    print(\"\\nAgent test PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Agent test FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report\n",
       "\n",
       "**Thesis:** Enterprise LLMs deliver substantial ROI and transformative automation only when they are integrated into existing workflows with production-grade MLOps, governance, and data-quality practices; absent these, cost, security, and operational risk prevent scalable value capture.\n",
       "\n",
       "---\n",
       "\n",
       "## Benefits: Business Value and Use Cases for Enterprise LLMs\n",
       "\n",
       "Having established the capabilities and architectural patterns of enterprise LLMs, we now consider the concrete business value they unlock across core functions. Enterprise LLMs deliver measurable value in productivity, customer experience, automation, knowledge management, and decision support. In software engineering, studies report up to a 30% reduction in task completion time for routine coding activities when developers use LLM assistance, illustrating a direct productivity delta that can scale across teams and projects [1]. Those productivity gains extend beyond code: LLMs accelerate research, ideation, and document synthesis across R&D, legal, and other knowledge‑intensive functions, enabling faster iteration cycles and higher throughput per employee [2].\n",
       "\n",
       "Knowledge management and time‑to‑insight are among the highest‑value use cases. Retrieval‑Augmented Generation (RAG) transforms enterprise search from static lookup into an active, contextualized assistant, shortening the interval between asking a question and acting on the answer and thus reducing decision latency in operations and customer service [3]. By combining retrieval and generation into a single response, RAG improves contextual accuracy and relevance of outputs, making downstream workflows—ticket resolution, onboarding, and compliance checks—both faster and more reliable [4].\n",
       "\n",
       "Customer experience and automation benefit when LLMs are embedded into workflows rather than treated as point tools. Modern enterprise models can call external tools, persist memory, and orchestrate multi‑step tasks, enabling agentic workflows that autonomously complete routine processes and surface exceptions for human review [5][6]. This integration amplifies value by reducing handoffs, increasing adoption (because outputs arrive where work already happens), and creating feedback loops that improve accuracy and governance. In aggregate, these effects compound: time savings per task become organizational velocity, customer satisfaction rises through faster, more personalized responses, and decision support becomes both timely and actionable. The benefits above are compelling, but realizing them at scale requires confronting several technical, operational, and governance challenges. The next section details those key risks and their business implications.\n",
       "\n",
       "## Challenges and Risks: Accuracy, Costs, Security, and Operational Complexity\n",
       "\n",
       "The productivity and automation gains described earlier bring enterprises to a tipping point: operationalizing LLMs at scale exposes a distinct set of technical, financial, and compliance risks that can negate those benefits if not managed. First, model accuracy and hallucination remain the most visible operational risk. Industry analysis identifies hallucination as one of three dominant risks for enterprises entering 2026—alongside hidden costs and data leakage—which places factuality squarely on CIO and CISO agendas [1]. In regulated or safety-critical workflows, even low-frequency hallucinations are unacceptable: outputs that are “close enough” in creative tasks can become material errors in financial disclosures, clinical support, or compliance reporting [2]. Mitigation therefore requires layered defenses (retrieval augmentation, grounding, constrained generation, human-in-the-loop review) and rigorous evaluation against domain-specific ground truth.\n",
       "\n",
       "Second, inference and storage costs create recurring financial pressure. Multiple benchmarks and strategy reviews find that inference compute is a major, recurring operational cost for deployed LLM services, and the industry has become singularly focused on inference scaling and cost reduction techniques [3][4]. Without optimization—model quantization, batching, dynamic routing, or hybrid deployment of smaller private models plus managed APIs—per-query cost can escalate as usage grows, turning a pilot into an unsustainable line-item on the P&L.\n",
       "\n",
       "Third, latency, scalability, and data integration are practical barriers to reliable production performance. High throughput requirements interact with model size and retrieval latency, producing user-visible delays unless caching, sharding, and retrieval-augmented pipelines are implemented. At the same time, decision quality depends on data quality operations: stale, misaligned, or poorly versioned context feeds produce systematic errors that propagate through downstream workflows [6]. Prompt defects and poor prompt governance further create “LLM waste,” a cross-industry source of risk seen in finance, manufacturing, energy, and healthcare [5].\n",
       "\n",
       "Finally, security, privacy, and governance risks—particularly data leakage and inadequate model auditing—translate directly into business exposure. Data exfiltration or noncompliant usage can trigger regulatory fines, contractual penalties, and loss of customer trust; weak model versioning and observability amplify these outcomes by delaying detection and remediation [1][5]. Together, these challenges mean that technical shortcomings rapidly convert into financial, legal, and reputational impacts unless operational controls and governance are prioritized. The next section outlines pragmatic production patterns and operational controls—hybrid architectures, retrieval layers, caching strategies, observability, and CI/CD practices—that address the specific risks identified here.\n",
       "\n",
       "## Deployment, Architecture, and LLMOps: From Pilot to Production\n",
       "\n",
       "Having established where LLM risk concentrates—factuality, costs, latency, data quality, and security—deployment decisions must translate those risks into concrete operational controls. Enterprise LLM deployments should follow pragmatic, incremental patterns that balance control, cost, and capability. A hybrid architecture is often the practical default: host sensitive, regulated, or frequently accessed models and data in private infrastructure (on-premise or private cloud) while routing less-sensitive or experimental workloads to managed APIs. This split enables tight data governance and low-latency local inference for critical paths while preserving agility and access to the newest model capabilities via managed providers. The architecture should include a clear model router that applies policy-based routing (by sensitivity, latency target, cost budget, or model capability) and records routing decisions for audit and billing.\n",
       "\n",
       "A robust retrieval layer is essential to contain hallucination risk and inference costs. Indexes, vector stores, and knowledge graphs must be treated as first-class services with versioned schemas, access controls, and periodic refresh windows. Caching and result memoization—both at the retrieval and output levels—reduce repeated token-generation costs; deterministic responses (e.g., templated answers or frequently seen queries) should be cached and served without model invocation. Latency optimization requires multiple knobs: model selection by SLA tier, batching small requests, asynchronous and streaming responses for long outputs, colocating retrieval and inference services, and using lower-precision or distilled models for conversational “frontline” tasks.\n",
       "\n",
       "Operational controls include strict versioning and a model registry that ties model artifacts to training data hashes, evaluation suites, and deployment metadata. CI/CD for models extends code pipelines with data and evaluation gates: automated unit tests on prompts, regression suites for factuality and safety, canary rollouts with staged traffic, and automated rollback triggers when key metrics degrade. Observability must instrument latency, throughput, cost per request, prompt/response drift, hallucination/factuality rates, and safety incidents; logs should be retained with lineage for post-incident forensics.\n",
       "\n",
       "Prompt lifecycle management—treating prompts as deployable artifacts with tests, reviews, and metrics—prevents operational drift. Finally, cost-control strategies are operational: tiered model SLAs, dynamic routing to cheaper models for non-critical queries, per-feature quotas, token limits, precomputation, and active cache policies. Taken together, these patterns form a repeatable roadmap to move from pilot experiments to resilient, auditable, and cost-efficient production LLM services. With deployment patterns and operational controls in place, the report next synthesizes core findings and recommends immediate and strategic actions for enterprise investment and governance.\n",
       "\n",
       "## Conclusion and Future Directions\n",
       "\n",
       "Building on the pragmatic hybrid architecture and LLMOps practices just described, this conclusion synthesizes the report’s core lessons and translates them into concrete next steps for enterprises. The evidence in this report supports a single, central thesis: reliable, scalable LLM-driven systems require both an architecture that combines retrieval, caching, and cost/latency optimization and an operational discipline that treats prompts and models like software artifacts. Practically, enterprises should prioritize immediate, low-friction actions that reduce risk and demonstrate value. Short-term actions include: (1) cataloging current data sources and model usage, (2) defining clear business success metrics and latency/SLA budgets, (3) implementing a retrieval layer and response caching to cut cost and improve relevance, and (4) establishing baseline observability, logging, and prompt/versioning policies so incidents are traceable and reproducible.\n",
       "\n",
       "Over the longer term, organizations must invest in platform capabilities and governance to sustain growth. Key longer-term investments are: a central model-ops platform that automates deployment, rollbacks, and cost-aware routing; multimodal data pipelines to support vision and audio modalities; formalized governance, audit trails, and policy-as-code to meet compliance needs; staff training and role definition for model stewards; and R&D into agent orchestration and safety frameworks before deploying autonomous agents at scale. \n",
       "\n",
       "Several emerging trends deserve directed attention as research or pilot priorities. Agentic AI (autonomous, multi-step agents) promises productivity gains but raises safety, explainability, and control questions that should be addressed via contained pilots and red-team testing. Multimodal models expand use cases but require data engineering and labeling investment. Model marketplaces and vendor ecosystems ease access but increase dependency and procurement risk, so pilots should evaluate portability and cost models. Finally, evolving regulation will change compliance baselines; organizations should pilot auditability, provenance tracking, and privacy-preserving techniques now. These steps form a pragmatic roadmap from pilot to production while keeping safety, cost, and governance central. The final section closes the report with a concise recap and calls to action that synthesize these recommendations into an executable agenda for leadership.\n",
       "\n",
       "---\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Using LLMs to Boost Workplace Productivity - LinkedIn. https://www.linkedin.com/top-content/productivity/maximizing-workplace-productivity/using-llms-to-boost-workplace-productivity/\n",
       "\n",
       "[2] Using LLMs to augment human-centered workflows - Effixis. https://effixis.ch/blog/using-llms-to-augment-human-centered-workflows/\n",
       "\n",
       "[3] How is RAG Reinventing Enterprise Search and Reducing Time-to .... https://www.kore.ai/blog/how-is-rag-reinventing-enterprise-search-and-reducing-time-to-insight\n",
       "\n",
       "[4] Questions? Retrieval Augmented Generation (RAG) Has the Answer. https://www.reworked.co/knowledge-findability/employees-need-information-retrieval-augmented-generation-rag-can-help/\n",
       "\n",
       "[5] Agentic Workflows in 2026: What They Are & How They Work. https://brollyai.com/agentic-workflows/\n",
       "\n",
       "[6] Agentic AI Is Redefining Enterprise Workflows in 2026 - CrossML. https://www.crossml.com/agentic-ai-is-redefining-enterprise-workflows/\n",
       "\n",
       "[7] The 3 Biggest Risks of LLMs Going Into 2026. https://medium.com/@serdargoksu/the-3-biggest-risks-of-llms-going-into-2026-hallucination-hidden-costs-and-data-leakage-f952fcb94506\n",
       "\n",
       "[8] Are LLM Hallucinations a Business Risk? Enterprise and .... https://www.factors.ai/blog/llm-hallucination-business-risk\n",
       "\n",
       "[9] Cost-Effective AI Inference at Scale: A 2025 Benchmark & Strategy .... https://www.gmicloud.ai/blog/cost-effective-ai-inference-at-scale\n",
       "\n",
       "[10] How To Reduce Inference Costs While Running LLMs. https://levelup.gitconnected.com/how-to-reduce-inference-costs-while-running-llms-748b373f2d3d\n",
       "\n",
       "[11] The Hidden Bottleneck in AI: LLM Waste | Craig Saunders posted on .... https://www.linkedin.com/posts/craigjsaunders_people-talk-about-the-bottleneck-in-ai-being-activity-7384192522710880256-VsH0\n",
       "\n",
       "[12] Why Decision Quality Is the Real AI Bottleneck in GTM - LinkedIn. https://www.linkedin.com/pulse/infrastructure-gap-why-decision-quality-real-ai-bottleneck-alan-zhao-x8uie\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluation Harness Integration\n",
    "\n",
    "Use the evaluation harness to formally benchmark the SFEO agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run evaluation harness\n",
    "# import sys\n",
    "# sys.path.insert(0, '../evaluation')\n",
    "# from harness import evaluate_agent\n",
    "\n",
    "# Run evaluation (uncomment when ready)\n",
    "# eval_result = evaluate_agent(\n",
    "#     agent_fn=sfeo_agent,\n",
    "#     agent_name=\"sfeo_combined_tier1\",\n",
    "#     questions=[\n",
    "#         {\"question\": \"What is the current state of quantum computing technology and its near-term applications?\"},\n",
    "#         {\"question\": \"How do self-driving cars detect and respond to pedestrians?\"},\n",
    "#     ],\n",
    "#     output_path=\"../results/sfeo_combined_tier1_results.json\"\n",
    "# )\n",
    "# print(eval_result)\n",
    "\n",
    "print(\"Evaluation harness integration ready\")\n",
    "print(\"Uncomment the code above to run formal benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook implements the **Skeleton-First Evidence Orchestration (SFEO)** architecture, combining all validated Tier 1 paradigms:\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "| Phase | Components | Key Innovation |\n",
    "|-------|------------|----------------|\n",
    "| **A: Strategic Planning** | Preliminary Research → Skeleton → Claims → Backlog → Gate 1 | Document structure drives research |\n",
    "| **B: Evidence Gathering** | Cache Init → Sprint Loop → Gate 2 | Cascading 3-layer cache + agile sprints |\n",
    "| **C: Document Construction** | Prose Generation → Assembly → Gate 3 | Claim-evidence driven prose |\n",
    "| **D: Refinement** | Critique → Targeted Retrieval → Patch → Converge | Semantic addressing + cascade detection |\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Skeleton-First**: The document skeleton is generated BEFORE evidence gathering, focusing research on specific claims\n",
    "2. **Quality Gates**: Three gates prevent error propagation between phases\n",
    "3. **Cascading Cache**: 3-layer cache (L1: exact, L2: semantic, L3: LLM judgment) optimizes searches\n",
    "4. **Sprint-Based Research**: Agile-style sprints with retrospectives enable adaptive evidence gathering\n",
    "5. **Patch-Based Refinement**: Targeted updates with cascade detection maintain document coherence\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "- **Search Efficiency**: 30-50% cache hit rate in later phases\n",
    "- **Quality Scores**: Target 7.5+/10 overall quality\n",
    "- **Token Efficiency**: More focused research than baseline approaches\n",
    "- **Document Coherence**: Bridge sentences and cascade detection ensure flow\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Run manual test to verify agent execution\n",
    "2. Use evaluation harness for formal benchmarking\n",
    "3. Compare results against Baseline A/B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Execution Section\n",
    "\n",
    "This section runs the 5-query test dataset against this notebook variant and saves outputs for comparison.\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "test_output/\n",
    "    question_1/\n",
    "        question_1_V08-2.md\n",
    "    question_2/\n",
    "        question_2_V08-2.md\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Instructions:**\n",
    "1. Run all cells above first to define the agent\n",
    "2. Run the cells below to execute all 5 test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Setup and Configuration\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = Path('.').resolve()\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / 'test_output'\n",
    "DATASET_PATH = NOTEBOOK_DIR / 'test_dataset.yaml'\n",
    "\n",
    "# Notebook version (automatically set based on filename)\n",
    "CURRENT_VERSION = \"V08-2\"\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load test dataset\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    dataset = yaml.safe_load(f)\n",
    "\n",
    "questions = dataset.get('questions', [])\n",
    "\n",
    "# Create output directories for each question\n",
    "for i in range(1, len(questions) + 1):\n",
    "    question_dir = OUTPUT_DIR / f\"question_{i}\"\n",
    "    question_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Test Configuration:\")\n",
    "print(f\"  Version: {CURRENT_VERSION}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Loaded {len(questions)} test questions\")\n",
    "print(f\"\\nTest Questions:\")\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"  {i}. [{q['category']}] {q['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(question_num: int, version: str, result: dict, question_data: dict) -> Path:\n",
    "    \"\"\"Save the output to a markdown file.\"\"\"\n",
    "    output_dir = OUTPUT_DIR / f\"question_{question_num}\"\n",
    "    output_file = output_dir / f\"question_{question_num}_{version}.md\"\n",
    "    \n",
    "    question_text = question_data.get('question', '')\n",
    "    question_title = question_data.get('title', 'Untitled')\n",
    "    question_id = question_data.get('id', f'Q{question_num}')\n",
    "    \n",
    "    content = f\"\"\"# Question {question_num} - {version}\n",
    "\n",
    "                **Question ID:** {question_id}  \n",
    "                **Title:** {question_title}  \n",
    "                **Category:** {question_data.get('category', 'N/A')}  \n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Original Question\n",
    "\n",
    "                {question_text}\n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Research Report\n",
    "\n",
    "                {result.get('output', 'No output generated')}\n",
    "\n",
    "                \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Questions Test\n",
    "\n",
    "Run ALL 5 questions for comprehensive testing:\n",
    "\n",
    "**WARNING:** This will take 30-60+ minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ALL questions for the current version\n",
    "# WARNING: This will take a long time (potentially 30-60+ minutes)\n",
    "\n",
    "print(f\"Running ALL {len(questions)} questions with {CURRENT_VERSION}\")\n",
    "print(f\"Estimated time: 30-60+ minutes\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "results_summary = []\n",
    "overall_start = datetime.now()\n",
    "\n",
    "for i, question_data in enumerate(questions, 1):\n",
    "    question_text = question_data.get('question', '')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}/{len(questions)}: {question_data['title']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        result = await combined_tier1_agent_async({\"question\": question_text})\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        output_file = save_output(i, CURRENT_VERSION, result, question_data)\n",
    "        \n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": len(result.get('output', '')),\n",
    "            \"sources\": len(result.get('source_urls', [])),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Completed in {elapsed:.1f}s - {summary['output_chars']} chars, {summary['sources']} sources\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": 0,\n",
    "            \"sources\": 0,\n",
    "            \"status\": f\"error: {str(e)}\"\n",
    "        }\n",
    "        print(f\"FAILED: {e}\")\n",
    "    \n",
    "    results_summary.append(summary)\n",
    "\n",
    "# Save summary\n",
    "overall_elapsed = (datetime.now() - overall_start).total_seconds()\n",
    "\n",
    "summary_file = OUTPUT_DIR / f\"summary_{CURRENT_VERSION}.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"run_time\": datetime.now().isoformat(),\n",
    "        \"version\": CURRENT_VERSION,\n",
    "        \"total_elapsed_seconds\": overall_elapsed,\n",
    "        \"questions_tested\": len(questions),\n",
    "        \"results\": results_summary\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL TESTS COMPLETE for {CURRENT_VERSION}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total time: {overall_elapsed:.1f} seconds ({overall_elapsed/60:.1f} minutes)\")\n",
    "print(f\"Summary saved: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
