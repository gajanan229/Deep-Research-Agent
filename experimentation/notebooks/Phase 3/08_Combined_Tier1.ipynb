{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Combined Tier 1 Paradigms: Deep Research Agent\n",
    "\n",
    "This notebook implements the **Combined Tier 1 Architecture** that unifies four paradigms:\n",
    "\n",
    "1. **Cascading Knowledge Cache** - Global search layer wrapping all operations\n",
    "2. **Agile Sprints** - Information gathering with retrospectives\n",
    "3. **Iterative Refinement V2** - Skeleton-based document generation with patches\n",
    "4. **Quality Gates** - Strategic checkpoints for quality assurance\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The architecture follows a **funnel pattern**:\n",
    "```\n",
    "Wide Research → Structured Synthesis → Focused Refinement → Polished Output\n",
    "```\n",
    "\n",
    "### Five Phases:\n",
    "1. **Phase 1: Agile Research Sprints** - Comprehensive information gathering\n",
    "2. **Phase 2: Skeleton Generation** - Create document structure\n",
    "3. **Phase 3: Node Expansion** - Generate prose per section\n",
    "4. **Phase 4: Verification & Refinement** - Quality gates and patching\n",
    "5. **Phase 5: Final Assembly** - Compile polished report\n",
    "\n",
    "## Technology Stack\n",
    "- **LLM**: gpt-5-mini-2025-08-07\n",
    "- **Web Search**: Tavily API\n",
    "- **Embeddings**: OpenAI text-embedding-3-small\n",
    "- **Tracing**: LangSmith\n",
    "- **Framework**: LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import asyncio\n",
    "import hashlib\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Annotated, TypedDict, Literal, Optional, Any\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "env_path = Path(\"../.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"deep_research_new\"\n",
    "\n",
    "print(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-5-mini-2025-08-07\n",
      "Research: max 3 sprints, 5 queries/sprint\n",
      "Refinement: max 2 iterations, threshold 7.5/10\n",
      "Cache: HIGH >= 0.75, LOW < 0.4\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM, Tavily, and Embeddings\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0, max_retries=10)\n",
    "tavily_client = TavilyClient()\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ===== CONFIGURATION PARAMETERS =====\n",
    "\n",
    "# Research Phase (Agile Sprints)\n",
    "MAX_RESEARCH_SPRINTS = 3\n",
    "QUERIES_PER_SPRINT = 5\n",
    "MIN_SOURCES_FOR_GATE1 = 15\n",
    "MIN_DOMAINS_FOR_GATE1 = 5\n",
    "\n",
    "# Skeleton Generation\n",
    "TARGET_WORDS_PER_NODE = 300\n",
    "MIN_SECTIONS = 5\n",
    "MAX_SECTIONS = 8\n",
    "\n",
    "# Knowledge Cache\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.75\n",
    "LOW_CONFIDENCE_THRESHOLD = 0.40\n",
    "SPECIFICITY_ADJUSTMENT = 0.2\n",
    "TOP_K_RETRIEVAL = 5\n",
    "\n",
    "# Verification & Refinement\n",
    "MAX_REFINEMENT_ITERATIONS = 2\n",
    "QUALITY_THRESHOLD = 7.5\n",
    "MIN_EVIDENCE_SCORE = 6\n",
    "MAX_CASCADES_PER_ITERATION = 5\n",
    "\n",
    "# Token Management\n",
    "MAX_CONTEXT_CHARS = 12000\n",
    "MAX_FINDINGS_CHARS = 10000\n",
    "\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "print(f\"Research: max {MAX_RESEARCH_SPRINTS} sprints, {QUERIES_PER_SPRINT} queries/sprint\")\n",
    "print(f\"Refinement: max {MAX_REFINEMENT_ITERATIONS} iterations, threshold {QUALITY_THRESHOLD}/10\")\n",
    "print(f\"Cache: HIGH >= {HIGH_CONFIDENCE_THRESHOLD}, LOW < {LOW_CONFIDENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2mhycmivay",
   "metadata": {},
   "source": [
    "## 2. Knowledge Cache Implementation\n",
    "\n",
    "The Knowledge Cache wraps ALL search operations throughout the agent, providing:\n",
    "- **Layer 1**: Deterministic deduplication (exact query match)\n",
    "- **Layer 2**: Semantic similarity retrieval (vector search)\n",
    "- **Layer 3**: LLM-augmented judgment (gap analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wejmds4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base initialized\n"
     ]
    }
   ],
   "source": [
    "# ===== Knowledge Cache Data Models =====\n",
    "\n",
    "class CachedDocument(BaseModel):\n",
    "    \"\"\"A cached web document.\"\"\"\n",
    "    url: str\n",
    "    normalized_url: str\n",
    "    content: str\n",
    "    content_hash: str\n",
    "    title: str = \"\"\n",
    "    retrieval_timestamp: str\n",
    "    source_query: str = \"\"\n",
    "\n",
    "\n",
    "class CachedChunk(BaseModel):\n",
    "    \"\"\"A chunk of content with embedding.\"\"\"\n",
    "    chunk_id: str\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "    source_url: str\n",
    "    position: int\n",
    "\n",
    "\n",
    "class CacheDecision(BaseModel):\n",
    "    \"\"\"Record of a cache decision for observability.\"\"\"\n",
    "    query: str\n",
    "    layer_reached: Literal[\"L1\", \"L2\", \"L3\"]\n",
    "    decision: str\n",
    "    confidence_score: float = 0.0\n",
    "    action_taken: Literal[\"USE_CACHE\", \"SEARCH\", \"TARGETED_SEARCH\"]\n",
    "    reasoning: str = \"\"\n",
    "    timestamp: str = \"\"\n",
    "\n",
    "\n",
    "class KnowledgeBase:\n",
    "    \"\"\"Session-scoped knowledge base with cascading cache capabilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url_registry: Dict[str, CachedDocument] = {}\n",
    "        self.query_cache: Dict[str, dict] = {}\n",
    "        self.chunks: List[CachedChunk] = []\n",
    "        self.chunk_embeddings: Optional[np.ndarray] = None\n",
    "        self.stats = {\n",
    "            \"total_queries\": 0, \"l1_hits\": 0, \"l2_high\": 0, \"l2_medium\": 0,\n",
    "            \"l2_low\": 0, \"l3_sufficient\": 0, \"l3_partial\": 0, \"l3_insufficient\": 0,\n",
    "            \"web_searches_executed\": 0, \"web_searches_avoided\": 0\n",
    "        }\n",
    "\n",
    "    def normalize_url(self, url: str) -> str:\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            host = parsed.netloc.lower()\n",
    "            if host.startswith(\"www.\"):\n",
    "                host = host[4:]\n",
    "            path = parsed.path.rstrip(\"/\")\n",
    "            return f\"https://{host}{path}\"\n",
    "        except:\n",
    "            return url.lower()\n",
    "\n",
    "    def normalize_query_light(self, query: str) -> str:\n",
    "        return \" \".join(query.lower().split())\n",
    "\n",
    "    def normalize_query_aggressive(self, query: str) -> str:\n",
    "        stop_words = {\"the\", \"a\", \"an\", \"is\", \"are\", \"of\", \"in\", \"to\", \"for\", \"and\", \"or\", \"what\", \"how\", \"why\"}\n",
    "        light = self.normalize_query_light(query)\n",
    "        terms = [t for t in light.split() if t not in stop_words and len(t) > 1]\n",
    "        return \" \".join(sorted(terms))\n",
    "\n",
    "    def compute_content_hash(self, content: str) -> str:\n",
    "        return hashlib.sha256(content.encode()).hexdigest()\n",
    "\n",
    "    def add_document(self, url: str, content: str, title: str = \"\", source_query: str = \"\"):\n",
    "        normalized_url = self.normalize_url(url)\n",
    "        doc = CachedDocument(\n",
    "            url=url, normalized_url=normalized_url, content=content,\n",
    "            content_hash=self.compute_content_hash(content), title=title,\n",
    "            retrieval_timestamp=datetime.now().isoformat(), source_query=source_query\n",
    "        )\n",
    "        self.url_registry[normalized_url] = doc\n",
    "        self._chunk_and_embed(doc)\n",
    "        return doc\n",
    "\n",
    "    def _chunk_and_embed(self, doc: CachedDocument):\n",
    "        content = doc.content\n",
    "        chunks_text = []\n",
    "        for i in range(0, len(content), CHUNK_SIZE - CHUNK_OVERLAP):\n",
    "            chunk_text = content[i:i + CHUNK_SIZE]\n",
    "            if len(chunk_text) > 50:\n",
    "                chunks_text.append(chunk_text)\n",
    "        if not chunks_text:\n",
    "            return\n",
    "        embeddings = embeddings_model.embed_documents(chunks_text)\n",
    "        for i, (text, embedding) in enumerate(zip(chunks_text, embeddings)):\n",
    "            chunk = CachedChunk(\n",
    "                chunk_id=f\"{doc.content_hash[:8]}_{i}\", text=text,\n",
    "                embedding=embedding, source_url=doc.url, position=i\n",
    "            )\n",
    "            self.chunks.append(chunk)\n",
    "        self._update_embedding_matrix()\n",
    "\n",
    "    def _update_embedding_matrix(self):\n",
    "        if self.chunks:\n",
    "            self.chunk_embeddings = np.array([c.embedding for c in self.chunks])\n",
    "\n",
    "    def add_query(self, query: str, result_urls: List[str], result_summary: str):\n",
    "        entry = {\n",
    "            \"original_query\": query, \"light_normalized\": self.normalize_query_light(query),\n",
    "            \"aggressive_normalized\": self.normalize_query_aggressive(query),\n",
    "            \"timestamp\": datetime.now().isoformat(), \"result_urls\": result_urls,\n",
    "            \"result_summary\": result_summary\n",
    "        }\n",
    "        self.query_cache[entry[\"light_normalized\"]] = entry\n",
    "        self.query_cache[entry[\"aggressive_normalized\"]] = entry\n",
    "        return entry\n",
    "\n",
    "    def lookup_query_exact(self, query: str) -> Optional[dict]:\n",
    "        return self.query_cache.get(self.normalize_query_light(query))\n",
    "\n",
    "    def semantic_search(self, query: str, top_k: int = TOP_K_RETRIEVAL) -> List[Tuple[CachedChunk, float]]:\n",
    "        if not self.chunks or self.chunk_embeddings is None:\n",
    "            return []\n",
    "        query_embedding = np.array(embeddings_model.embed_query(query))\n",
    "        similarities = np.dot(self.chunk_embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.chunk_embeddings, axis=1) * np.linalg.norm(query_embedding) + 1e-8\n",
    "        )\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        return [(self.chunks[idx], float(similarities[idx])) for idx in top_indices]\n",
    "\n",
    "    def get_stats_summary(self) -> str:\n",
    "        total = self.stats[\"total_queries\"]\n",
    "        if total == 0:\n",
    "            return \"No queries processed yet.\"\n",
    "        avoided = self.stats[\"web_searches_avoided\"]\n",
    "        hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "        return f\"Total: {total} queries, {avoided} avoided ({hit_rate:.1f}% hit rate), {len(self.chunks)} chunks cached\"\n",
    "\n",
    "\n",
    "# Initialize global knowledge base\n",
    "knowledge_base = KnowledgeBase()\n",
    "print(\"Knowledge base initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "t6srgqg8yfh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cascaded search function defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Cascaded Search Function =====\n",
    "\n",
    "def search_web(query: str, max_results: int = 8) -> Tuple[str, List[str], List[str]]:\n",
    "    \"\"\"Execute web search using Tavily. Returns (summary, results, urls).\"\"\"\n",
    "    try:\n",
    "        if len(query) > 400:\n",
    "            query = query[:400]\n",
    "        response = tavily_client.search(query=query, max_results=max_results, include_answer=True)\n",
    "        results = []\n",
    "        urls = []\n",
    "        summary = response.get(\"answer\", \"\")\n",
    "        for r in response.get(\"results\", []):\n",
    "            url = r.get('url', '')\n",
    "            urls.append(url)\n",
    "            content = r.get('content', '')[:500]\n",
    "            title = r.get('title', 'No title')\n",
    "            results.append(f\"[{title}] {content}... (Source: {url})\")\n",
    "        return summary, results, urls\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\", [], []\n",
    "\n",
    "\n",
    "def compute_confidence(top_results: List[Tuple[CachedChunk, float]], query: str) -> float:\n",
    "    \"\"\"Compute multi-signal confidence score.\"\"\"\n",
    "    if not top_results:\n",
    "        return 0.0\n",
    "    top_score = top_results[0][1]\n",
    "    score_gap = top_results[0][1] - top_results[1][1] if len(top_results) > 1 else top_score\n",
    "    query_terms = set(query.lower().split())\n",
    "    top_chunk_terms = set(top_results[0][0].text.lower().split())\n",
    "    term_overlap = len(query_terms & top_chunk_terms) / len(query_terms | top_chunk_terms) if query_terms | top_chunk_terms else 0\n",
    "    return 0.5 * top_score + 0.25 * min(score_gap * 2, 1.0) + 0.25 * term_overlap\n",
    "\n",
    "\n",
    "async def cascaded_search(query: str, kb: KnowledgeBase) -> Tuple[str, List[str], CacheDecision]:\n",
    "    \"\"\"Execute full cascading cache check and search if needed.\"\"\"\n",
    "    kb.stats[\"total_queries\"] += 1\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    # Layer 1: Exact match\n",
    "    exact_match = kb.lookup_query_exact(query)\n",
    "    if exact_match:\n",
    "        kb.stats[\"l1_hits\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        return exact_match[\"result_summary\"], exact_match[\"result_urls\"], CacheDecision(\n",
    "            query=query, layer_reached=\"L1\", decision=\"HIT\", confidence_score=1.0,\n",
    "            action_taken=\"USE_CACHE\", reasoning=\"Exact query match\", timestamp=timestamp\n",
    "        )\n",
    "\n",
    "    # Layer 2: Semantic search\n",
    "    results = kb.semantic_search(query)\n",
    "    if results:\n",
    "        confidence = compute_confidence(results, query)\n",
    "        if confidence >= HIGH_CONFIDENCE_THRESHOLD:\n",
    "            kb.stats[\"l2_high\"] += 1\n",
    "            kb.stats[\"web_searches_avoided\"] += 1\n",
    "            content = \"\\n\\n\".join([f\"[From: {c.source_url}]\\n{c.text}\" for c, _ in results[:3]])\n",
    "            urls = list(set([c.source_url for c, _ in results]))\n",
    "            return content, urls, CacheDecision(\n",
    "                query=query, layer_reached=\"L2\", decision=\"HIGH_CONF\", confidence_score=confidence,\n",
    "                action_taken=\"USE_CACHE\", reasoning=f\"High semantic similarity ({confidence:.2f})\", timestamp=timestamp\n",
    "            )\n",
    "        elif confidence >= LOW_CONFIDENCE_THRESHOLD:\n",
    "            kb.stats[\"l2_medium\"] += 1\n",
    "            # For medium confidence, still do a search but could use cached context\n",
    "        else:\n",
    "            kb.stats[\"l2_low\"] += 1\n",
    "\n",
    "    # Execute web search\n",
    "    summary, search_results, urls = search_web(query)\n",
    "    kb.stats[\"web_searches_executed\"] += 1\n",
    "\n",
    "    # Cache results\n",
    "    query_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\nResults:\\n\" + \"\\n\\n\".join(search_results)\n",
    "    synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "    kb.add_document(synthetic_url, query_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "    kb.add_query(query, urls, summary)\n",
    "\n",
    "    return query_content, urls, CacheDecision(\n",
    "        query=query, layer_reached=\"L2\", decision=\"LOW_CONF\",\n",
    "        confidence_score=compute_confidence(results, query) if results else 0.0,\n",
    "        action_taken=\"SEARCH\", reasoning=\"Executed web search\", timestamp=timestamp\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Cascaded search function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecg0xqpp7qm",
   "metadata": {},
   "source": [
    "## 3. State Definition and Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4syemwmgu7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data models defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Skeleton and Prose Models =====\n",
    "\n",
    "class SkeletonNode(BaseModel):\n",
    "    \"\"\"A node in the document skeleton hierarchy.\"\"\"\n",
    "    node_id: str = Field(description=\"Unique identifier like 'sec:intro'\")\n",
    "    title: str = Field(description=\"Section title\")\n",
    "    intent: str = Field(description=\"1-3 sentence description of purpose\")\n",
    "    target_word_count: int = Field(default=300)\n",
    "    dependencies: List[str] = Field(default_factory=list)\n",
    "    children: List[str] = Field(default_factory=list)\n",
    "    is_expanded: bool = Field(default=False)\n",
    "\n",
    "\n",
    "class SkeletonGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for skeleton generation.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence thesis statement\")\n",
    "    sections: List[SkeletonNode] = Field(description=\"All sections in document order\")\n",
    "\n",
    "\n",
    "class ProseGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for prose generation.\"\"\"\n",
    "    bridge_in: str = Field(description=\"Transitional sentences from previous section\")\n",
    "    main_content: str = Field(description=\"Main prose content\")\n",
    "    bridge_out: str = Field(description=\"Transitional sentences to next section\")\n",
    "    summary: str = Field(description=\"1-2 sentence summary\")\n",
    "\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"A verifiable assertion in the document.\"\"\"\n",
    "    claim_id: str\n",
    "    claim_text: str\n",
    "    source_node: str\n",
    "    verification_status: Literal[\"unverified\", \"verified\", \"contested\"] = \"unverified\"\n",
    "    supporting_evidence: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class ClaimExtractionOutput(BaseModel):\n",
    "    \"\"\"Output for claim extraction.\"\"\"\n",
    "    claims: List[Claim]\n",
    "\n",
    "\n",
    "class CritiqueIssue(BaseModel):\n",
    "    \"\"\"An issue identified during critique.\"\"\"\n",
    "    issue_id: str\n",
    "    scope: Literal[\"global\", \"section\", \"transition\"]\n",
    "    target_nodes: List[str]\n",
    "    issue_type: str\n",
    "    severity: Literal[\"critical\", \"major\", \"minor\"]\n",
    "    description: str\n",
    "    suggestion: str\n",
    "    search_query: str = \"\"\n",
    "\n",
    "\n",
    "class CritiqueResult(BaseModel):\n",
    "    \"\"\"Complete critique output.\"\"\"\n",
    "    overall_quality: float = Field(description=\"Quality score 1-10\")\n",
    "    issues: List[CritiqueIssue] = Field(default_factory=list)\n",
    "    summary: str\n",
    "\n",
    "\n",
    "print(\"Data models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff6wt0f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined state defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Combined Tier 1 State =====\n",
    "\n",
    "class CombinedTier1State(TypedDict):\n",
    "    \"\"\"State for the Combined Tier 1 Deep Research Agent.\"\"\"\n",
    "    # Input\n",
    "    question: str\n",
    "\n",
    "    # ===== PHASE 1: Research Sprints =====\n",
    "    research_backlog: List[str]  # REPLACED each sprint\n",
    "    current_research_sprint: int\n",
    "    max_research_sprints: int\n",
    "    sprint_findings: Annotated[List[str], operator.add]  # ACCUMULATED\n",
    "    research_source_urls: Annotated[List[str], operator.add]\n",
    "    research_retrospective_notes: Annotated[List[str], operator.add]\n",
    "    research_summary: str\n",
    "    research_complete: bool\n",
    "\n",
    "    # ===== PHASE 2: Skeleton =====\n",
    "    skeleton: Dict[str, Any]\n",
    "    skeleton_validated: bool\n",
    "\n",
    "    # ===== PHASE 3: Node Expansion =====\n",
    "    prose_store: Dict[str, Dict[str, Any]]\n",
    "    claims_registry: Dict[str, Dict[str, Any]]\n",
    "    nodes_expanded: List[str]\n",
    "\n",
    "    # ===== PHASE 4: Verification =====\n",
    "    noise_map: List[Dict[str, Any]]\n",
    "    nodes_to_patch: List[str]\n",
    "    cascade_queue: List[str]\n",
    "    targeted_evidence: Dict[str, List[str]]\n",
    "    current_refinement_iteration: int\n",
    "    max_refinement_iterations: int\n",
    "    quality_scores: Annotated[List[float], operator.add]\n",
    "    verification_log: Annotated[List[str], operator.add]\n",
    "\n",
    "    # ===== PHASE 5: Output =====\n",
    "    final_report: str\n",
    "\n",
    "    # ===== METRICS =====\n",
    "    total_searches: int\n",
    "    cache_hits: int\n",
    "    cache_decisions: Annotated[List[Dict], operator.add]\n",
    "\n",
    "\n",
    "print(\"Combined state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcm345wig8",
   "metadata": {},
   "source": [
    "## 4. Phase 1: Agile Research Sprints\n",
    "\n",
    "This phase decomposes the question, executes sprints with retrospectives, and produces a compressed research brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ctvzx7f1sm9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 prompts defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Prompts =====\n",
    "\n",
    "DECOMPOSE_PROMPT = \"\"\"You are a research planning expert. Decompose this research question into 5-7 specific sub-questions.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Generate a prioritized list of specific, focused research questions that together will comprehensively answer the main question. Each should be independently searchable.\n",
    "\n",
    "Return as a numbered list (highest priority first):\n",
    "1. [Most critical sub-question]\n",
    "2. [Second priority]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "SPRINT_SYNTHESIS_PROMPT = \"\"\"You are a research agent conducting Sprint {sprint_num} of {max_sprints}.\n",
    "\n",
    "Current research focus: {current_questions}\n",
    "\n",
    "Based on the search results below, extract key findings addressing these questions.\n",
    "Be specific and cite sources with URLs.\n",
    "\n",
    "Search Results:\n",
    "{search_results}\n",
    "\n",
    "Provide a comprehensive summary of findings (400-600 words) with specific facts and source URLs.\n",
    "\"\"\"\n",
    "\n",
    "RETROSPECTIVE_PROMPT = \"\"\"You are conducting a sprint retrospective for a research project.\n",
    "\n",
    "Original Question: {original_question}\n",
    "\n",
    "Sprint {sprint_num} of {max_sprints} has completed.\n",
    "\n",
    "Summary of findings so far:\n",
    "{findings_summary}\n",
    "\n",
    "Current remaining questions:\n",
    "{remaining_backlog}\n",
    "\n",
    "Provide a STRUCTURED response:\n",
    "\n",
    "## LEARNINGS\n",
    "Key insights from this sprint.\n",
    "\n",
    "## GAPS\n",
    "What is still unclear or needs investigation?\n",
    "\n",
    "## CONTINUE\n",
    "Should we continue with another sprint? Answer YES or NO.\n",
    "\n",
    "## NEW_QUESTIONS\n",
    "List 2-4 NEW questions that emerged (or \"None\"):\n",
    "- [New question 1]\n",
    "- [New question 2]\n",
    "\n",
    "## REPRIORITIZED_BACKLOG\n",
    "Reorder remaining questions by priority:\n",
    "1. [Highest priority]\n",
    "2. [Next priority]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "COMPRESS_FINDINGS_PROMPT = \"\"\"Summarize these research findings into a concise research brief.\n",
    "\n",
    "All Findings:\n",
    "{all_findings}\n",
    "\n",
    "Create a bullet-point summary (max 600 words) capturing:\n",
    "- Key facts and statistics\n",
    "- Main themes and patterns\n",
    "- Important sources\n",
    "- Any contradictions identified\n",
    "\n",
    "Be concise but preserve critical information.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Phase 1 prompts defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tz8p5jb6rv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 node functions defined (part 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Node Functions =====\n",
    "\n",
    "async def decompose_question(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Decompose the research question into a backlog of sub-questions.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1a: Question Decomposition\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    prompt = DECOMPOSE_PROMPT.format(question=question)\n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    lines = response.content.strip().split(\"\\n\")\n",
    "    backlog = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "            clean = line.lstrip(\"0123456789.-) \").strip()\n",
    "            if clean:\n",
    "                backlog.append(clean)\n",
    "    \n",
    "    print(f\"  Created backlog with {len(backlog)} research questions\")\n",
    "    for i, q in enumerate(backlog[:5], 1):\n",
    "        print(f\"    {i}. {q[:60]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"research_backlog\": backlog,\n",
    "        \"current_research_sprint\": 1,\n",
    "        \"max_research_sprints\": MAX_RESEARCH_SPRINTS,\n",
    "        \"research_complete\": False\n",
    "    }\n",
    "\n",
    "\n",
    "async def execute_research_sprint(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Execute a research sprint on top backlog items.\"\"\"\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 1b: Research Sprint {current_sprint}/{max_sprints}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not backlog:\n",
    "        return {\"sprint_findings\": [\"No questions in backlog.\"]}\n",
    "    \n",
    "    # Take top questions for this sprint\n",
    "    current_questions = backlog[:QUERIES_PER_SPRINT]\n",
    "    \n",
    "    all_content = []\n",
    "    all_urls = []\n",
    "    all_decisions = []\n",
    "    \n",
    "    for i, question in enumerate(current_questions, 1):\n",
    "        print(f\"  [{i}/{len(current_questions)}] {question[:50]}...\")\n",
    "        content, urls, decision = await cascaded_search(question, knowledge_base)\n",
    "        all_content.append(f\"### {question}\\n{content}\")\n",
    "        all_urls.extend(urls)\n",
    "        all_decisions.append(decision.model_dump())\n",
    "        \n",
    "        action = \"CACHE\" if decision.action_taken == \"USE_CACHE\" else \"SEARCH\"\n",
    "        print(f\"      {action} | Layer: {decision.layer_reached}\")\n",
    "    \n",
    "    # Synthesize findings\n",
    "    combined_results = \"\\n\\n---\\n\\n\".join(all_content)\n",
    "    if len(combined_results) > 12000:\n",
    "        combined_results = combined_results[:12000] + \"\\n...[truncated]\"\n",
    "    \n",
    "    synthesis_prompt = SPRINT_SYNTHESIS_PROMPT.format(\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        current_questions=\"\\n\".join(f\"- {q}\" for q in current_questions),\n",
    "        search_results=combined_results\n",
    "    )\n",
    "    \n",
    "    synthesis = await llm.ainvoke([HumanMessage(content=synthesis_prompt)])\n",
    "    finding = f\"## Sprint {current_sprint} Findings\\n\\n{synthesis.content}\"\n",
    "    \n",
    "    # Update backlog (remove processed questions)\n",
    "    updated_backlog = backlog[QUERIES_PER_SPRINT:]\n",
    "    \n",
    "    print(f\"  Synthesized {len(synthesis.content)} chars, {len(all_urls)} sources\")\n",
    "    \n",
    "    return {\n",
    "        \"sprint_findings\": [finding],\n",
    "        \"research_source_urls\": all_urls,\n",
    "        \"cache_decisions\": all_decisions,\n",
    "        \"research_backlog\": updated_backlog\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 1 node functions defined (part 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cijvkfsbm5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 node functions defined (part 2)\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 1 Node Functions (continued) =====\n",
    "\n",
    "def parse_reprioritized_backlog(response_content: str) -> List[str]:\n",
    "    \"\"\"Parse reprioritized backlog from retrospective.\"\"\"\n",
    "    backlog_match = re.search(r'## REPRIORITIZED_BACKLOG\\s*(.*?)(?=##|$)', response_content, re.DOTALL | re.IGNORECASE)\n",
    "    if backlog_match:\n",
    "        backlog_text = backlog_match.group(1)\n",
    "        questions = []\n",
    "        for line in backlog_text.strip().split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "                clean = re.sub(r'^[\\d\\.\\-\\)\\s]+', '', line).strip()\n",
    "                if clean and len(clean) > 10:\n",
    "                    questions.append(clean)\n",
    "        return questions\n",
    "    return []\n",
    "\n",
    "\n",
    "def parse_should_continue_research(response_content: str) -> bool:\n",
    "    \"\"\"Parse whether to continue from retrospective.\"\"\"\n",
    "    continue_match = re.search(r'## CONTINUE\\s*(.*?)(?=##|$)', response_content, re.DOTALL | re.IGNORECASE)\n",
    "    if continue_match:\n",
    "        text = continue_match.group(1).strip().lower()\n",
    "        negative_patterns = [r'^no\\b', r'should\\s+stop', r'sufficient', r'adequately']\n",
    "        for pattern in negative_patterns:\n",
    "            if re.search(pattern, text):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "async def research_retrospective(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Conduct retrospective after research sprint.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 1c: Sprint {current_sprint} Retrospective\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Summarize findings for token efficiency\n",
    "    if len(all_findings) > 4000:\n",
    "        compress_prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:8000])\n",
    "        compress_response = await llm.ainvoke([HumanMessage(content=compress_prompt)])\n",
    "        findings_summary = compress_response.content\n",
    "    else:\n",
    "        findings_summary = all_findings\n",
    "    \n",
    "    prompt = RETROSPECTIVE_PROMPT.format(\n",
    "        original_question=question,\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        findings_summary=findings_summary,\n",
    "        remaining_backlog=\"\\n\".join(f\"- {q}\" for q in backlog) if backlog else \"None\"\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    reprioritized = parse_reprioritized_backlog(response.content)\n",
    "    should_continue = parse_should_continue_research(response.content)\n",
    "    \n",
    "    if not reprioritized and backlog:\n",
    "        reprioritized = backlog\n",
    "    \n",
    "    print(f\"  Should continue: {should_continue}\")\n",
    "    print(f\"  Backlog size: {len(reprioritized)}\")\n",
    "    \n",
    "    return {\n",
    "        \"research_retrospective_notes\": [f\"### Sprint {current_sprint} Retrospective\\n{response.content}\"],\n",
    "        \"current_research_sprint\": current_sprint + 1,\n",
    "        \"research_backlog\": reprioritized,\n",
    "        \"research_summary\": findings_summary,\n",
    "        \"research_complete\": not should_continue\n",
    "    }\n",
    "\n",
    "\n",
    "async def quality_gate_1(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Check source sufficiency before moving to synthesis.\"\"\"\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    unique_urls = list(set(source_urls))\n",
    "    \n",
    "    # Count unique domains\n",
    "    domains = set()\n",
    "    for url in unique_urls:\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            domains.add(parsed.netloc)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Quality Gate 1: Source Sufficiency\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Unique sources: {len(unique_urls)} (min: {MIN_SOURCES_FOR_GATE1})\")\n",
    "    print(f\"  Unique domains: {len(domains)} (min: {MIN_DOMAINS_FOR_GATE1})\")\n",
    "    \n",
    "    passed = len(unique_urls) >= MIN_SOURCES_FOR_GATE1 and len(domains) >= MIN_DOMAINS_FOR_GATE1\n",
    "    print(f\"  Gate 1 {'PASSED' if passed else 'PASSED (relaxed)'}\")  # Always pass but note\n",
    "    \n",
    "    return {\"research_complete\": True}\n",
    "\n",
    "\n",
    "async def compress_findings(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Compress all findings into a research brief for skeleton generation.\"\"\"\n",
    "    all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 1d: Compressing Research Brief\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(all_findings) > MAX_FINDINGS_CHARS:\n",
    "        prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:MAX_FINDINGS_CHARS])\n",
    "        response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        summary = response.content\n",
    "    else:\n",
    "        summary = all_findings\n",
    "    \n",
    "    print(f\"  Compressed to {len(summary)} chars\")\n",
    "    \n",
    "    return {\"research_summary\": summary}\n",
    "\n",
    "\n",
    "def should_continue_research(state: CombinedTier1State) -> Literal[\"execute_sprint\", \"quality_gate_1\"]:\n",
    "    \"\"\"Decide whether to continue research or move to quality gate.\"\"\"\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    research_complete = state.get(\"research_complete\", False)\n",
    "    \n",
    "    if current_sprint > max_sprints:\n",
    "        print(f\"  Max sprints reached. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    if not backlog:\n",
    "        print(f\"  Backlog empty. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    if research_complete:\n",
    "        print(f\"  Research marked complete. Moving to Quality Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    \n",
    "    print(f\"  Continuing to sprint {current_sprint}.\")\n",
    "    return \"execute_sprint\"\n",
    "\n",
    "\n",
    "print(\"Phase 1 node functions defined (part 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qwvjkdiw82",
   "metadata": {},
   "source": [
    "## 5. Phase 2: Skeleton Generation\n",
    "\n",
    "Creates a hierarchical document structure before writing prose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "j2jwub7q73o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 2: Skeleton Generation =====\n",
    "\n",
    "SKELETON_PROMPT = \"\"\"You are a research document architect. Create a document skeleton.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Research Findings Summary:\n",
    "{research_summary}\n",
    "\n",
    "Create a hierarchical document structure with:\n",
    "1. A thesis statement (one sentence)\n",
    "2. 5-7 main sections for a comprehensive research report\n",
    "\n",
    "Each section needs:\n",
    "- node_id: Unique identifier like \"sec:intro\", \"sec:background\"\n",
    "- title: Descriptive section title\n",
    "- intent: 1-3 sentences describing what this section accomplishes\n",
    "- target_word_count: 250-400 words per section\n",
    "- dependencies: List of node_ids this section builds upon (empty for intro)\n",
    "- children: Empty list (flat structure)\n",
    "\n",
    "REQUIRED SECTIONS:\n",
    "1. Introduction - Present topic, context, thesis\n",
    "2. Background - Foundation knowledge\n",
    "3. Main Body (2-4 sections) - Key aspects in depth\n",
    "4. Analysis/Discussion - Synthesize findings\n",
    "5. Conclusion - Summary and future directions\n",
    "\n",
    "Node IDs must be unique. Dependencies must reference existing nodes only.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def validate_skeleton(skeleton: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"Validate skeleton structure.\"\"\"\n",
    "    issues = []\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    \n",
    "    for root_id in root_nodes:\n",
    "        if root_id not in nodes:\n",
    "            issues.append(f\"Root node '{root_id}' not found\")\n",
    "    \n",
    "    for node_id, node in nodes.items():\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id not in nodes:\n",
    "                issues.append(f\"Node '{node_id}' depends on non-existent '{dep_id}'\")\n",
    "    \n",
    "    return len(issues) == 0, issues\n",
    "\n",
    "\n",
    "async def generate_skeleton(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Generate the document skeleton structure.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    research_summary = state.get(\"research_summary\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 2: Skeleton Generation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    prompt = SKELETON_PROMPT.format(question=question, research_summary=research_summary[:6000])\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SkeletonGenerationOutput)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Build skeleton dictionary\n",
    "    skeleton = {\n",
    "        \"thesis\": result.thesis,\n",
    "        \"root_nodes\": [],\n",
    "        \"nodes\": {}\n",
    "    }\n",
    "    \n",
    "    child_ids = set()\n",
    "    for section in result.sections:\n",
    "        child_ids.update(section.children)\n",
    "    \n",
    "    for section in result.sections:\n",
    "        skeleton[\"nodes\"][section.node_id] = section.model_dump()\n",
    "        if section.node_id not in child_ids:\n",
    "            skeleton[\"root_nodes\"].append(section.node_id)\n",
    "    \n",
    "    if not skeleton[\"root_nodes\"]:\n",
    "        skeleton[\"root_nodes\"] = list(skeleton[\"nodes\"].keys())\n",
    "    \n",
    "    is_valid, issues = validate_skeleton(skeleton)\n",
    "    \n",
    "    print(f\"  Thesis: {result.thesis[:80]}...\")\n",
    "    print(f\"  Sections: {len(skeleton['nodes'])}\")\n",
    "    print(f\"  Valid: {is_valid}\")\n",
    "    if issues:\n",
    "        for issue in issues[:3]:\n",
    "            print(f\"    Warning: {issue}\")\n",
    "    \n",
    "    return {\n",
    "        \"skeleton\": skeleton,\n",
    "        \"skeleton_validated\": is_valid,\n",
    "        \"prose_store\": {},\n",
    "        \"claims_registry\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 2 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2oo3hx60bb",
   "metadata": {},
   "source": [
    "## 6. Phase 3: Node Expansion\n",
    "\n",
    "Generates prose for each skeleton node with dependency awareness and bridge sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4t2x8m8gwq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 3: Node Expansion =====\n",
    "\n",
    "PROSE_PROMPT = \"\"\"You are a research writer generating content for a specific section.\n",
    "\n",
    "DOCUMENT CONTEXT:\n",
    "Research Question: {question}\n",
    "Document Thesis: {thesis}\n",
    "\n",
    "SECTION TO WRITE:\n",
    "Node ID: {node_id}\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "Target Length: ~{target_words} words\n",
    "\n",
    "PREVIOUS SECTION ENDING:\n",
    "{previous_bridge_out}\n",
    "\n",
    "DEPENDENCY SUMMARIES:\n",
    "{dependency_summaries}\n",
    "\n",
    "RESEARCH FINDINGS:\n",
    "{research_findings}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. bridge_in (1-2 sentences): Transition from previous section\n",
    "2. main_content (~{target_words} words): Substantive prose with citations (Source: URL)\n",
    "3. bridge_out (1-2 sentences): Transition to next section\n",
    "4. summary (1-2 sentences): What this section establishes\n",
    "\n",
    "Be comprehensive, specific, and well-sourced.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_leaf_nodes(skeleton: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Get all leaf node IDs in document order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    \n",
    "    def collect_leaves(node_ids: List[str]) -> List[str]:\n",
    "        leaves = []\n",
    "        for nid in node_ids:\n",
    "            node = nodes.get(nid, {})\n",
    "            children = node.get(\"children\", [])\n",
    "            if not children:\n",
    "                leaves.append(nid)\n",
    "            else:\n",
    "                leaves.extend(collect_leaves(children))\n",
    "        return leaves\n",
    "    \n",
    "    return collect_leaves(root_nodes)\n",
    "\n",
    "\n",
    "def topological_sort_nodes(skeleton: Dict[str, Any], node_ids: List[str]) -> List[str]:\n",
    "    \"\"\"Sort nodes by dependency order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    node_id_set = set(node_ids)\n",
    "    remaining = set(node_ids)\n",
    "    sorted_nodes = []\n",
    "    \n",
    "    while remaining:\n",
    "        ready = []\n",
    "        for nid in remaining:\n",
    "            node = nodes.get(nid, {})\n",
    "            deps = set(node.get(\"dependencies\", []))\n",
    "            internal_deps = deps & node_id_set\n",
    "            if internal_deps.issubset(set(sorted_nodes)):\n",
    "                ready.append(nid)\n",
    "        \n",
    "        if not ready:\n",
    "            # Circular dependency - add remaining in order\n",
    "            for nid in node_ids:\n",
    "                if nid in remaining:\n",
    "                    sorted_nodes.append(nid)\n",
    "            break\n",
    "        \n",
    "        ready_ordered = [nid for nid in node_ids if nid in ready]\n",
    "        sorted_nodes.extend(ready_ordered)\n",
    "        remaining -= set(ready_ordered)\n",
    "    \n",
    "    return sorted_nodes\n",
    "\n",
    "\n",
    "async def expand_all_nodes(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Expand all leaf nodes in dependency order.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    research_summary = state.get(\"research_summary\", \"\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 3: Node Expansion\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_nodes = topological_sort_nodes(skeleton, leaf_nodes)\n",
    "    \n",
    "    prose_store = {}\n",
    "    claims_registry = {}\n",
    "    \n",
    "    for i, node_id in enumerate(sorted_nodes):\n",
    "        node = skeleton[\"nodes\"][node_id]\n",
    "        print(f\"  [{i+1}/{len(sorted_nodes)}] {node_id}: {node['title']}\")\n",
    "        \n",
    "        # Get previous node's bridge_out\n",
    "        prev_bridge_out = \"\"\n",
    "        if i > 0:\n",
    "            prev_id = sorted_nodes[i-1]\n",
    "            if prev_id in prose_store:\n",
    "                prev_bridge_out = prose_store[prev_id].get(\"bridge_out\", \"\")\n",
    "        \n",
    "        # Get dependency summaries\n",
    "        dep_summaries = []\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id in prose_store:\n",
    "                dep_title = skeleton[\"nodes\"].get(dep_id, {}).get(\"title\", dep_id)\n",
    "                dep_summary = prose_store[dep_id].get(\"summary\", \"\")\n",
    "                dep_summaries.append(f\"{dep_title}: {dep_summary}\")\n",
    "        \n",
    "        prompt = PROSE_PROMPT.format(\n",
    "            question=question,\n",
    "            thesis=skeleton.get(\"thesis\", \"\"),\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            target_words=node.get(\"target_word_count\", TARGET_WORDS_PER_NODE),\n",
    "            previous_bridge_out=prev_bridge_out if prev_bridge_out else \"(First section)\",\n",
    "            dependency_summaries=\"\\n\".join(dep_summaries) if dep_summaries else \"(No dependencies)\",\n",
    "            research_findings=research_summary[:4000]\n",
    "        )\n",
    "        \n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        prose_store[node_id] = {\n",
    "            \"node_id\": node_id,\n",
    "            \"main_content\": result.main_content,\n",
    "            \"bridge_in\": result.bridge_in,\n",
    "            \"bridge_out\": result.bridge_out,\n",
    "            \"summary\": result.summary,\n",
    "            \"revision_count\": 0\n",
    "        }\n",
    "        \n",
    "        print(f\"      Generated {len(result.main_content)} chars\")\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"claims_registry\": claims_registry,\n",
    "        \"nodes_expanded\": sorted_nodes\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 3 functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9q8tqacevdw",
   "metadata": {},
   "source": [
    "## 7. Phase 4: Verification and Refinement\n",
    "\n",
    "Critique the document, apply Quality Gate 2, do targeted retrieval for weak claims, and apply patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "h0agndxc5sc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 critique defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 4: Critique and Quality Gate 2 =====\n",
    "\n",
    "CRITIQUE_PROMPT = \"\"\"You are a critical reviewer evaluating a research document.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "DOCUMENT THESIS: {thesis}\n",
    "\n",
    "FULL DOCUMENT:\n",
    "{document_content}\n",
    "\n",
    "Analyze at THREE levels:\n",
    "\n",
    "## 1. GLOBAL ISSUES (entire document)\n",
    "- Thesis clarity and consistency\n",
    "- Overall argument flow\n",
    "- Terminology consistency\n",
    "\n",
    "## 2. SECTION ISSUES (per node) - MOST IMPORTANT\n",
    "- weak_claim: Claims lacking evidence\n",
    "- missing_evidence: Key assertions needing sources\n",
    "- logical_gap: Reasoning jumps\n",
    "- unclear: Ambiguous passages\n",
    "- depth: Insufficient detail\n",
    "\n",
    "## 3. TRANSITION ISSUES (between sections)\n",
    "- Abrupt topic shifts\n",
    "- Redundant transitions\n",
    "\n",
    "For each issue provide:\n",
    "- issue_id: Unique identifier\n",
    "- scope: \"global\", \"section\", or \"transition\"\n",
    "- target_nodes: Affected node IDs\n",
    "- issue_type: Category\n",
    "- severity: \"critical\", \"major\", or \"minor\"\n",
    "- description: What the problem is\n",
    "- suggestion: How to fix it\n",
    "- search_query: Query to find evidence (for evidence issues)\n",
    "\n",
    "SCORING (1-10):\n",
    "- 9-10: Publication ready\n",
    "- 7-8: Good, minor issues\n",
    "- 5-6: Needs improvement\n",
    "- 3-4: Significant problems\n",
    "\n",
    "Provide overall_quality score and list of issues.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def critique_document(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Perform structured critique producing the Noise Map.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state[\"prose_store\"]\n",
    "    question = state[\"question\"]\n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4a: Critique (Iteration {iteration})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build document content\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    document_content = \"\"\n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id in prose_store:\n",
    "            node = skeleton[\"nodes\"][node_id]\n",
    "            prose = prose_store[node_id]\n",
    "            document_content += f\"\\n\\n## {node['title']} [{node_id}]\\n\"\n",
    "            document_content += f\"{prose.get('bridge_in', '')}\\n\"\n",
    "            document_content += f\"{prose.get('main_content', '')}\\n\"\n",
    "            document_content += f\"{prose.get('bridge_out', '')}\\n\"\n",
    "    \n",
    "    if len(document_content) > 12000:\n",
    "        document_content = document_content[:12000] + \"\\n...[truncated]\"\n",
    "    \n",
    "    prompt = CRITIQUE_PROMPT.format(\n",
    "        question=question,\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        document_content=document_content\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(CritiqueResult)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    noise_map = [issue.model_dump() for issue in result.issues]\n",
    "    \n",
    "    # Identify nodes needing patches\n",
    "    nodes_to_patch = list(set(\n",
    "        node_id for issue in result.issues\n",
    "        for node_id in issue.target_nodes\n",
    "        if issue.severity in [\"critical\", \"major\"]\n",
    "    ))\n",
    "    \n",
    "    print(f\"  Quality Score: {result.overall_quality}/10\")\n",
    "    print(f\"  Issues: {len(result.issues)}\")\n",
    "    print(f\"  Nodes to patch: {len(nodes_to_patch)}\")\n",
    "    \n",
    "    return {\n",
    "        \"noise_map\": noise_map,\n",
    "        \"nodes_to_patch\": nodes_to_patch,\n",
    "        \"quality_scores\": [result.overall_quality],\n",
    "        \"current_refinement_iteration\": iteration\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Phase 4 critique defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87in7uvly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 retrieval and patching defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 4: Targeted Retrieval and Patching =====\n",
    "\n",
    "PATCH_PROMPT = \"\"\"You are revising a section based on critique feedback.\n",
    "\n",
    "SECTION TO REVISE:\n",
    "Node ID: {node_id}\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "\n",
    "CURRENT CONTENT:\n",
    "{current_content}\n",
    "\n",
    "ISSUES TO FIX:\n",
    "{issues_text}\n",
    "\n",
    "NEW EVIDENCE:\n",
    "{new_evidence}\n",
    "\n",
    "CONTEXT:\n",
    "Previous section ends with: {prev_bridge_out}\n",
    "Next section starts with: {next_bridge_in}\n",
    "\n",
    "Revise the section to address ALL issues, incorporate evidence with citations.\n",
    "Output: bridge_in, main_content, bridge_out, summary\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def targeted_retrieval(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Search for evidence to address issues.\"\"\"\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 4b: Targeted Retrieval\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No nodes need patching\")\n",
    "        return {\"targeted_evidence\": {}}\n",
    "    \n",
    "    # Collect search queries per node\n",
    "    node_queries = {}\n",
    "    for issue in noise_map:\n",
    "        if issue.get(\"search_query\") and issue.get(\"severity\") in [\"critical\", \"major\"]:\n",
    "            for node_id in issue.get(\"target_nodes\", []):\n",
    "                if node_id in nodes_to_patch:\n",
    "                    if node_id not in node_queries:\n",
    "                        node_queries[node_id] = []\n",
    "                    node_queries[node_id].append(issue[\"search_query\"])\n",
    "    \n",
    "    targeted_evidence = {}\n",
    "    \n",
    "    for node_id, queries in node_queries.items():\n",
    "        print(f\"  Searching for: {node_id}\")\n",
    "        node_evidence = []\n",
    "        for query in queries[:2]:  # Limit queries per node\n",
    "            print(f\"    Query: {query[:40]}...\")\n",
    "            content, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "            node_evidence.append(content[:1000])\n",
    "            action = \"CACHE\" if decision.action_taken == \"USE_CACHE\" else \"SEARCH\"\n",
    "            print(f\"      {action} | Layer: {decision.layer_reached}\")\n",
    "        targeted_evidence[node_id] = node_evidence\n",
    "    \n",
    "    print(f\"  Evidence gathered for {len(targeted_evidence)} nodes\")\n",
    "    \n",
    "    return {\"targeted_evidence\": targeted_evidence}\n",
    "\n",
    "\n",
    "async def apply_patches(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Apply patches to nodes with issues.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state[\"prose_store\"]\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    targeted_evidence = state.get(\"targeted_evidence\", {})\n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 4c: Apply Patches\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No patches needed\")\n",
    "        return {\"prose_store\": prose_store, \"current_refinement_iteration\": iteration + 1}\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_patch = topological_sort_nodes(skeleton, [n for n in nodes_to_patch if n in leaf_nodes])\n",
    "    \n",
    "    for node_id in sorted_patch[:3]:  # Limit patches per iteration\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "        \n",
    "        node = skeleton[\"nodes\"].get(node_id, {})\n",
    "        current = prose_store[node_id]\n",
    "        \n",
    "        print(f\"  Patching: {node_id}\")\n",
    "        \n",
    "        # Get issues for this node\n",
    "        node_issues = [i for i in noise_map if node_id in i.get(\"target_nodes\", [])]\n",
    "        issues_text = \"\\n\".join([\n",
    "            f\"- [{i['severity']}] {i['issue_type']}: {i['description']}\"\n",
    "            for i in node_issues\n",
    "        ])\n",
    "        \n",
    "        evidence = targeted_evidence.get(node_id, [])\n",
    "        evidence_text = \"\\n\\n\".join(evidence) if evidence else \"No additional evidence.\"\n",
    "        \n",
    "        # Get adjacent context\n",
    "        idx = leaf_nodes.index(node_id) if node_id in leaf_nodes else -1\n",
    "        prev_bridge = prose_store.get(leaf_nodes[idx-1], {}).get(\"bridge_out\", \"\") if idx > 0 else \"\"\n",
    "        next_bridge = prose_store.get(leaf_nodes[idx+1], {}).get(\"bridge_in\", \"\") if idx < len(leaf_nodes)-1 else \"\"\n",
    "        \n",
    "        prompt = PATCH_PROMPT.format(\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            current_content=f\"{current.get('bridge_in', '')}\\n{current.get('main_content', '')}\\n{current.get('bridge_out', '')}\",\n",
    "            issues_text=issues_text,\n",
    "            new_evidence=evidence_text[:3000],\n",
    "            prev_bridge_out=prev_bridge if prev_bridge else \"(First)\",\n",
    "            next_bridge_in=next_bridge if next_bridge else \"(Last)\"\n",
    "        )\n",
    "        \n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        prose_store[node_id] = {\n",
    "            \"node_id\": node_id,\n",
    "            \"main_content\": result.main_content,\n",
    "            \"bridge_in\": result.bridge_in,\n",
    "            \"bridge_out\": result.bridge_out,\n",
    "            \"summary\": result.summary,\n",
    "            \"revision_count\": current.get(\"revision_count\", 0) + 1\n",
    "        }\n",
    "        \n",
    "        print(f\"    Revised: {len(result.main_content)} chars\")\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"current_refinement_iteration\": iteration + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def should_continue_refining(state: CombinedTier1State) -> Literal[\"targeted_retrieval\", \"assemble\"]:\n",
    "    \"\"\"Decide whether to continue refinement.\"\"\"\n",
    "    iteration = state.get(\"current_refinement_iteration\", 0)\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    \n",
    "    latest_score = quality_scores[-1] if quality_scores else 0\n",
    "    \n",
    "    print(f\"\\n--- Quality Gate 2 ---\")\n",
    "    print(f\"  Iteration: {iteration}/{MAX_REFINEMENT_ITERATIONS}\")\n",
    "    print(f\"  Score: {latest_score}/{QUALITY_THRESHOLD}\")\n",
    "    \n",
    "    if iteration >= MAX_REFINEMENT_ITERATIONS:\n",
    "        print(\"  Max iterations. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    if latest_score >= QUALITY_THRESHOLD:\n",
    "        print(\"  Quality threshold met. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    if not nodes_to_patch:\n",
    "        print(\"  No issues. Finalizing.\")\n",
    "        return \"assemble\"\n",
    "    \n",
    "    print(\"  Continuing refinement.\")\n",
    "    return \"targeted_retrieval\"\n",
    "\n",
    "\n",
    "print(\"Phase 4 retrieval and patching defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hrpkztl86ol",
   "metadata": {},
   "source": [
    "## 8. Phase 5: Final Assembly\n",
    "\n",
    "Assembles the final markdown report from all prose entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f13xtzj6ns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 5 assembly defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Phase 5: Final Assembly =====\n",
    "\n",
    "async def assemble_document(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Assemble the final document from prose entries.\"\"\"\n",
    "    skeleton = state[\"skeleton\"]\n",
    "    prose_store = state[\"prose_store\"]\n",
    "    quality_scores = state.get(\"quality_scores\", [])\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Phase 5: Final Assembly\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    \n",
    "    # Build document\n",
    "    parts = []\n",
    "    parts.append(f\"# Research Report\\n\")\n",
    "    parts.append(f\"**Thesis:** {skeleton.get('thesis', '')}\\n\\n\")\n",
    "    \n",
    "    for node_id in leaf_nodes:\n",
    "        if node_id not in prose_store:\n",
    "            continue\n",
    "        node = skeleton[\"nodes\"].get(node_id, {})\n",
    "        prose = prose_store[node_id]\n",
    "        \n",
    "        parts.append(f\"## {node.get('title', node_id)}\\n\\n\")\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            parts.append(f\"{prose['bridge_in']} \")\n",
    "        parts.append(f\"{prose.get('main_content', '')}\")\n",
    "        if prose.get(\"bridge_out\"):\n",
    "            parts.append(f\" {prose['bridge_out']}\")\n",
    "        parts.append(\"\\n\\n\")\n",
    "    \n",
    "    # References\n",
    "    unique_urls = list(set(source_urls))\n",
    "    if unique_urls:\n",
    "        parts.append(\"## References\\n\\n\")\n",
    "        for i, url in enumerate(unique_urls[:25], 1):\n",
    "            parts.append(f\"{i}. {url}\\n\")\n",
    "    \n",
    "    final_report = \"\".join(parts)\n",
    "    word_count = len(final_report.split())\n",
    "    \n",
    "    print(f\"  Document: {len(final_report)} chars ({word_count} words)\")\n",
    "    print(f\"  Sections: {len(leaf_nodes)}\")\n",
    "    print(f\"  Quality: {' -> '.join([f'{s:.1f}' for s in quality_scores])}\")\n",
    "    print(f\"  Sources: {len(unique_urls)}\")\n",
    "    print(f\"  Cache: {knowledge_base.get_stats_summary()}\")\n",
    "    \n",
    "    return {\"final_report\": final_report}\n",
    "\n",
    "\n",
    "print(\"Phase 5 assembly defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h2odwkgb4lf",
   "metadata": {},
   "source": [
    "## 9. Graph Construction\n",
    "\n",
    "Build the complete LangGraph combining all phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "v8576b11i7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Tier 1 Agent compiled successfully!\n",
      "\n",
      "Architecture:\n",
      "  Phase 1: decompose → [sprint → retrospective] → gate1 → compress\n",
      "  Phase 2: generate_skeleton\n",
      "  Phase 3: expand_all_nodes\n",
      "  Phase 4: [critique → retrieval → patch] loop\n",
      "  Phase 5: assemble_document\n"
     ]
    }
   ],
   "source": [
    "# ===== Graph Construction =====\n",
    "\n",
    "builder = StateGraph(CombinedTier1State)\n",
    "\n",
    "# Add all nodes\n",
    "builder.add_node(\"decompose_question\", decompose_question)\n",
    "builder.add_node(\"execute_research_sprint\", execute_research_sprint)\n",
    "builder.add_node(\"research_retrospective\", research_retrospective)\n",
    "builder.add_node(\"quality_gate_1\", quality_gate_1)\n",
    "builder.add_node(\"compress_findings\", compress_findings)\n",
    "builder.add_node(\"generate_skeleton\", generate_skeleton)\n",
    "builder.add_node(\"expand_all_nodes\", expand_all_nodes)\n",
    "builder.add_node(\"critique_document\", critique_document)\n",
    "builder.add_node(\"targeted_retrieval\", targeted_retrieval)\n",
    "builder.add_node(\"apply_patches\", apply_patches)\n",
    "builder.add_node(\"assemble_document\", assemble_document)\n",
    "\n",
    "# Phase 1: Research Sprints\n",
    "builder.add_edge(START, \"decompose_question\")\n",
    "builder.add_edge(\"decompose_question\", \"execute_research_sprint\")\n",
    "builder.add_edge(\"execute_research_sprint\", \"research_retrospective\")\n",
    "\n",
    "# Research loop\n",
    "builder.add_conditional_edges(\n",
    "    \"research_retrospective\",\n",
    "    should_continue_research,\n",
    "    {\n",
    "        \"execute_sprint\": \"execute_research_sprint\",\n",
    "        \"quality_gate_1\": \"quality_gate_1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Phase 1 -> Phase 2\n",
    "builder.add_edge(\"quality_gate_1\", \"compress_findings\")\n",
    "builder.add_edge(\"compress_findings\", \"generate_skeleton\")\n",
    "\n",
    "# Phase 2 -> Phase 3\n",
    "builder.add_edge(\"generate_skeleton\", \"expand_all_nodes\")\n",
    "\n",
    "# Phase 3 -> Phase 4\n",
    "builder.add_edge(\"expand_all_nodes\", \"critique_document\")\n",
    "\n",
    "# Phase 4: Refinement loop\n",
    "builder.add_conditional_edges(\n",
    "    \"critique_document\",\n",
    "    should_continue_refining,\n",
    "    {\n",
    "        \"targeted_retrieval\": \"targeted_retrieval\",\n",
    "        \"assemble\": \"assemble_document\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"targeted_retrieval\", \"apply_patches\")\n",
    "builder.add_edge(\"apply_patches\", \"critique_document\")\n",
    "\n",
    "# Phase 5\n",
    "builder.add_edge(\"assemble_document\", END)\n",
    "\n",
    "# Compile\n",
    "combined_tier1_graph = builder.compile()\n",
    "\n",
    "print(\"Combined Tier 1 Agent compiled successfully!\")\n",
    "print(\"\\nArchitecture:\")\n",
    "print(\"  Phase 1: decompose → [sprint → retrospective] → gate1 → compress\")\n",
    "print(\"  Phase 2: generate_skeleton\")\n",
    "print(\"  Phase 3: expand_all_nodes\")\n",
    "print(\"  Phase 4: [critique → retrieval → patch] loop\")\n",
    "print(\"  Phase 5: assemble_document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cysou8b9rc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "try:\n",
    "    display(Image(combined_tier1_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thcu30qhwx",
   "metadata": {},
   "source": [
    "## 10. Agent Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fn44x7nej9u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent wrappers defined\n"
     ]
    }
   ],
   "source": [
    "# ===== Agent Wrapper =====\n",
    "\n",
    "async def combined_tier1_agent_async(inputs: dict) -> dict:\n",
    "    \"\"\"Async version of the Combined Tier 1 research agent.\"\"\"\n",
    "    global knowledge_base\n",
    "    knowledge_base = KnowledgeBase()  # Reset for fresh session\n",
    "    \n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    result = await combined_tier1_graph.ainvoke(\n",
    "        {\"question\": question},\n",
    "        config={\"recursion_limit\": 100}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.stats.copy(),\n",
    "        \"skeleton\": result.get(\"skeleton\", {}),\n",
    "        \"research_sprints\": result.get(\"current_research_sprint\", 1) - 1,\n",
    "        \"refinement_iterations\": result.get(\"current_refinement_iteration\", 0)\n",
    "    }\n",
    "\n",
    "\n",
    "def combined_tier1_agent(inputs: dict) -> dict:\n",
    "    \"\"\"Sync wrapper for Combined Tier 1 research agent. Compatible with evaluation harness.\"\"\"\n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    async def _execute():\n",
    "        global knowledge_base\n",
    "        knowledge_base = KnowledgeBase()\n",
    "        return await combined_tier1_graph.ainvoke(\n",
    "            {\"question\": question},\n",
    "            config={\"recursion_limit\": 100}\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import concurrent.futures\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(asyncio.run, _execute())\n",
    "            result = future.result()\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(_execute())\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.stats.copy()\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Agent wrappers defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9umohyn6mv",
   "metadata": {},
   "source": [
    "## 11. Manual Test\n",
    "\n",
    "Run this cell to verify the Combined Tier 1 agent works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1ftb2wr0s",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Combined Tier 1 Agent\n",
      "Question: What are the key benefits and challenges of using large language models in enterprise applications?\n",
      "\n",
      "Running combined architecture (this will take several minutes)...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Phase 1a: Question Decomposition\n",
      "============================================================\n",
      "  Created backlog with 7 research questions\n",
      "    1. What measurable business benefits (productivity improvements...\n",
      "    2. What are the primary model-quality and reliability challenge...\n",
      "    3. How do data privacy, confidentiality, and regulatory require...\n",
      "    4. What are the technical and operational integration challenge...\n",
      "    5. What governance, ethics, and accountability challenges (bias...\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 1/3\n",
      "============================================================\n",
      "  [1/5] What measurable business benefits (productivity im...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] What are the primary model-quality and reliability...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] How do data privacy, confidentiality, and regulato...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] What are the technical and operational integration...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] What governance, ethics, and accountability challe...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 5994 chars, 40 sources\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 1 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 7\n",
      "  Continuing to sprint 2.\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 2/3\n",
      "============================================================\n",
      "  [1/5] What are the total cost of ownership and procureme...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] What human factors and organizational-change chall...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] Define standardized, domain-specific evaluation fr...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] RAG and knowledge-store security: map attack surfa...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] Develop a vendor-claim validation playbook: templa...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 5279 chars, 40 sources\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 2 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 12\n",
      "  Continuing to sprint 3.\n",
      "\n",
      "============================================================\n",
      "Phase 1b: Research Sprint 3/3\n",
      "============================================================\n",
      "  [1/5] Model lifecycle & ops playbook — top priority...\n",
      "      SEARCH | Layer: L2\n",
      "  [2/5] Deliverable: an actionable playbook covering stage...\n",
      "      SEARCH | Layer: L2\n",
      "  [3/5] Suggested experiments/metrics for Sprint 3: run a ...\n",
      "      SEARCH | Layer: L2\n",
      "  [4/5] Legal/regulatory risk quantification — second prio...\n",
      "      SEARCH | Layer: L2\n",
      "  [5/5] Deliverable: a framework to translate measured err...\n",
      "      SEARCH | Layer: L2\n",
      "  Synthesized 6009 chars, 29 sources\n",
      "\n",
      "============================================================\n",
      "Phase 1c: Sprint 3 Retrospective\n",
      "============================================================\n",
      "  Should continue: True\n",
      "  Backlog size: 9\n",
      "  Max sprints reached. Moving to Quality Gate 1.\n",
      "\n",
      "============================================================\n",
      "Quality Gate 1: Source Sufficiency\n",
      "============================================================\n",
      "  Unique sources: 107 (min: 15)\n",
      "  Unique domains: 88 (min: 5)\n",
      "  Gate 1 PASSED\n",
      "\n",
      "============================================================\n",
      "Phase 1d: Compressing Research Brief\n",
      "============================================================\n",
      "  Compressed to 4037 chars\n",
      "\n",
      "============================================================\n",
      "Phase 2: Skeleton Generation\n",
      "============================================================\n",
      "  Thesis: Large language models can deliver measurable business impact in targeted enterpr...\n",
      "  Sections: 7\n",
      "  Valid: True\n",
      "\n",
      "============================================================\n",
      "Phase 3: Node Expansion\n",
      "============================================================\n",
      "  [1/7] sec:intro: Introduction: LLMs in the Enterprise — Scope and Thesis\n",
      "      Generated 821 chars\n",
      "  [2/7] sec:background: Background: LLM Fundamentals, Market Context, and Evaluation Landscape\n",
      "      Generated 2418 chars\n",
      "  [3/7] sec:benefits: Business Benefits: Use Cases, Measured Outcomes, and Economic Effects\n",
      "      Generated 2491 chars\n",
      "  [4/7] sec:technical: Technical Challenges and Mitigations: Reliability, Quality, and Evaluation\n",
      "      Generated 2441 chars\n",
      "  [5/7] sec:orgops: Organizational, Privacy, and Operational Considerations: Governance, Costs, and Adoption\n",
      "      Generated 2614 chars\n",
      "  [6/7] sec:analysis: Analysis and Discussion: Tradeoffs, Contradictions, and Strategic Recommendations\n",
      "      Generated 2813 chars\n",
      "  [7/7] sec:conclusion: Conclusion and Future Directions: Summary, Practical Next Steps, and Research Needs\n",
      "      Generated 2227 chars\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Critique (Iteration 0)\n",
      "============================================================\n",
      "  Quality Score: 6.0/10\n",
      "  Issues: 15\n",
      "  Nodes to patch: 5\n",
      "\n",
      "--- Quality Gate 2 ---\n",
      "  Iteration: 0/2\n",
      "  Score: 6.0/7.5\n",
      "  Continuing refinement.\n",
      "\n",
      "============================================================\n",
      "Phase 4b: Targeted Retrieval\n",
      "============================================================\n",
      "  Searching for: sec:intro\n",
      "    Query: enterprise LLM ROI case study independen...\n",
      "      SEARCH | Layer: L2\n",
      "    Query: independent study generative AI producti...\n",
      "      SEARCH | Layer: L2\n",
      "  Searching for: sec:background\n",
      "    Query: enterprise LLM ROI case study independen...\n",
      "      CACHE | Layer: L1\n",
      "    Query: independent study generative AI producti...\n",
      "      CACHE | Layer: L1\n",
      "  Searching for: sec:benefits\n",
      "    Query: enterprise LLM ROI case study independen...\n",
      "      CACHE | Layer: L1\n",
      "    Query: independent study generative AI producti...\n",
      "      CACHE | Layer: L1\n",
      "  Searching for: sec:technical\n",
      "    Query: enterprise LLM ROI case study independen...\n",
      "      CACHE | Layer: L1\n",
      "    Query: retrieval augmented generation reduces h...\n",
      "      SEARCH | Layer: L2\n",
      "  Searching for: sec:orgops\n",
      "    Query: enterprise LLM ROI case study independen...\n",
      "      CACHE | Layer: L1\n",
      "    Query: LLM governance framework 'data processin...\n",
      "      SEARCH | Layer: L2\n",
      "  Evidence gathered for 5 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 4c: Apply Patches\n",
      "============================================================\n",
      "  Patching: sec:intro\n",
      "    Revised: 4836 chars\n",
      "  Patching: sec:background\n",
      "    Revised: 7132 chars\n",
      "  Patching: sec:technical\n",
      "    Revised: 8760 chars\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Critique (Iteration 1)\n",
      "============================================================\n",
      "  Quality Score: 7.0/10\n",
      "  Issues: 12\n",
      "  Nodes to patch: 2\n",
      "\n",
      "--- Quality Gate 2 ---\n",
      "  Iteration: 1/2\n",
      "  Score: 7.0/7.5\n",
      "  Continuing refinement.\n",
      "\n",
      "============================================================\n",
      "Phase 4b: Targeted Retrieval\n",
      "============================================================\n",
      "  Searching for: sec:intro\n",
      "    Query: McKinsey generative AI 2025 productivity...\n",
      "      SEARCH | Layer: L2\n",
      "    Query: 15-40% productivity uplift generative AI...\n",
      "      SEARCH | Layer: L2\n",
      "  Searching for: sec:background\n",
      "    Query: McKinsey generative AI 2025 productivity...\n",
      "      CACHE | Layer: L1\n",
      "    Query: TruthfulQA hallucination rates LLM hallu...\n",
      "      SEARCH | Layer: L2\n",
      "  Evidence gathered for 2 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 4c: Apply Patches\n",
      "============================================================\n",
      "  Patching: sec:intro\n",
      "    Revised: 8266 chars\n",
      "  Patching: sec:background\n",
      "    Revised: 10708 chars\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Critique (Iteration 2)\n",
      "============================================================\n",
      "  Quality Score: 6.0/10\n",
      "  Issues: 13\n",
      "  Nodes to patch: 9\n",
      "\n",
      "--- Quality Gate 2 ---\n",
      "  Iteration: 2/2\n",
      "  Score: 6.0/7.5\n",
      "  Max iterations. Finalizing.\n",
      "\n",
      "============================================================\n",
      "Phase 5: Final Assembly\n",
      "============================================================\n",
      "  Document: 44285 chars (5375 words)\n",
      "  Sections: 7\n",
      "  Quality: 6.0 -> 7.0 -> 6.0\n",
      "  Sources: 107\n",
      "  Cache: Total: 29 queries, 7 avoided (24.1% hit rate), 239 chunks cached\n",
      "\n",
      "================================================================================\n",
      "FINAL REPORT\n",
      "================================================================================\n",
      "# Research Report\n",
      "**Thesis:** Large language models can deliver measurable business impact in targeted enterprise use cases, but realizing that value at scale requires disciplined TCO management, robust privacy and governance architectures, multidimensional evaluation, and strong change-management focused on trust and UX.\n",
      "\n",
      "## Introduction: LLMs in the Enterprise — Scope and Thesis\n",
      "\n",
      "The following revised introduction sharpens the report’s research question, defines what we mean by “enterprise‑grade” LLM deployments, grounds headline claims with specific sources and methodology notes, and gives a practical budget breakdown tied to common architecture choices. Research question and scope\n",
      "This report asks a practical question for CIOs, product leaders, and compliance teams: what concrete benefits and measurable risks do large language models (LLMs) bring when deployed under enterprise constraints, and what organizational, technical, and regulatory practices are required to capture the upside while limiting harm?\n",
      "Scope and boundary conditions\n",
      "We focus on enterprise‑grade deployment—not consumer chat or experimental research use. By “enterprise‑grade” we mean systems that must meet a combination of the following typical thresholds and capabilities: authenticated access and single‑sign‑on (SSO), centralized audit logging and role‑based access control, agreed SLAs (commonly 99.9%+ uptime for core services and latency targets appropriate to the application), data residency and PII controls required by regulation, support for concurrent users at production scale (from tens to thousands of daily active users), and formal governance (model inventory, risk signoff, and incident response). Where an organization’s requirements fall below these thresholds (for example, a one‑person pilot using a hosted API without sensitive data), the recommended technical and compliance practices in this report should be calibrated downward.\n",
      "Thesis (evidence‑linked and qualified)\n",
      "LLMs can deliver measurable business impact in many enterprise contexts, but reliable value capture requires disciplined cost management, rigorous evaluation frameworks, and active governance. This conclusion is supported by three linked observations:\n",
      "1. Broad and growing adoption is documented across multiple independent sources, and many studies find sizable per‑task uplifts in knowledge‑work activities. (See McKinsey, 2025; peer‑reviewed benchmarks described below.)\n",
      "2. Empirical outcomes vary substantially by task, measurement approach, and implementation choices: gains reported for individual tasks (e.g., draft generation, summarization, coding assistance) do not automatically translate to team‑level or long‑run ROI without process redesign and measurement.\n",
      "3. Projects lacking explicit governance, evaluation, and resourcing plans face heightened risk of underperformance or abandonment.\n",
      "What the evidence shows (sources, methods, and nuance)\n",
      "Adoption and macro impact: McKinsey’s 2025 analysis (How Generative AI Is Reshaping Global Productivity and the Future of Work, McKinsey & Company, 2025) evaluated 63 use cases across 16 business functions and estimates large aggregate economic potential (McKinsey highlights a multitrillion‑dollar upside and reports routine generative‑AI deployment in a large share of firms—reported ~71% in 2024–25). These figures are macro estimates built from case‑by‑case modeling and should be used to set strategic expectations rather than as direct implementation forecasts.\n",
      "Per‑task productivity figures and methodological caveats: Several industry and academic sources report per‑task productivity improvements commonly quoted in the 15–40% range for affected activities. Important qualifiers:\n",
      "- Task definition matters: reported gains typically apply to narrowly defined tasks (e.g., first‑draft document generation, code completion, or initial legal brief drafting), not end‑to‑end business processes. \n",
      "- Measurement method varies: studies use time‑motion measur...\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "Report length: 44285 characters\n",
      "Research sprints: 3\n",
      "Refinement iterations: 2\n",
      "Quality scores: [6.0, 7.0, 6.0]\n",
      "Unique sources: 107\n",
      "\n",
      "Cache Performance:\n",
      "  Total queries: 29\n",
      "  Cache hits: 7 (24.1%)\n",
      "  L1 hits: 7\n",
      "  L2 HIGH: 0\n",
      "\n",
      "Agent test PASSED\n"
     ]
    }
   ],
   "source": [
    "# Manual Test\n",
    "test_question = \"What are the key benefits and challenges of using large language models in enterprise applications?\"\n",
    "\n",
    "print(f\"Testing Combined Tier 1 Agent\")\n",
    "print(f\"Question: {test_question}\")\n",
    "print(\"\\nRunning combined architecture (this will take several minutes)...\\n\")\n",
    "\n",
    "try:\n",
    "    result = await combined_tier1_agent_async({\"question\": test_question})\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result[\"output\"][:4000] + \"...\" if len(result[\"output\"]) > 4000 else result[\"output\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Report length: {len(result['output'])} characters\")\n",
    "    print(f\"Research sprints: {result.get('research_sprints', 'N/A')}\")\n",
    "    print(f\"Refinement iterations: {result.get('refinement_iterations', 'N/A')}\")\n",
    "    print(f\"Quality scores: {result.get('quality_scores', [])}\")\n",
    "    print(f\"Unique sources: {len(result.get('source_urls', []))}\")\n",
    "    \n",
    "    stats = result.get(\"cache_stats\", {})\n",
    "    total = stats.get(\"total_queries\", 0)\n",
    "    avoided = stats.get(\"web_searches_avoided\", 0)\n",
    "    hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nCache Performance:\")\n",
    "    print(f\"  Total queries: {total}\")\n",
    "    print(f\"  Cache hits: {avoided} ({hit_rate:.1f}%)\")\n",
    "    print(f\"  L1 hits: {stats.get('l1_hits', 0)}\")\n",
    "    print(f\"  L2 HIGH: {stats.get('l2_high', 0)}\")\n",
    "    \n",
    "    print(\"\\nAgent test PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Agent test FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc84975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report\n",
       "**Thesis:** Large language models can deliver measurable business impact in targeted enterprise use cases, but realizing that value at scale requires disciplined TCO management, robust privacy and governance architectures, multidimensional evaluation, and strong change-management focused on trust and UX.\n",
       "\n",
       "## Introduction: LLMs in the Enterprise — Scope and Thesis\n",
       "\n",
       "The following revised introduction sharpens the report’s research question, defines what we mean by “enterprise‑grade” LLM deployments, grounds headline claims with specific sources and methodology notes, and gives a practical budget breakdown tied to common architecture choices. Research question and scope\n",
       "This report asks a practical question for CIOs, product leaders, and compliance teams: what concrete benefits and measurable risks do large language models (LLMs) bring when deployed under enterprise constraints, and what organizational, technical, and regulatory practices are required to capture the upside while limiting harm?\n",
       "Scope and boundary conditions\n",
       "We focus on enterprise‑grade deployment—not consumer chat or experimental research use. By “enterprise‑grade” we mean systems that must meet a combination of the following typical thresholds and capabilities: authenticated access and single‑sign‑on (SSO), centralized audit logging and role‑based access control, agreed SLAs (commonly 99.9%+ uptime for core services and latency targets appropriate to the application), data residency and PII controls required by regulation, support for concurrent users at production scale (from tens to thousands of daily active users), and formal governance (model inventory, risk signoff, and incident response). Where an organization’s requirements fall below these thresholds (for example, a one‑person pilot using a hosted API without sensitive data), the recommended technical and compliance practices in this report should be calibrated downward.\n",
       "Thesis (evidence‑linked and qualified)\n",
       "LLMs can deliver measurable business impact in many enterprise contexts, but reliable value capture requires disciplined cost management, rigorous evaluation frameworks, and active governance. This conclusion is supported by three linked observations:\n",
       "1. Broad and growing adoption is documented across multiple independent sources, and many studies find sizable per‑task uplifts in knowledge‑work activities. (See McKinsey, 2025; peer‑reviewed benchmarks described below.)\n",
       "2. Empirical outcomes vary substantially by task, measurement approach, and implementation choices: gains reported for individual tasks (e.g., draft generation, summarization, coding assistance) do not automatically translate to team‑level or long‑run ROI without process redesign and measurement.\n",
       "3. Projects lacking explicit governance, evaluation, and resourcing plans face heightened risk of underperformance or abandonment.\n",
       "What the evidence shows (sources, methods, and nuance)\n",
       "Adoption and macro impact: McKinsey’s 2025 analysis (How Generative AI Is Reshaping Global Productivity and the Future of Work, McKinsey & Company, 2025) evaluated 63 use cases across 16 business functions and estimates large aggregate economic potential (McKinsey highlights a multitrillion‑dollar upside and reports routine generative‑AI deployment in a large share of firms—reported ~71% in 2024–25). These figures are macro estimates built from case‑by‑case modeling and should be used to set strategic expectations rather than as direct implementation forecasts.\n",
       "Per‑task productivity figures and methodological caveats: Several industry and academic sources report per‑task productivity improvements commonly quoted in the 15–40% range for affected activities. Important qualifiers:\n",
       "- Task definition matters: reported gains typically apply to narrowly defined tasks (e.g., first‑draft document generation, code completion, or initial legal brief drafting), not end‑to‑end business processes. \n",
       "- Measurement method varies: studies use time‑motion measurements, A/B experiments, simulated tasks, or expert grading; each method has different biases (e.g., simulated tasks may overstate transfer to noisy production settings). \n",
       "- Short‑term vs. long‑term: early lifts can be large for drafting and ideation tasks, while team‑level productivity depends on workflow integration, retraining, and process redesign.\n",
       "Sources for model capability and safety: Peer‑reviewed benchmarks and reproducible evaluations (for example, TruthfulQA [Lin et al., 2022], MMLU, HumanEval) provide standardized measures of model capabilities and failure modes that complement industry adoption studies. These benchmarks help estimate risks (hallucination, reliability, prompt sensitivity) that influence governance and evaluation design, but they do not directly measure enterprise ROI.\n",
       "Failure and abandonment risks: Independent industry analysis (e.g., Gartner, 2024) flags a nontrivial abandonment rate for generative‑AI initiatives when governance, training, and integration are insufficient (Gartner’s projections suggested roughly a 30% abandonment risk for early GenAI projects by 2025). The patterns reported—insufficient training, lack of evaluation metrics, and weak executive sponsorship—are consistent across multiple independent reports.\n",
       "On vendor examples and independent studies: Vendor case studies and vendor‑reported efficiency figures are useful for illustration but often use opaque baselines and selective examples; they should not be treated as population‑level estimates. This report privileges independent analyses and peer‑reviewed benchmarks where available, and flags vendor examples as illustrative.\n",
       "Cost drivers and a practical budget breakdown\n",
       "The total cost of ownership (TCO) for enterprise LLM programs is driven by model choice (hosted API vs. private/hybrid hosting), data preparation and labeling, systems integration, security and compliance engineering, monitoring and MLOps, and ongoing licensing/compute. Typical ballpark ranges (intended as planning inputs, not firm quotes):\n",
       "- Small, tightly scoped pilot (proof‑of‑value, no sensitive data, using hosted APIs): ~$25k–$100k total. Major line items: prompt engineering and design; a limited integration; third‑party API spend; evaluation and user testing.\n",
       "- Mid‑scale, departmental deployment (integrations to CRM/ERP, limited private data, basic compliance controls): ~$250k–$1M first‑year. Major line items: data ingestion and cleaning, labeling or fine‑tuning data, engineering for connectors, security hardening, MLOps pipelines, and licensing.\n",
       "- Enterprise program (multi‑team, sensitive data, private hosting or VPC, strict compliance and residency needs): $1M+ annually. Major line items: private model hosting or dedicated inference clusters, high‑volume labeling and data engineering, full security/compliance engineering (data governance, DLP, encryption, auditability), SLAs, model governance process, and staff costs for continuous monitoring and improvement.\n",
       "Key architecture tradeoffs that change cost: using a hosted API lowers initial fixed costs but raises variable inference costs and may not meet strict residency or provenance requirements; private hosting raises capital and operational costs (GPU clusters, engineering for scaling) but can reduce per‑query cost at high volume and enable stronger data controls.\n",
       "Headline findings that motivate the report\n",
       "- Adoption is widespread but uneven: many organizations have active generative‑AI initiatives, yet success depends on integration, data readiness, and workforce practices (McKinsey, 2025; Gartner, 2024). \n",
       "- Per‑task productivity gains are plausible but context‑dependent: independent studies commonly report 15–40% improvements on narrowly defined tasks; team and long‑run benefits require measurement and redesign. \n",
       "- Failure and abandonment are real risks: absent governance, evaluation metrics, and training, a substantial share of projects may fail to realize expected outcomes (Gartner, 2024). \n",
       "- Cost and compliance are first‑order constraints: TCO is driven by model hosting choice, data preparation and labeling, integration engineering, and ongoing monitoring; regulatory and privacy obligations can materially change economics.\n",
       "How this report uses evidence\n",
       "Subsequent sections analyze evaluation metrics, cost drivers, technical architectures, and governance practices using a hierarchy of evidence: independent industry analyses and reproducible benchmarks first, peer‑reviewed work and public benchmarks second, and vendor examples only as illustrative. Where empirical support is thin or mixed we call that out explicitly and recommend conservative planning assumptions. The prescriptive recommendations that follow are tied back to these empirical patterns: they aim to reduce documented risks (abandonment, overruns, safety incidents) and increase the probability of realizing the productivity gains independent studies report. Building on the thesis that capturing LLM value requires disciplined TCO, governance, and multidimensional evaluation, the next section grounds those prescriptions in technical fundamentals: LLM basics, common enterprise architectures, market signals, and the evaluation and safety landscape enterprises face.\n",
       "\n",
       "## Background: LLM Fundamentals, Market Context, and Evaluation Landscape\n",
       "\n",
       "Building on the thesis that capturing LLM value requires disciplined TCO, governance, and multidimensional evaluation, the following revised background consolidates technical fundamentals, enterprise architecture tradeoffs, and independent evidence (peer‑reviewed and public benchmarks) to ground our prescriptions in reproducible findings and concrete operational controls. What LLMs are (foundations and measured failure modes)\n",
       "- Definition and capabilities: Large language models (LLMs) are transformer‑based neural networks pre‑trained on very large text corpora and often instruction‑tuned to perform generation and understanding tasks (Vaswani et al., 2017; Brown et al., 2020). When conditioned with prompts and context, they can summarize, answer questions, generate code, and support dialog workflows—capabilities that industry and academic studies link to productivity improvements in knowledge work (McKinsey, 2025; peer‑reviewed evaluations summarized below).\n",
       "\n",
       "- Empirical failure modes (quantified): academic benchmarks and reproducible case studies document persistent, often measurable shortcomings that matter in production:\n",
       "  - Hallucination (factual errors): public benchmarks such as TruthfulQA and task‑specific factuality tests show non‑trivial error rates across models and prompts. For example, TruthfulQA evaluations report sizable failure rates on knowledge‑demanding prompts for earlier instruction‑tuned and base models; subsequent models reduce but do not eliminate these rates (see TruthfulQA benchmark results; comparative model evaluations, 2021–2024). Reproducible studies and system evaluations typically report remaining factuality/failure rates in the low double‑digits to tens of percent depending on task difficulty, prompting style, and grounding—underscoring that hallucination is not a corner case but a frequent operational risk (TruthfulQA; Lewis et al., 2020; Rowen et al., 2023–24).\n",
       "  - Context‑window limits: finite context lengths introduce truncation and retrieval‑freshness problems for long documents and pipelines that concatenate many sources; empirical work shows degradation in coherence and factual recall as context exceeds model limits (GPT‑family evaluations; Kaplan et al., scaling‑law analyses).\n",
       "  - Prompt brittleness: empirical prompting research (e.g., chain‑of‑thought and few‑shot prompting studies) demonstrates that small syntactic or example changes can substantially alter outputs and measured task performance, creating reproducibility and engineering brittleness in production (Wei et al., 2022; subsequent prompt‑sensitivity papers).\n",
       "  - Model drift and distributional change: classical ML literature (Gama et al., 2014) and contemporary LLM pipeline studies document that input distribution shifts and changes to knowledge sources (retrieval index staleness, business process changes) degrade deployed performance over time.\n",
       "\n",
       "Practical implication: the measurable nature of these failure modes explains why governance, dataset and metric‑driven evaluation, human oversight, and change management materially affect reliability and ROI in production deployments.\n",
       "\n",
       "Common architectural patterns and decision criteria (definitions and tradeoffs)\n",
       "- Definitions (acronyms): TCO = total cost of ownership; VPC = virtual private cloud; RAG = retrieval‑augmented generation; AHT = average handle time; TAT = turnaround time; NPS = Net Promoter Score.\n",
       "\n",
       "- Hosted/API (SaaS) models\n",
       "  - Pros: fastest time‑to‑value, minimal infra ops, elastic scaling.\n",
       "  - Cons and operational controls: less direct control of data flows unless the vendor provides contractual, technical, and audit guarantees (e.g., SOC 2, ISO 27001, Data Processing Agreement, subprocessors disclosure). For regulated data, enterprises should require contractual commitments, encrypted transport, customer‑controlled keys (where available), and documented logging/subpoena handling policies.\n",
       "  - When to choose: pilots, proofs‑of‑concept, low‑sensitivity data, or when speed is the priority.\n",
       "\n",
       "- Private / VPC / on‑prem deployments\n",
       "  - Pros: stronger data residency and provenance, end‑to‑end encryption under enterprise control, and easier alignment to certification regimes when implemented correctly (e.g., HIPAA controls for health data; NIST/HHS guidance for PHI handling).\n",
       "  - Cons: substantially higher infra and operational costs, longer lead times for deployment, and greater maintenance/engineering overhead (observability, patching, model updates).\n",
       "  - When to choose: regulated domains, strict SLAs/latency requirements, or where full audit trails and data residency are required.\n",
       "\n",
       "- Hybrid architectures (API gateway + private hosting)\n",
       "  - Pros: pragmatic balance—use hosted models for low‑sensitivity workloads while routing regulated or high‑risk queries to private models, and apply data classification and routing policies.\n",
       "  - Decision note: hybrids are common when teams scale from pilots to production and need to balance cost, latency, and compliance.\n",
       "\n",
       "- Retrieval‑Augmented Generation (RAG) and grounding (evidence and tradeoffs)\n",
       "  - What it is: RAG augments generation with retrieval from internal knowledge stores (sparse or dense) so model outputs can be explicitly grounded in retrieved passages (Lewis et al., 2020).\n",
       "  - Measured effect: multiple evaluations show RAG reduces unsupported statements and improves factual grounding in knowledge‑intensive tasks. Comparative studies report substantive reductions in hallucination metrics (reported reductions vary by dataset and retrieval quality, commonly in the tens of percent) and improve verifiable answer rates versus pure generative baselines (Lewis et al., 2020; Rowen et al., 2023–24). However, RAG is not a panacea: gains depend on index quality, retrieval latency, prompt engineering, and freshness policies—stale or mis‑indexed vectors can introduce systematic errors.\n",
       "  - Tradeoffs: added engineering (vector store management, index refresh, embedding pipelines), higher per‑query latency/cost, and new failure modes (bad retrievals, attribution errors). Operational controls include retrieval quality monitoring, citation‑style outputs, and fallbacks to human review when retrieval confidence is low.\n",
       "\n",
       "- Domain adaptation and fine‑tuning\n",
       "  - Benefits and risks: instruction‑tuning or specialist fine‑tuning can improve domain accuracy on held‑out test sets, but increases maintenance (retraining, monitoring), can amplify dataset biases, and raises auditing complexity. Fine‑tuning decisions should be backed by measured gains on reproducible, domain‑specific evaluation sets and cost/benefit analyses.\n",
       "\n",
       "Market and procurement context (evidence and caveats)\n",
       "- Adoption and outcomes: independent industry evidence shows rapid adoption—e.g., surveys reporting ~71% of organizations regularly using generative AI—and analyst syntheses (Gartner, 2024; McKinsey, 2025) estimate broad productivity gains. McKinsey’s 2025 analysis quantifies potential labour productivity uplift across many use cases (summary: up to tens of percent improvements and an aggregate economic potential on the order of trillions annually). Peer‑reviewed and publicly reproducible case studies corroborate that benefits are real but highly variable by use case and execution quality (McKinsey, 2025; peer‑reviewed evaluations cited above).\n",
       "\n",
       "- Cautionary signals and abandonment risk: analyst warnings are specific—without governance, many initiatives underdeliver or are discontinued (Gartner, 2024; observed program churn in industry postmortems). This supports the report’s core argument that measurement, governance, and change management are decisive for ROI.\n",
       "\n",
       "- Budgets and KPIs: reported spends vary by scope—pilots can be low‑cost while enterprise programs often reach six‑figure to low seven‑figure annual budgets. Common, measurable KPIs tied to ROI include process metrics (TAT, AHT, throughput), quality metrics (error/rework rates, factuality/hallucination rates), and customer metrics (NPS/CSAT). Vendor claims should be validated via controlled pilots, A/B tests, or pre/post baselines with pre‑registered success criteria.\n",
       "\n",
       "Evaluation, safety, and operational observability (concrete guardrails and evidence of tooling gaps)\n",
       "- Multidimensional evaluation: evaluation has shifted from single‑turn accuracy to pipelines that measure task completion, factuality/hallucination rates (benchmarked via TruthfulQA and task datasets), toxicity/privacy leakage, latency, and cost per query. Domain‑specific safety (clinical, legal, financial) requires bespoke benchmarks plus human‑in‑the‑loop verification.\n",
       "\n",
       "- Tooling and what it does: teams commonly use MLflow, Weights & Biases, OpenAI Evals, and specialized third‑party platforms to capture metrics, run regression suites, and surface drift. These tools materially improve observability and reproducibility, enable rollout policies (canarying, shadow testing), and simplify experiment tracking.\n",
       "\n",
       "- Tooling gaps (evidence and examples): however, independent reproducibility studies and vendor evaluations show gaps remain—particularly around multi‑step agent evaluation, compositional safety across chained APIs, and domain‑specific certification workflows. For example, while OpenAI Evals and third‑party platforms automate single‑turn factuality checks, multi‑step agents that call external tools or databases require scenario‑based, stateful testing that is not yet solved by off‑the‑shelf tooling (academic reproducibility reports; vendor whitepapers).\n",
       "\n",
       "- Recommended guardrails (operational prescriptives tied to evidence):\n",
       "  - Continuous testing: automate regression suites, hallucination/factuality tests (including RAG grounding tests and citation checks), latency and cost budgets, and freshness checks for retrieval systems.\n",
       "  - Human review and escalation: integrate human oversight for high‑risk outputs and periodic audits of fine‑tuned models; use adjudicated test sets for high‑risk domains.\n",
       "  - Change management and training: require role‑based training, documented SOPs, and stakeholder buy‑in; empirical studies show adoption correlates strongly with organizational training and governance.\n",
       "  - Measurement discipline: require pre‑registered success criteria (KPIs, duration, datasets) for pilots, and insist on independent or blinded evaluation where feasible to avoid optimistic vendor narratives.\n",
       "\n",
       "Takeaway for the report’s thesis\n",
       "- Synthesis: peer‑reviewed benchmarks and public evaluations (TruthfulQA, RAG comparisons, and reproducible case studies) plus industry surveys and analyst syntheses (McKinsey, 2025; Gartner, 2024) converge on a consistent conclusion: LLMs can deliver measurable business impact but only when technical choices (hosted vs private vs hybrid, RAG, fine‑tuning) are made with clear decision criteria, and when disciplined TCO, continuous evaluation, and governance are enforced. Quantitative risks (hallucination rates, latency/cost tradeoffs for RAG, and prompt/context brittleness) should be tracked with concrete metrics and mitigations built into procurement and operational playbooks. Having established the technical primitives, comparative architecture tradeoffs, and an evaluation‑centric set of operational guardrails grounded in public benchmarks and peer‑reviewed findings, the report next examines concrete business outcomes enterprises report when deploying these models in targeted workflows.\n",
       "\n",
       "## Business Benefits: Use Cases, Measured Outcomes, and Economic Effects\n",
       "\n",
       "Having established the technical primitives, market shape, and evaluation landscape for LLMs, we now turn to concrete business outcomes enterprises report when deploying these models in targeted workflows. Enterprises consistently report four classes of business benefits from LLM adoption: productivity gains, operational efficiency, improved customer experience, and new revenue or product capabilities. Representative, vendor-reported values include ~40% reductions in content‑creation time, ~60% faster document processing, and ~40% reductions in customer‑service handling time—figures cited in recent case studies and vendor materials (AssemblyAI; AgileSoftLabs). Source: https://www.assemblyai.com, https://www.agilesoftlabs.com\n",
       "\n",
       "How organizations quantify these effects: most programs use A/B experiments or before/after process KPIs tied to specific workflows rather than universal accuracy metrics. Typical measurement levers are turnaround time (TAT) or processing throughput, average handle time (AHT) in contact centers, error/rework rates for document tasks, and customer metrics such as NPS/CSAT for CX improvements. Conversion, lead velocity, and monetized time-savings are typical for revenue-impact claims. Robust programs combine randomized A/B tests for external-facing changes with controlled canaries and pre/post process metrics for back‑office automation. Source: https://openai.com/evals, https://wandb.ai, https://mlflow.org\n",
       "\n",
       "Economic effects are material but heterogeneous. Pilot budgets commonly range $20k–$60k, mid‑sized apps $60k–$250k+, and enterprise programs $400k–$1M+ when factoring model costs, integration, and governance—so initial ROI can be rapid for high‑frequency, well‑scoped tasks but scales into recurring opex (inference, storage, monitoring, data labeling) that can create “runaway” TCO without discipline. Source: https://quokkalabs.ai, https://ecosystm360.com\n",
       "\n",
       "Caveats on generalizability and benchmarking: vendor case studies frequently report strong, task‑level gains, but methods vary and results are often proprietary and non‑replicable; cross‑vendor ROI comparisons are therefore unreliable without shared baselines. Regulatory and privacy constraints (GDPR, HIPAA) also shape architecture choices—cloud APIs may enable fast time‑to‑value, but private/VPC deployments are common where provenance and data residency matter, which changes cost and speed tradeoffs. Source: https://www.startus-insights.com, https://www.researchgate.net\n",
       "\n",
       "In practice, realizing reported benefits requires disciplined experiment design, continuous QA/observability for model drift and hallucinations, and strong change management to secure user adoption and trust. The next section examines the cost drivers and architectures that reconcile these measured benefits with compliance, privacy, and long‑term total cost of ownership.\n",
       "\n",
       "## Technical Challenges and Mitigations: Reliability, Quality, and Evaluation\n",
       "\n",
       "The previous section established that pilots can produce measurable benefits but only when compliance, operational controls, and human factors are aligned. Before we turn to cost and architecture tradeoffs, it is necessary to pivot from outcomes to the technical failure modes that most commonly erode those gains and the concrete engineering and governance patterns that prevent them. Framing: why failure modes matter\n",
       "LLM pilots often show clear task-level gains (e.g., faster draft generation, improved decision support), but converting pilot wins into durable, auditable production value requires disciplined TCO, governance, and continuous evaluation. Empirical surveys underline both the opportunity and the risk: in 2024 roughly 71% of organizations regularly deployed generative AI, yet analysts estimate up to 30% of GenAI projects will be abandoned by 2025 unless operational practices improve (Gartner, 2024). At the same time, McKinsey’s 2025 review finds substantial ROI for adopters—74% of leaders met or exceeded expectations—highlighting that success is achievable but contingent on operational rigor (McKinsey, 2025). These mixed outcomes motivate a focused look at the technical failure modes and the engineering patterns that materially reduce operational and regulatory risk.\n",
       "\n",
       "Principal failure modes (definitions)\n",
       "- Hallucinations: confident but factually incorrect or unverifiable outputs.\n",
       "- Prompt/context brittleness: materially different outputs when prompts or surrounding context shift slightly.  \n",
       "- Hard context-window limits: inability to retain or reason over long histories or documents within a single model context.  \n",
       "- Model drift: performance changes over time as input distributions, user behavior, or downstream labels evolve.  \n",
       "- Evaluation gaps / multidimensional evaluation: lack of standardized, task‑aligned metrics (factuality, safety, latency, cost, human satisfaction) that collectively reflect business value.\n",
       "\n",
       "Why these matter\n",
       "Each failure mode raises direct costs (increased human review, rework), indirect costs (lost user trust, regulatory exposure), and recurring operational costs (monitoring, retraining). That link—from technical failure to governance/TCO—explains why recommendations about governance and TCO must be tightly coupled to engineering patterns: mitigations reduce both technical risk and the downstream governance burden.\n",
       "\n",
       "Evidence and what empirics say about RAG and grounding\n",
       "Retrieval‑augmented generation (RAG) — where the model conditions on retrieved, vetted documents rather than relying on internal parametric memory — is widely adopted because it reduces factual errors and improves provenance. Foundational work (e.g., Lewis et al., 2020) demonstrated the approach, and systematic reviews/surveys (e.g., a recent survey synthesizing ~51 RAG studies) report consistent reductions in hallucinated content across many domains while noting important caveats (ScienceDirect survey, 2023/24). Key empirical points:\n",
       "- Consistent directionality: multiple evaluations find fewer factual hallucinations with RAG than closed‑book (exact magnitudes vary by dataset and retrieval quality).  \n",
       "- Sensitivity to retrieval quality: RAG can fail when the retriever returns noisy, stale, or ambiguous documents — in such cases grounding can amplify incorrect source material.  \n",
       "- Domain dependence: effectiveness is higher when the knowledge store is comprehensive and well‑curated (internal docs, vetted KBs); performance degrades if the knowledge base lacks coverage of the target domain.\n",
       "Practical implication: RAG should be treated as a risk‑reduction technique, not a panacea. Instrument retrieval precision@k, provenance links, and run regular retrieval-quality audits.\n",
       "\n",
       "Repeatable engineering mitigations (what to adopt and why)\n",
       "- Grounding / RAG with provenance: store and version sources, attach retrieval IDs to responses, and expose provenance in outputs. Empirical work supports improved factuality when retrieval precision is high (Lewis et al., 2020; systematic surveys). \n",
       "- Domain adaptation and controlled fine‑tuning: private fine‑tuning or instruction tuning on curated in‑domain corpora improves robustness to prompt/context shifts — but this requires governance: data lineage, privacy controls, holdout test sets, and versioned model artifacts.  \n",
       "- Prompt design and response steering: use system-level constraints, structured templates, and few‑shot exemplars to constrain output style and reduce error modes.  \n",
       "- Structured QA and CI for models: apply unit tests (single-shot checks), adversarial suites (targeted edge cases), synthetic scenario suites (multi‑step logic), and regression tests run in CI for any model or retrieval changes (OpenAI Evals and similar frameworks are useful here).  \n",
       "- Observability and continuous validation: log inputs, retrieval context identifiers, model versions, outputs, latencies, downstream task outcomes, and user feedback; use these signals for drift detection and automated canary/rollback rules.\n",
       "\n",
       "Concrete observability metrics, log schema, and alert guidance\n",
       "- Key production metrics to collect: factuality/hallucination rate (measured via periodic human or automated checks), retrieval precision@k, answer correctness (task-specific), latency P50/P95, token cost per request, user satisfaction (NPS or task success rate), human‑in‑loop escalation rate, and AHT (average handling time) or TAT (turnaround time) where applicable. Define acronyms: AHT = average handling time; TAT = turnaround time; NPS = net promoter score.  \n",
       "- Example alert rules (illustrative):\n",
       "  - Trigger investigation if hallucination rate increases by >20% relative to baseline or exceeds an absolute threshold (e.g., >5%) for high‑risk workflows.  \n",
       "  - Alert if retrieval precision@5 drops by >15% or if P95 latency increases beyond SLA (e.g., 2× baseline).  \n",
       "  - Auto‑roll back canary if task correctness falls below agreed SLAs on holdout tests.  \n",
       "- Minimal log schema (per request): timestamp, user/request ID, model/version, system prompt hash, user prompt, retrieval IDs + scores, retrieved texts (or pointers), response, token usage, latency, downstream outcome (if available), human label or feedback, and privacy/classification tags. Store this schema in indexed observability storage for efficient query and drift detection.\n",
       "\n",
       "Testing and CI specifics\n",
       "- Unit tests: canonical prompts and expected outputs (string/semantic match, tolerances).  \n",
       "- Adversarial tests: crafted prompts designed to elicit hallucinations or unsafe behavior.  \n",
       "- Scenario suites: multi‑step workflows that exercise chain‑of‑thought, memory, and external tool calls.  \n",
       "- Canary and staged rollouts: deploy to small cohorts, monitor the test and production metrics above, then expand if thresholds are met. Integrate model change reviews into product release processes and include human‑in‑the‑loop checkpoints for high‑risk changes.\n",
       "\n",
       "Operational patterns and governance connections\n",
       "Adopt hybrid architectures (cloud APIs for fast experimentation; VPC or private models for regulated data), staged canarying, and human‑in‑the‑loop gating for high‑risk outputs. These engineering choices have direct governance and TCO implications: private hosting raises fixed cost but lowers compliance overhead; rigorous observability and CI increase near‑term engineering cost but reduce long‑term review and regulatory costs.\n",
       "\n",
       "Toolchains and benchmark gaps\n",
       "Modern toolchains typically combine vector stores, RAG pipelines, monitoring/trace systems, evaluation frameworks (OpenAI Evals, custom suites), and retraining pipelines (W&B, MLflow, or equivalent). Significant gaps remain: standardized benchmarks for multi‑step agent behavior, consistent hallucination scoring across tasks, and domain‑specific safety metrics. Because third‑party benchmarks are incomplete, enterprises often build customized evaluation suites and synthetic adversarial tests to achieve acceptable reliability.\n",
       "\n",
       "Practical checklist (what to start with in Q1)\n",
       "1) Define multidimensional SLAs: factuality, latency, cost-per-call, human escalation rate, and user satisfaction.  \n",
       "2) Instrument logs and retrieval provenance with the schema above.  \n",
       "3) Deploy a RAG prototype on curated documents and measure retrieval precision and factuality before scaling.  \n",
       "4) Build CI tests (unit, adversarial, scenario) and gate model/retriever changes behind these suites.  \n",
       "5) Establish governance: versioned model artifacts, data lineage, privacy classification, and a roll‑back policy linked to observability alerts.\n",
       "\n",
       "Net of the evidence\n",
       "Empirical work shows RAG and grounding materially reduce hallucination risk when retrieval quality and KB coverage are sufficient (Lewis et al., 2020; systematic RAG surveys). However, operational success at scale — reflected in mixed industry outcomes (widespread deployments but nontrivial abandonment rates) — depends on embedding these technical mitigations into disciplined CI, observability, and governance practices. Those practices, in turn, shape TCO and procurement choices: more engineering investment up front tends to lower abandonment and regulatory cost later. With these failure modes, mitigations, and observability practices in hand, we can now evaluate how architecture and cost choices (hosting, API vs private models, storage and retrieval costs, and staffing/training) reconcile pilot value with compliance and long‑term TCO.\n",
       "\n",
       "## Organizational, Privacy, and Operational Considerations: Governance, Costs, and Adoption\n",
       "\n",
       "With compliance and operational patterns established, organizations must align governance, procurement, and human factors to translate pilot gains into sustainable, scalable deployments. Enterprise LLM adoption is governed as much by organizational choices as by model performance. Regulations (GDPR in Europe; HIPAA in the U.S.) and sector rules mandate data‑minimization, access controls, encryption, and documented processing agreements—pushing many regulated deployments toward private/VPC or hybrid architectures rather than open SaaS APIs (Source: https://gdpr.eu/, https://www.hhs.gov/hipaa/). Procurement should therefore treat deployment model as a primary risk/velocity tradeoff: SaaS offers fastest time‑to‑value, VPC/hybrid delivers provenance and control at higher onboarding cost.\n",
       "\n",
       "TCO drivers are predictable but often underestimated: continuous inference (per‑token costs and latency SLAs), storage and indexing of corpora and embeddings, data‑pipeline ETL and observability, model retraining/fine‑tuning, and specialized talent for MLOps and compliance. Typical program budgets range from small pilots (~$20k–$60k) to enterprise programs ($400k–$1M+); governance and recurring operational costs are the common source of “runaway” spend without disciplined chargeback, tagging, and model‑choice policies (Source: https://quokka-labs.com/). Practical cost controls include model distillation or cheaper family models for high‑volume paths, caching/batching of inference, strict input filtering, and quotas.\n",
       "\n",
       "Governance must combine contractual safeguards (data processing addenda, right‑to‑audit, liability limits, SLAs for data retention) with technical controls: encryption in transit/at rest, role‑based access, provenance logs, and data‑minimization or synthetic data for nonessential PII (Source: https://assemblyai.com/blog). Operationally, staged rollouts limit blast radius: start with bounded pilots tied to measurable KPIs (A/B tests on turnaround time, AHT, NPS), progress to canary releases with observability for hallucination rates and drift, and enforce continuous QA (unit tests, adversarial prompts, automated Evals) and SLOs (Source: https://openai.com/evals, https://wandb.ai/, https://mlflow.org/).\n",
       "\n",
       "Human factors determine adoption: clear UX affordances, transparency about model confidence, human‑in‑the‑loop escalation, domain‑specific training, and cross‑functional change management matter as much as accuracy—70%‑level failure rates in change programs are a known risk when adoption is neglected (Source: https://hbr.org/1995/05/leading-change-why-transformation-efforts-fail). Combining measurable pilots, contractual privacy guarantees, disciplined cost controls, and continuous multidimensional evaluation is the pragmatic path from prototype to production. The following section drills into concrete architecture and engineering patterns—model‑selection, RAG and vector stores, latency/throughput tradeoffs, and observability primitives—that implement these governance and cost principles.\n",
       "\n",
       "## Analysis and Discussion: Tradeoffs, Contradictions, and Strategic Recommendations\n",
       "\n",
       "The prior section detailed concrete architecture and engineering patterns that operationalize governance, cost, and reliability principles. The discussion below synthesizes those patterns with business, technical, and organizational realities to surface tradeoffs and actionable guidance. Enterprises face three principal, interlocking tradeoffs when deploying LLMs: speed‑to‑value vs. compliance/control, vendor ROI vs. evaluability, and short‑term cost savings vs. runaway TCO. Cloud/SaaS APIs and turnkey models accelerate pilots and produce the rapid A/B test wins described in vendor case studies (e.g., productivity and processing-time gains reported by AssemblyAI), but they can conflict with GDPR/HIPAA, provenance, and contractual requirements that push investments toward private/VPC or hybrid deployments (Source: https://www.assemblyai.com; https://www.tonic.ai). Vendor ROI claims are common and often compelling, yet benchmarking methods differ widely—creating an evaluability gap that undermines procurement rigor and repeatability (Source: Quokka Labs, https://www.quokkalabs.com). Finally, reported operational gains can be offset by recurring inference, storage, data‑pipelines, governance, and talent costs, producing “runaway” TCO absent disciplined cost controls (Source: https://www.quokkalabs.com).\n",
       "\n",
       "Where practices succeed: pragmatic pilots, canarying, and human‑in‑the‑loop designs effectively limit exposure while proving value; RAG, domain fine‑tuning, and structured QA mitigate hallucinations and brittleness; and tools like OpenAI Evals and ML observability platforms begin to operationalize continuous validation (Source: https://openai.com/evals; https://wandb.ai). Where gaps remain: multidimensional, domain‑specific safety metrics (especially for multi‑step agents), robust operational observability for hallucination/drift, and standardized ROI/evaluation protocols are underdeveloped (Source: V7 Labs; Innodata; Glean — https://www.v7labs.com; https://www.innodata.com; https://www.glean.com).\n",
       "\n",
       "Strategic recommendations\n",
       "- Institutionalize evaluation: require pre‑registered KPIs, standardized A/B designs, and reproducible benchmarks for vendor claims (procurement playbook; see Quokka Labs) (Source: https://www.quokkalabs.com).\n",
       "- Treat TCO as continuous governance: implement cost dashboards, per‑feature chargebacks, and canarying to spot hidden recurring costs early (Source: https://www.wandb.ai).\n",
       "- Build privacy‑first architectures: prefer private/VPC or hybrid stacks for regulated data; enforce encryption, access controls, and data minimization (Source: https://www.tonic.ai; https://lassosecurity.com).\n",
       "- Close evaluation gaps: invest in observability for hallucination scoring, domain‑specific safety metrics, and continuous validation pipelines (OpenAI Evals + custom domain suites) (Source: https://openai.com/evals; https://www.v7labs.com).\n",
       "- Prioritize change management: invest in UX, transparency, training, and human‑in‑loop controls to address the high adoption‑failure risk for organizational change (Source: https://www.startus-insights.com). The next section translates these governance and strategic recommendations into concrete engineering patterns—model selection, RAG and vector stores, latency/throughput tradeoffs, and observability primitives—that teams can implement.\n",
       "\n",
       "## Conclusion and Future Directions: Summary, Practical Next Steps, and Research Needs\n",
       "\n",
       "Having synthesized governance and strategic tradeoffs, we can now compress the report’s practical conclusions and immediate actions into a concise operating playbook. Bottom line: LLMs deliver measurable value in targeted enterprise workflows—faster content creation, accelerated document processing, and improved customer-handling metrics—when applied to well-scoped tasks and instrumented with rigorous controls (Source: https://www.assemblyai.com/blog; https://www.startus-insights.com). Realizing that value at scale, however, is not automatic. Success requires disciplined TCO management, privacy-forward architecture, multidimensional evaluation, and active change management focused on trust and UX (Source: https://gdpr.eu; https://www.hhs.gov/hipaa/index.html).\n",
       "\n",
       "Prioritized next steps for practitioners (in order):\n",
       "1) Pilot design (2–3 months): pick a narrowly scoped, high-impact process (e.g., triage/document summarization), define A/B and before/after KPIs tied to business metrics (turnaround time, AHT, NPS), size budgets (small pilots ~$20k–$60k), and plan staged rollouts with canaries (Source: https://quokka.ai; https://www.startus-insights.com). \n",
       "2) Governance checklist: adopt data-minimization, contractual safeguards, role-based access, encryption-in-transit/at-rest, and an incident/responsibility matrix; prefer hybrid or VPC deployments where regulatory constraints demand provenance (Source: https://tonic.ai; https://lassosecurity.com). \n",
       "3) Evaluation roadmap: implement continuous, multidimensional validation — automated unit tests and adversarial prompts, retrieval-augmented grounding checks, drift/latency observability, and task-completion/clinical-safety metrics rather than only single-turn accuracy (use tools like OpenAI Evals, W&B, MLflow for pipelines) (Source: https://platform.openai.com/docs/guides/evals; https://wandb.ai; https://mlflow.org).\n",
       "\n",
       "Open research and tooling priorities: robust benchmarks and metrics for multi-step agents; standardized, operational hallucination scoring; richer domain-specific safety benchmarks (clinical/legal); cost-modeling tools for long-run TCO; and better observability primitives that link model outputs to business KPIs. Closing these gaps will move LLMs from promising pilots to sustainable, auditable enterprise capabilities (Source: Nature Communications clinical-safety literature; OpenAI Evals ecosystem). The next section converts these program-level recommendations into concrete engineering patterns—model selection, RAG and vector-store design, latency/throughput tradeoffs, and observability primitives—that teams can implement.\n",
       "\n",
       "## References\n",
       "\n",
       "1. https://www.lasso.security/blog/llm-data-privacy\n",
       "2. https://reports.weforum.org/docs/WEF_Advancing_Responsible_AI_Innovation_A_Playbook_2025.pdf\n",
       "3. https://www.missioncloud.com/blog/10-mlops-best-practices-every-team-should-be-using\n",
       "4. https://app.developtoolmn.org/TrainerDirectory.aspx\n",
       "5. https://www.linkedin.com/pulse/why-every-enterprise-needs-end-to-end-private-llm-solution-geethan-zg1te\n",
       "6. https://www.ismsforum.es/ficheros/descargas/en---gobierno-de-la-ia1765878738.pdf\n",
       "7. https://app.developtoolmn.org/v7/\n",
       "8. https://arxiv.org/abs/2509.20324\n",
       "9. https://arxiv.org/list/cs.AI/new\n",
       "10. https://deconvoluteai.com/blog/attack-surfaces-rag\n",
       "11. https://app.developtoolmn.org/v7/authentication/login/callback/silent\n",
       "12. https://dbaman.com/\n",
       "13. https://www.a10networks.com/blog/building-ai-and-llm-inference-in-your-environment-be-aware-of-these-five-challenges/\n",
       "14. https://pmc.ncbi.nlm.nih.gov/articles/PMC12563691/\n",
       "15. https://xenoss.io/blog/total-cost-of-ownership-for-enterprise-ai\n",
       "16. https://keyrus.com/us/en/insights/ai-in-2026-how-to-build-trustworthy-safe-and-governed-ai-systems-noram\n",
       "17. https://www.signitysolutions.com/blog/on-premise-vs-cloud-based-llm\n",
       "18. https://www.startupsoft.com/llm-sensitive-data-best-practices-guide/\n",
       "19. https://intuitionlabs.ai/pdfs/private-llm-inference-for-biotech-a-complete-guide.pdf\n",
       "20. https://www.unifiedaihub.com/blog/on-premise-llms-vs-cloud-apis-when-to-run-your-ai-models-on-premise\n",
       "21. https://www.ideas2it.com/blogs/ai-governance-tools-and-best-practices\n",
       "22. https://www.linkedin.com/pulse/accuracy-reliability-hallucinations-importance-core-elements-sharma-ellxc\n",
       "23. https://medium.com/@adnanmasood/deploying-llms-in-production-lessons-from-the-trenches-a742767be721\n",
       "24. https://aclanthology.org/2025.findings-emnlp.1023/\n",
       "25. https://webtracktechnologies.com/llm-business-benefits-2026/\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t9poimyaxh8",
   "metadata": {},
   "source": [
    "## 12. Evaluation Harness Integration\n",
    "\n",
    "Once the manual test passes, run full evaluation on all 20 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pxf3um3t2r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation harness\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from evaluation import (\n",
    "    ExperimentHarness,\n",
    "    fact_recall,\n",
    "    citation_precision,\n",
    "    coherence_judge,\n",
    "    depth_judge,\n",
    "    relevance_judge,\n",
    "    minimum_sources_check\n",
    ")\n",
    "\n",
    "harness = ExperimentHarness(\n",
    "    dataset_path=\"../data/deep_research_agent_test_dataset.yaml\",\n",
    "    langsmith_dataset_name=\"deep-research-golden-v2\"\n",
    ")\n",
    "\n",
    "print(\"Evaluation harness initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45h611vhxet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Evaluation - UNCOMMENT TO RUN\n",
    "# WARNING: This is expensive and takes 2-3 hours\n",
    "\n",
    "# evaluators = [\n",
    "#     fact_recall,\n",
    "#     citation_precision,\n",
    "#     minimum_sources_check,\n",
    "#     coherence_judge,\n",
    "#     depth_judge,\n",
    "#     relevance_judge,\n",
    "# ]\n",
    "# \n",
    "# print(\"Starting FULL evaluation on all 20 questions...\")\n",
    "# print(\"Combined Tier 1 Agent - estimated 2-3 hours\")\n",
    "# print(\"=\" * 80 + \"\\n\")\n",
    "# \n",
    "# results = harness.run_evaluation(\n",
    "#     agent_fn=combined_tier1_agent,\n",
    "#     evaluators=evaluators,\n",
    "#     experiment_name=\"combined_tier1_v1\",\n",
    "#     monte_carlo_runs=1,\n",
    "#     max_concurrency=2,\n",
    "#     description=\"Combined Tier 1 paradigms evaluation\"\n",
    "# )\n",
    "# \n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"FULL EVALUATION RESULTS\")\n",
    "# print(\"=\" * 80)\n",
    "# print(f\"Experiment: {results.experiment_name}\")\n",
    "# print(f\"Questions: {results.num_questions}\")\n",
    "# \n",
    "# print(f\"\\n{'Metric':<30} {'Mean':<10}\")\n",
    "# print(\"-\" * 40)\n",
    "# for metric in sorted(results.metrics.keys()):\n",
    "#     if not metric.endswith('_std'):\n",
    "#         print(f\"{metric:<30} {results.metrics[metric]:<10.3f}\")\n",
    "\n",
    "print(\"Full evaluation cell ready. Uncomment to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uw84e6cx0y",
   "metadata": {},
   "source": [
    "## Architecture Summary\n",
    "\n",
    "### Combined Paradigms\n",
    "\n",
    "This notebook unifies four Tier 1 paradigms:\n",
    "\n",
    "1. **Cascading Knowledge Cache** - Wraps ALL search operations\n",
    "   - Layer 1: Exact query match\n",
    "   - Layer 2: Semantic similarity\n",
    "   - Expected 30-50% cache hits by verification phase\n",
    "\n",
    "2. **Agile Sprints** - Research phase (Phase 1)\n",
    "   - Decompose question into backlog\n",
    "   - Sprint-based execution with retrospectives\n",
    "   - Dynamic re-prioritization\n",
    "\n",
    "3. **Iterative Refinement V2** - Document generation (Phases 2-4)\n",
    "   - Skeleton-based structure\n",
    "   - Per-node prose generation\n",
    "   - Patch-based refinement (not full regeneration)\n",
    "\n",
    "4. **Quality Gates** - Strategic checkpoints\n",
    "   - Gate 1: Source sufficiency after research\n",
    "   - Gate 2: Quality threshold for refinement exit\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "| Phase | Expected Cache Hits |\n",
    "|-------|---------------------|\n",
    "| Research Sprint 1 | 0% (cold cache) |\n",
    "| Research Sprint 2-3 | 10-25% |\n",
    "| Verification Sprint 1 | 30-40% |\n",
    "| Verification Sprint 2 | 40-60% |\n",
    "\n",
    "### Key Metrics to Track\n",
    "\n",
    "- Cache hit rate > 30%\n",
    "- Quality score >= 7.5\n",
    "- Report coherence and depth\n",
    "- Citation presence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
