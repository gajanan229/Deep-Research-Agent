{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906f87ff",
   "metadata": {},
   "source": [
    "# Paradigm 08-1: Combined Tier 1 Research Agent\n",
    "\n",
    "This notebook implements the **Combined Tier 1 Architecture** combining:\n",
    "- **Cascading Knowledge Cache** (global search layer)\n",
    "- **Agile Sprints** (research phase, max 2 sprints)\n",
    "- **Quality Gates** (strategic checkpoints)\n",
    "- **Iterative Refinement V2** (document structure + patch-based refinement)\n",
    "\n",
    "## Architecture Phases\n",
    "\n",
    "1. **Phase 1: RESEARCH** (Agile Sprints + Knowledge Cache)\n",
    "2. **Phase 2: STRUCTURE** (Skeleton + Claim Placeholders)\n",
    "3. **Phase 3: EXPANSION** (Node-by-Node Prose)\n",
    "4. **Phase 4: VERIFICATION** (Quality Gates + Patches)\n",
    "5. **Phase 5: FINALIZATION** (Assembly + Polish)\n",
    "\n",
    "## Technology Stack\n",
    "- **LLM**: gpt-5-mini-2025-08-07\n",
    "- **Web Search**: Tavily API\n",
    "- **Embeddings**: OpenAI text-embedding-3-small\n",
    "- **Tracing**: LangSmith\n",
    "- **Framework**: LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ced875",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "380a10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import asyncio\n",
    "import hashlib\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Annotated, TypedDict, Literal, Optional, Any\n",
    "from urllib.parse import urlparse\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "env_path = Path(\"../.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Configure LangSmith tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"deep_research_new\"\n",
    "\n",
    "print(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7da7a028",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-5-mini-2025-08-07\n",
      "Max research sprints: 2\n",
      "Max verification iterations: 2\n",
      "Quality threshold: 7.5/10\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM, Tavily, and Embeddings\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0, max_retries=10)\n",
    "tavily_client = TavilyClient()\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ===== CONFIGURATION PARAMETERS =====\n",
    "\n",
    "# Research Phase (Agile Sprints)\n",
    "MAX_RESEARCH_SPRINTS = 2  # Reduced based on user observation\n",
    "QUESTIONS_PER_SPRINT = 4\n",
    "SEARCHES_PER_QUESTION = 3\n",
    "MIN_SOURCES_FOR_GATE1 = 15\n",
    "MIN_DOMAINS_FOR_GATE1 = 5\n",
    "\n",
    "# Skeleton (Iterative Refinement)\n",
    "TARGET_WORDS_PER_NODE = 300\n",
    "MIN_SECTIONS = 5\n",
    "MAX_SECTIONS = 8\n",
    "\n",
    "# Knowledge Cache\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.75\n",
    "LOW_CONFIDENCE_THRESHOLD = 0.40\n",
    "SPECIFICITY_ADJUSTMENT_FACTOR = 0.2\n",
    "TOP_K_RETRIEVAL = 5\n",
    "\n",
    "# Verification (Quality Gates)\n",
    "MAX_VERIFICATION_ITERATIONS = 2\n",
    "QUALITY_THRESHOLD = 7.5\n",
    "MIN_EVIDENCE_SCORE = 6.0\n",
    "SKIP_CASCADE_ON_FIRST_ITERATION = True\n",
    "\n",
    "# Token Management\n",
    "MAX_CONTEXT_CHARS = 12000\n",
    "MAX_FINDINGS_CHARS = 10000\n",
    "\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "print(f\"Max research sprints: {MAX_RESEARCH_SPRINTS}\")\n",
    "print(f\"Max verification iterations: {MAX_VERIFICATION_ITERATIONS}\")\n",
    "print(f\"Quality threshold: {QUALITY_THRESHOLD}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb2e7b",
   "metadata": {},
   "source": [
    "## 2. Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3fcf31d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Knowledge Cache Models ===\n",
    "class CachedDocument(BaseModel):\n",
    "    \"\"\"A cached web document.\"\"\"\n",
    "    url: str = Field(description=\"Original URL\")\n",
    "    normalized_url: str = Field(description=\"Normalized URL for lookup\")\n",
    "    content: str = Field(description=\"Full text content\")\n",
    "    content_hash: str = Field(description=\"SHA-256 hash of content\")\n",
    "    title: str = Field(default=\"\", description=\"Page title\")\n",
    "    retrieval_timestamp: str = Field(description=\"When this was retrieved\")\n",
    "    source_query: str = Field(default=\"\", description=\"Query that led to this content\")\n",
    "\n",
    "\n",
    "class CachedChunk(BaseModel):\n",
    "    \"\"\"A chunk of content with embedding.\"\"\"\n",
    "    chunk_id: str = Field(description=\"Unique identifier\")\n",
    "    text: str = Field(description=\"Chunk text content\")\n",
    "    embedding: List[float] = Field(description=\"Vector embedding\")\n",
    "    source_url: str = Field(description=\"Source document URL\")\n",
    "    position: int = Field(description=\"Position within source document\")\n",
    "\n",
    "\n",
    "class QueryCacheEntry(BaseModel):\n",
    "    \"\"\"A cached query and its results.\"\"\"\n",
    "    original_query: str\n",
    "    light_normalized: str\n",
    "    aggressive_normalized: str\n",
    "    timestamp: str\n",
    "    result_urls: List[str]\n",
    "    result_summary: str = \"\"\n",
    "\n",
    "\n",
    "class CacheDecision(BaseModel):\n",
    "    \"\"\"Record of a cache decision for observability.\"\"\"\n",
    "    query: str\n",
    "    layer_reached: Literal[\"L1\", \"L2\", \"L3\"]\n",
    "    decision: Literal[\"HIT\", \"HIGH_CONF\", \"MEDIUM_CONF\", \"LOW_CONF\",\n",
    "                      \"SUFFICIENT\", \"PARTIAL\", \"INSUFFICIENT\"]\n",
    "    confidence_score: float = 0.0\n",
    "    action_taken: Literal[\"USE_CACHE\", \"SEARCH\", \"TARGETED_SEARCH\"]\n",
    "    reasoning: str = \"\"\n",
    "    timestamp: str = \"\"\n",
    "\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of a query's characteristics.\"\"\"\n",
    "    original_query: str\n",
    "    specificity_score: float = Field(description=\"0.0 (general) to 1.0 (very specific)\")\n",
    "    temporal_intent_score: float = Field(description=\"0.0 (no temporal) to 1.0 (time-sensitive)\")\n",
    "    adjusted_high_threshold: float\n",
    "    adjusted_low_threshold: float\n",
    "    extracted_entities: List[str] = Field(default_factory=list)\n",
    "    extracted_dates: List[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "290c435e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Skeleton and Prose Models (from Iterative Refinement) ===\n",
    "class SkeletonNode(BaseModel):\n",
    "    \"\"\"A node in the document skeleton hierarchy.\"\"\"\n",
    "    node_id: str = Field(description=\"Unique identifier like 'sec:intro'\")\n",
    "    title: str = Field(description=\"Section title for the final document\")\n",
    "    intent: str = Field(description=\"1-3 sentence description of what this section should accomplish\")\n",
    "    target_word_count: int = Field(default=300, description=\"Approximate target length\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"Node IDs this section depends on\")\n",
    "    children: List[str] = Field(default_factory=list, description=\"Child node IDs (empty for leaf nodes)\")\n",
    "    is_expanded: bool = Field(default=False, description=\"Whether prose has been generated\")\n",
    "\n",
    "\n",
    "class DocumentSkeleton(BaseModel):\n",
    "    \"\"\"The complete document skeleton structure.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence statement of the document's central purpose\")\n",
    "    root_nodes: List[str] = Field(description=\"Top-level section node IDs in document order\")\n",
    "    nodes: Dict[str, SkeletonNode] = Field(default_factory=dict, description=\"All nodes by ID\")\n",
    "    style_constraints: str = Field(default=\"\", description=\"Global style guidelines\")\n",
    "\n",
    "\n",
    "class SkeletonGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for skeleton generation.\"\"\"\n",
    "    thesis: str = Field(description=\"One-sentence thesis statement\")\n",
    "    sections: List[SkeletonNode] = Field(description=\"All sections in document order\")\n",
    "\n",
    "\n",
    "class ProseEntry(BaseModel):\n",
    "    \"\"\"Content stored for each expanded node.\"\"\"\n",
    "    node_id: str = Field(description=\"The skeleton node this prose belongs to\")\n",
    "    main_content: str = Field(description=\"The substantive prose for this section\")\n",
    "    bridge_in: str = Field(default=\"\", description=\"Transitional sentences connecting from previous section\")\n",
    "    bridge_out: str = Field(default=\"\", description=\"Transitional sentences leading to next section\")\n",
    "    summary: str = Field(default=\"\", description=\"1-2 sentence compression of content\")\n",
    "    revision_count: int = Field(default=0, description=\"How many times this node has been revised\")\n",
    "\n",
    "\n",
    "class ProseGenerationOutput(BaseModel):\n",
    "    \"\"\"Output schema for prose generation.\"\"\"\n",
    "    bridge_in: str = Field(description=\"1-2 transitional sentences\")\n",
    "    main_content: str = Field(description=\"The main prose content for this section\")\n",
    "    bridge_out: str = Field(description=\"1-2 transitional sentences leading to next section\")\n",
    "    summary: str = Field(description=\"1-2 sentence summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79ad60c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Claims Models ===\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"A verifiable assertion in the document.\"\"\"\n",
    "    claim_id: str = Field(description=\"Unique identifier for this claim\")\n",
    "    claim_text: str = Field(description=\"The assertion itself, stated precisely\")\n",
    "    source_node: str = Field(description=\"Skeleton node ID where this claim appears\")\n",
    "    verification_status: Literal[\"placeholder\", \"unverified\", \"verified\", \"contested\", \"retracted\"] = Field(\n",
    "        default=\"unverified\", description=\"Current verification state\"\n",
    "    )\n",
    "    supporting_evidence: List[str] = Field(default_factory=list, description=\"Sources supporting this claim\")\n",
    "    claim_dependencies: List[str] = Field(default_factory=list, description=\"Other claim IDs this depends on\")\n",
    "\n",
    "\n",
    "class ClaimExtractionOutput(BaseModel):\n",
    "    \"\"\"Output schema for claim extraction.\"\"\"\n",
    "    claims: List[Claim] = Field(description=\"All factual claims extracted from the prose\")\n",
    "\n",
    "\n",
    "class ClaimPlaceholderOutput(BaseModel):\n",
    "    \"\"\"Output schema for identifying claim placeholders from skeleton.\"\"\"\n",
    "    claims: List[Claim] = Field(description=\"Placeholder claims to research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f3c7415c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Critique Models ===\n",
    "class CritiqueIssue(BaseModel):\n",
    "    \"\"\"An issue identified during critique.\"\"\"\n",
    "    issue_id: str = Field(description=\"Unique identifier\")\n",
    "    scope: Literal[\"global\", \"section\", \"transition\"] = Field(description=\"Level of the issue\")\n",
    "    target_nodes: List[str] = Field(description=\"Affected skeleton node IDs\")\n",
    "    issue_type: Literal[\"weak_claim\", \"missing_evidence\", \"logical_gap\", \"unclear\", \"coherence\", \"depth\", \"transition\"] = Field(\n",
    "        description=\"Category of issue\"\n",
    "    )\n",
    "    severity: Literal[\"critical\", \"major\", \"minor\"] = Field(description=\"How serious the issue is\")\n",
    "    affected_claims: List[str] = Field(default_factory=list, description=\"Claim IDs affected\")\n",
    "    description: str = Field(description=\"What the problem is\")\n",
    "    suggestion: str = Field(description=\"How to fix it\")\n",
    "    search_query: str = Field(default=\"\", description=\"Specific query to find evidence\")\n",
    "\n",
    "\n",
    "class CritiqueResult(BaseModel):\n",
    "    \"\"\"Complete critique output.\"\"\"\n",
    "    overall_quality: float = Field(description=\"Quality score 1-10\")\n",
    "    issues: List[CritiqueIssue] = Field(default_factory=list, description=\"All identified issues\")\n",
    "    strengths: str = Field(default=\"\", description=\"What the document does well\")\n",
    "    summary: str = Field(description=\"Overall assessment\")\n",
    "\n",
    "\n",
    "class QualityScores(BaseModel):\n",
    "    \"\"\"Multi-dimensional quality scores for Gate 2 (from V1).\"\"\"\n",
    "    question_coverage: float = Field(description=\"1-10: Does it address ALL parts of the question?\")\n",
    "    evidence_quality: float = Field(description=\"1-10: Are major claims supported by cited sources?\")\n",
    "    coherence: float = Field(description=\"1-10: Is the argument logical and well-structured?\")\n",
    "    depth: float = Field(description=\"1-10: Does it go beyond surface-level information?\")\n",
    "    overall: float = Field(description=\"Average of all scores\")\n",
    "    passed: bool = Field(description=\"True if overall >= 7.5 AND evidence_quality >= 6\")\n",
    "    weak_claims: List[str] = Field(default_factory=list, description=\"Claims needing more support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48267578",
   "metadata": {},
   "source": [
    "## 3. Knowledge Base Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdfe5bd9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base initialized\n"
     ]
    }
   ],
   "source": [
    "class KnowledgeBase:\n",
    "    \"\"\"Session-scoped knowledge base with cascading cache capabilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url_registry: Dict[str, CachedDocument] = {}\n",
    "        self.query_cache: Dict[str, QueryCacheEntry] = {}\n",
    "        self.chunks: List[CachedChunk] = []\n",
    "        self.chunk_embeddings: Optional[np.ndarray] = None\n",
    "\n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            \"total_queries\": 0,\n",
    "            \"l1_hits\": 0,\n",
    "            \"l2_high\": 0,\n",
    "            \"l2_medium\": 0,\n",
    "            \"l2_low\": 0,\n",
    "            \"l3_sufficient\": 0,\n",
    "            \"l3_partial\": 0,\n",
    "            \"l3_insufficient\": 0,\n",
    "            \"web_searches_executed\": 0,\n",
    "            \"web_searches_avoided\": 0\n",
    "        }\n",
    "\n",
    "    def normalize_url(self, url: str) -> str:\n",
    "        \"\"\"Normalize URL for consistent lookup.\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            host = parsed.netloc.lower()\n",
    "            if host.startswith(\"www.\"):\n",
    "                host = host[4:]\n",
    "            path = parsed.path.rstrip(\"/\")\n",
    "            query_params = sorted(parsed.query.split(\"&\")) if parsed.query else []\n",
    "            tracking_params = {\"utm_source\", \"utm_medium\", \"utm_campaign\", \"ref\", \"fbclid\"}\n",
    "            query_params = [p for p in query_params if p.split(\"=\")[0] not in tracking_params]\n",
    "            query = \"&\".join(query_params)\n",
    "            normalized = f\"https://{host}{path}\"\n",
    "            if query:\n",
    "                normalized += f\"?{query}\"\n",
    "            return normalized\n",
    "        except:\n",
    "            return url.lower()\n",
    "\n",
    "    def normalize_query_light(self, query: str) -> str:\n",
    "        \"\"\"Light normalization: lowercase, collapse whitespace.\"\"\"\n",
    "        return \" \".join(query.lower().split())\n",
    "\n",
    "    def normalize_query_aggressive(self, query: str) -> str:\n",
    "        \"\"\"Aggressive normalization: remove stop words, sort terms.\"\"\"\n",
    "        stop_words = {\"the\", \"a\", \"an\", \"is\", \"are\", \"of\", \"in\", \"to\", \"for\", \"and\", \"or\", \"what\", \"how\", \"why\", \"when\", \"where\"}\n",
    "        light = self.normalize_query_light(query)\n",
    "        terms = [t for t in light.split() if t not in stop_words and len(t) > 1]\n",
    "        return \" \".join(sorted(terms))\n",
    "\n",
    "    def compute_content_hash(self, content: str) -> str:\n",
    "        \"\"\"Compute SHA-256 hash of content.\"\"\"\n",
    "        return hashlib.sha256(content.encode()).hexdigest()\n",
    "\n",
    "    def add_document(self, url: str, content: str, title: str = \"\", source_query: str = \"\"):\n",
    "        \"\"\"Add a document to the knowledge base.\"\"\"\n",
    "        normalized_url = self.normalize_url(url)\n",
    "        doc = CachedDocument(\n",
    "            url=url,\n",
    "            normalized_url=normalized_url,\n",
    "            content=content,\n",
    "            content_hash=self.compute_content_hash(content),\n",
    "            title=title,\n",
    "            retrieval_timestamp=datetime.now().isoformat(),\n",
    "            source_query=source_query\n",
    "        )\n",
    "        self.url_registry[normalized_url] = doc\n",
    "        self._chunk_and_embed(doc)\n",
    "        return doc\n",
    "\n",
    "    def _chunk_and_embed(self, doc: CachedDocument):\n",
    "        \"\"\"Chunk document and compute embeddings.\"\"\"\n",
    "        content = doc.content\n",
    "        chunks_text = []\n",
    "        for i in range(0, len(content), CHUNK_SIZE - CHUNK_OVERLAP):\n",
    "            chunk_text = content[i:i + CHUNK_SIZE]\n",
    "            if len(chunk_text) > 50:\n",
    "                chunks_text.append(chunk_text)\n",
    "        if not chunks_text:\n",
    "            return\n",
    "        embeddings = embeddings_model.embed_documents(chunks_text)\n",
    "        for i, (text, embedding) in enumerate(zip(chunks_text, embeddings)):\n",
    "            chunk = CachedChunk(\n",
    "                chunk_id=f\"{doc.content_hash[:8]}_{i}\",\n",
    "                text=text,\n",
    "                embedding=embedding,\n",
    "                source_url=doc.url,\n",
    "                position=i\n",
    "            )\n",
    "            self.chunks.append(chunk)\n",
    "        self._update_embedding_matrix()\n",
    "\n",
    "    def _update_embedding_matrix(self):\n",
    "        \"\"\"Update the numpy matrix of embeddings for fast search.\"\"\"\n",
    "        if self.chunks:\n",
    "            self.chunk_embeddings = np.array([c.embedding for c in self.chunks])\n",
    "\n",
    "    def add_query(self, query: str, result_urls: List[str], result_summary: str = \"\"):\n",
    "        \"\"\"Add a query to the cache.\"\"\"\n",
    "        # Handle None values defensively\n",
    "        result_summary = result_summary or \"\"\n",
    "        entry = QueryCacheEntry(\n",
    "            original_query=query,\n",
    "            light_normalized=self.normalize_query_light(query),\n",
    "            aggressive_normalized=self.normalize_query_aggressive(query),\n",
    "            timestamp=datetime.now().isoformat(),\n",
    "            result_urls=result_urls,\n",
    "            result_summary=result_summary\n",
    "        )\n",
    "        self.query_cache[entry.light_normalized] = entry\n",
    "        self.query_cache[entry.aggressive_normalized] = entry\n",
    "        return entry\n",
    "\n",
    "    def lookup_query_exact(self, query: str) -> Optional[QueryCacheEntry]:\n",
    "        \"\"\"Check for exact query match.\"\"\"\n",
    "        light = self.normalize_query_light(query)\n",
    "        return self.query_cache.get(light)\n",
    "\n",
    "    def lookup_query_aggressive(self, query: str) -> Optional[QueryCacheEntry]:\n",
    "        \"\"\"Check for bag-of-words query match.\"\"\"\n",
    "        aggressive = self.normalize_query_aggressive(query)\n",
    "        return self.query_cache.get(aggressive)\n",
    "\n",
    "    def semantic_search(self, query: str, top_k: int = TOP_K_RETRIEVAL) -> List[Tuple[CachedChunk, float]]:\n",
    "        \"\"\"Find semantically similar chunks.\"\"\"\n",
    "        if not self.chunks or self.chunk_embeddings is None:\n",
    "            return []\n",
    "        query_embedding = np.array(embeddings_model.embed_query(query))\n",
    "        similarities = np.dot(self.chunk_embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.chunk_embeddings, axis=1) * np.linalg.norm(query_embedding) + 1e-8\n",
    "        )\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append((self.chunks[idx], float(similarities[idx])))\n",
    "        return results\n",
    "\n",
    "    def get_stats_summary(self) -> str:\n",
    "        \"\"\"Get human-readable stats summary.\"\"\"\n",
    "        total = self.stats[\"total_queries\"]\n",
    "        if total == 0:\n",
    "            return \"No queries processed yet.\"\n",
    "        avoided = self.stats[\"web_searches_avoided\"]\n",
    "        executed = self.stats[\"web_searches_executed\"]\n",
    "        hit_rate = avoided / total * 100 if total > 0 else 0\n",
    "        return f\"\"\"\n",
    "Cache Statistics:\n",
    "- Total queries: {total}\n",
    "- Web searches avoided: {avoided} ({hit_rate:.1f}% hit rate)\n",
    "- Web searches executed: {executed}\n",
    "- Documents cached: {len(self.url_registry)}\n",
    "- Chunks indexed: {len(self.chunks)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Initialize global knowledge base (session-scoped)\n",
    "knowledge_base = KnowledgeBase()\n",
    "print(\"Knowledge base initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef38af",
   "metadata": {},
   "source": [
    "## 4. Combined State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78ac0a96",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CombinedTier1State(TypedDict):\n",
    "    \"\"\"State for the Combined Tier 1 Research Agent.\"\"\"\n",
    "    # Input\n",
    "    question: str\n",
    "\n",
    "    # ===== PHASE 1: Research Sprints =====\n",
    "    research_backlog: List[str]  # REPLACED each sprint\n",
    "    current_research_sprint: int\n",
    "    max_research_sprints: int\n",
    "    sprint_findings: Annotated[List[str], operator.add]  # ACCUMULATED\n",
    "    research_source_urls: Annotated[List[str], operator.add]\n",
    "    research_retrospective_notes: Annotated[List[str], operator.add]\n",
    "    research_brief: str  # Compressed findings\n",
    "    gate1_passed: bool\n",
    "    gate1_attempts: int\n",
    "\n",
    "    # ===== PHASE 2: Skeleton + Claims =====\n",
    "    skeleton: Dict[str, Any]  # DocumentSkeleton as dict\n",
    "    skeleton_validated: bool\n",
    "    claims_registry: Dict[str, Dict[str, Any]]  # claim_id -> Claim\n",
    "\n",
    "    # ===== PHASE 3: Node Expansion =====\n",
    "    prose_store: Dict[str, Dict[str, Any]]  # node_id -> ProseEntry\n",
    "    nodes_expanded: List[str]\n",
    "    assembled_draft: str\n",
    "\n",
    "    # ===== PHASE 4: Verification =====\n",
    "    noise_map: List[Dict[str, Any]]  # CritiqueIssue list\n",
    "    nodes_to_patch: List[str]\n",
    "    targeted_evidence: Dict[str, List[str]]  # node_id -> evidence\n",
    "    current_verification_iteration: int\n",
    "    max_verification_iterations: int\n",
    "    quality_scores: Annotated[List[Dict[str, float]], operator.add]\n",
    "    gate2_passed: bool\n",
    "    limitations_noted: List[str]\n",
    "\n",
    "    # ===== PHASE 5: Output =====\n",
    "    final_report: str\n",
    "\n",
    "    # ===== METRICS =====\n",
    "    total_searches: int\n",
    "    cache_hits: int\n",
    "    cache_decisions: Annotated[List[Dict], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca03e3f",
   "metadata": {},
   "source": [
    "## 5. Query Analysis and Cache Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4e78d94",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_specificity(query: str) -> float:\n",
    "    \"\"\"Compute query specificity score (0.0 to 1.0).\"\"\"\n",
    "    score = 0.0\n",
    "    if re.search(r'\\b\\d{4}\\b', query):\n",
    "        score += 0.2\n",
    "    if re.search(r'\\d+%|\\$\\d+|\\d+\\s*(billion|million|thousand)', query, re.IGNORECASE):\n",
    "        score += 0.2\n",
    "    if re.search(r'Q[1-4]\\s*\\d{4}|FY\\d{4}', query, re.IGNORECASE):\n",
    "        score += 0.2\n",
    "    proper_nouns = re.findall(r'(?<!^)(?<!\\. )[A-Z][a-z]+', query)\n",
    "    if len(proper_nouns) > 1:\n",
    "        score += 0.15\n",
    "    if '\"' in query or \"'\" in query:\n",
    "        score += 0.15\n",
    "    if re.search(r'\\b(exact|precise|specific|exactly|how many|what is the)\\b', query, re.IGNORECASE):\n",
    "        score += 0.1\n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def compute_temporal_intent(query: str) -> float:\n",
    "    \"\"\"Compute temporal intent score (0.0 to 1.0).\"\"\"\n",
    "    score = 0.0\n",
    "    if re.search(r'\\b(current|latest|now|today|recent|present|this week|this month|this year)\\b', query, re.IGNORECASE):\n",
    "        score += 0.4\n",
    "    if re.search(r'\\b(who is the|what is the current|is .+ still)\\b', query, re.IGNORECASE):\n",
    "        score += 0.3\n",
    "    if re.search(r'\\b(how has .+ changed|compared to|versus last)\\b', query, re.IGNORECASE):\n",
    "        score += 0.2\n",
    "    if re.search(r'\\b(stock price|election|weather|score|breaking)\\b', query, re.IGNORECASE):\n",
    "        score += 0.3\n",
    "    return min(score, 1.0)\n",
    "\n",
    "\n",
    "def analyze_query(query: str) -> QueryAnalysis:\n",
    "    \"\"\"Perform full query analysis.\"\"\"\n",
    "    specificity = compute_specificity(query)\n",
    "    temporal_intent = compute_temporal_intent(query)\n",
    "    high_adjustment = specificity * SPECIFICITY_ADJUSTMENT_FACTOR\n",
    "    adjusted_high = min(HIGH_CONFIDENCE_THRESHOLD + high_adjustment, 0.95)\n",
    "    adjusted_low = LOW_CONFIDENCE_THRESHOLD\n",
    "    entities = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b', query)\n",
    "    dates = re.findall(r'\\b\\d{4}\\b|\\bQ[1-4]\\s*\\d{4}\\b', query, re.IGNORECASE)\n",
    "    return QueryAnalysis(\n",
    "        original_query=query,\n",
    "        specificity_score=specificity,\n",
    "        temporal_intent_score=temporal_intent,\n",
    "        adjusted_high_threshold=adjusted_high,\n",
    "        adjusted_low_threshold=adjusted_low,\n",
    "        extracted_entities=entities[:10],\n",
    "        extracted_dates=dates[:5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d3d39cc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_layer1(query: str, kb: KnowledgeBase) -> Tuple[Literal[\"HIT\", \"MISS\"], Optional[str], Optional[List[str]]]:\n",
    "    \"\"\"Layer 1: Deterministic deduplication.\"\"\"\n",
    "    exact_match = kb.lookup_query_exact(query)\n",
    "    if exact_match:\n",
    "        return \"HIT\", exact_match.result_summary, exact_match.result_urls\n",
    "    aggressive_match = kb.lookup_query_aggressive(query)\n",
    "    if aggressive_match:\n",
    "        return \"HIT\", aggressive_match.result_summary, aggressive_match.result_urls\n",
    "    return \"MISS\", None, None\n",
    "\n",
    "\n",
    "def compute_confidence(\n",
    "    top_results: List[Tuple[CachedChunk, float]],\n",
    "    query: str,\n",
    "    analysis: QueryAnalysis\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"Compute multi-signal confidence score.\"\"\"\n",
    "    if not top_results:\n",
    "        return 0.0, {}\n",
    "    top_score = top_results[0][1]\n",
    "    score_gap = top_results[0][1] - top_results[1][1] if len(top_results) > 1 else top_score\n",
    "    query_terms = set(query.lower().split())\n",
    "    top_chunk_terms = set(top_results[0][0].text.lower().split())\n",
    "    term_overlap = len(query_terms & top_chunk_terms) / len(query_terms | top_chunk_terms) if query_terms | top_chunk_terms else 0\n",
    "    weights = {\"top_score\": 0.5, \"score_gap\": 0.25, \"term_overlap\": 0.25}\n",
    "    raw_confidence = (\n",
    "        weights[\"top_score\"] * top_score +\n",
    "        weights[\"score_gap\"] * min(score_gap * 2, 1.0) +\n",
    "        weights[\"term_overlap\"] * term_overlap\n",
    "    )\n",
    "    confidence = max(0.0, min(raw_confidence, 1.0))\n",
    "    signals = {\n",
    "        \"top_score\": top_score,\n",
    "        \"score_gap\": score_gap,\n",
    "        \"term_overlap\": term_overlap,\n",
    "        \"final_confidence\": confidence\n",
    "    }\n",
    "    return confidence, signals\n",
    "\n",
    "\n",
    "def check_layer2(\n",
    "    query: str,\n",
    "    kb: KnowledgeBase,\n",
    "    analysis: QueryAnalysis\n",
    ") -> Tuple[Literal[\"HIGH\", \"MEDIUM\", \"LOW\"], float, List[Tuple[CachedChunk, float]], Dict]:\n",
    "    \"\"\"Layer 2: Semantic retrieval with confidence scoring.\"\"\"\n",
    "    results = kb.semantic_search(query, top_k=TOP_K_RETRIEVAL)\n",
    "    if not results:\n",
    "        return \"LOW\", 0.0, [], {}\n",
    "    confidence, signals = compute_confidence(results, query, analysis)\n",
    "    if confidence >= analysis.adjusted_high_threshold:\n",
    "        decision = \"HIGH\"\n",
    "    elif confidence >= analysis.adjusted_low_threshold:\n",
    "        decision = \"MEDIUM\"\n",
    "    else:\n",
    "        decision = \"LOW\"\n",
    "    return decision, confidence, results, signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69068ed7",
   "metadata": {},
   "source": [
    "## 6. Layer 3 and Cascaded Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a974566",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "LAYER3_JUDGMENT_PROMPT = \"\"\"You are evaluating whether cached content answers a research query.\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "CACHED CONTENT (top {num_chunks} relevant chunks):\n",
    "{chunks_text}\n",
    "\n",
    "Analyze on these dimensions:\n",
    "1. TOPICAL RELEVANCE: Is the cached content about the same subject?\n",
    "2. SPECIFICITY MATCH: Does it address the specific aspect asked about?\n",
    "3. COMPLETENESS: Does it provide a complete or only partial answer?\n",
    "4. FACTUAL DENSITY: Does it contain concrete facts that answer the query?\n",
    "\n",
    "Provide your assessment in this exact format:\n",
    "VERDICT: [SUFFICIENT|PARTIAL|INSUFFICIENT]\n",
    "RELEVANCE: [0.0-1.0]\n",
    "COMPLETENESS: [0.0-1.0]\n",
    "REASONING: [Your explanation in 2-3 sentences]\n",
    "GAPS: [List specific missing information, or \"None\" if sufficient]\n",
    "\"\"\"\n",
    "\n",
    "GAP_ANALYSIS_PROMPT = \"\"\"Based on your analysis, the cached content only partially answers the query.\n",
    "\n",
    "QUERY: {query}\n",
    "IDENTIFIED GAPS: {gaps}\n",
    "\n",
    "Generate 1-2 highly targeted search queries that would fill these specific gaps.\n",
    "The refined queries should:\n",
    "- Target ONLY the missing information (not repeat what we already have)\n",
    "- Be specific and searchable\n",
    "- Different from the original query\n",
    "\n",
    "Return queries one per line, no numbering or bullets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def check_layer3(\n",
    "    query: str,\n",
    "    chunks: List[Tuple[CachedChunk, float]],\n",
    "    kb: KnowledgeBase\n",
    ") -> Tuple[Literal[\"SUFFICIENT\", \"PARTIAL\", \"INSUFFICIENT\"], List[str], Optional[List[str]]]:\n",
    "    \"\"\"Layer 3: LLM-augmented judgment with gap analysis.\"\"\"\n",
    "    chunks_text = \"\\n\\n---\\n\\n\".join([\n",
    "        f\"[Chunk {i+1}, similarity: {score:.3f}]\\n{chunk.text}\"\n",
    "        for i, (chunk, score) in enumerate(chunks[:5])\n",
    "    ])\n",
    "    prompt = LAYER3_JUDGMENT_PROMPT.format(\n",
    "        query=query,\n",
    "        num_chunks=min(len(chunks), 5),\n",
    "        chunks_text=chunks_text\n",
    "    )\n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    verdict_match = re.search(r'VERDICT:\\s*(SUFFICIENT|PARTIAL|INSUFFICIENT)', content, re.IGNORECASE)\n",
    "    verdict = verdict_match.group(1).upper() if verdict_match else \"INSUFFICIENT\"\n",
    "    gaps = []\n",
    "    gaps_match = re.search(r'GAPS:\\s*(.+?)(?=\\n\\n|$)', content, re.DOTALL | re.IGNORECASE)\n",
    "    if gaps_match:\n",
    "        gaps_text = gaps_match.group(1).strip()\n",
    "        if gaps_text.lower() != \"none\":\n",
    "            gaps = [g.strip() for g in re.split(r'[-â€¢\\n]', gaps_text) if g.strip()]\n",
    "    refined_queries = None\n",
    "    if verdict == \"PARTIAL\" and gaps:\n",
    "        refine_prompt = GAP_ANALYSIS_PROMPT.format(\n",
    "            query=query,\n",
    "            gaps=\"\\n\".join(f\"- {g}\" for g in gaps)\n",
    "        )\n",
    "        refine_response = await llm.ainvoke([HumanMessage(content=refine_prompt)])\n",
    "        refined_queries = [q.strip() for q in refine_response.content.split(\"\\n\") if q.strip()][:2]\n",
    "    return verdict, gaps, refined_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb2ccdff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache layer functions defined\n"
     ]
    }
   ],
   "source": [
    "def search_web(query: str, max_results: int = 8) -> Tuple[str, List[str], List[str]]:\n",
    "    \"\"\"Execute web search using Tavily. Returns (summary, results, urls).\"\"\"\n",
    "    try:\n",
    "        if len(query) > 400:\n",
    "            query = query[:400]\n",
    "        response = tavily_client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            include_answer=True\n",
    "        )\n",
    "        results = []\n",
    "        urls = []\n",
    "        summary = response.get(\"answer\") or \"\"  # Handle None explicitly\n",
    "        for r in response.get(\"results\", []):\n",
    "            url = r.get('url', '')\n",
    "            urls.append(url)\n",
    "            content = r.get('content', '')[:500]\n",
    "            title = r.get('title', 'No title')\n",
    "            results.append(f\"[{title}] {content}... (Source: {url})\")\n",
    "        return summary, results, urls\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\", [], []\n",
    "\n",
    "\n",
    "async def cascaded_search(\n",
    "    query: str,\n",
    "    kb: KnowledgeBase\n",
    ") -> Tuple[str, List[str], CacheDecision]:\n",
    "    \"\"\"Execute the full cascading cache check and search if needed.\"\"\"\n",
    "    kb.stats[\"total_queries\"] += 1\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    analysis = analyze_query(query)\n",
    "    \n",
    "    # Layer 1\n",
    "    l1_decision, l1_summary, l1_urls = check_layer1(query, kb)\n",
    "    if l1_decision == \"HIT\":\n",
    "        kb.stats[\"l1_hits\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L1\", decision=\"HIT\",\n",
    "            confidence_score=1.0, action_taken=\"USE_CACHE\",\n",
    "            reasoning=\"Exact query match found in cache\", timestamp=timestamp\n",
    "        )\n",
    "        return l1_summary, l1_urls, decision\n",
    "    \n",
    "    # Layer 2\n",
    "    l2_decision, confidence, chunks, signals = check_layer2(query, kb, analysis)\n",
    "    \n",
    "    if l2_decision == \"HIGH\":\n",
    "        kb.stats[\"l2_high\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        content = \"\\n\\n\".join([f\"[From: {c.source_url}]\\n{c.text}\" for c, _ in chunks[:3]])\n",
    "        urls = list(set([c.source_url for c, _ in chunks]))\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L2\", decision=\"HIGH_CONF\",\n",
    "            confidence_score=confidence, action_taken=\"USE_CACHE\",\n",
    "            reasoning=f\"High semantic similarity (conf={confidence:.3f})\", timestamp=timestamp\n",
    "        )\n",
    "        return content, urls, decision\n",
    "    \n",
    "    elif l2_decision == \"LOW\":\n",
    "        kb.stats[\"l2_low\"] += 1\n",
    "        summary, results, urls = search_web(query)\n",
    "        kb.stats[\"web_searches_executed\"] += 1\n",
    "        query_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\nResults:\\n\" + \"\\n\\n\".join(results)\n",
    "        synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "        kb.add_document(synthetic_url, query_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "        kb.add_query(query, urls, summary)\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L2\", decision=\"LOW_CONF\",\n",
    "            confidence_score=confidence, action_taken=\"SEARCH\",\n",
    "            reasoning=f\"Low confidence ({confidence:.3f}), executed web search\", timestamp=timestamp\n",
    "        )\n",
    "        return query_content, urls, decision\n",
    "    \n",
    "    # Layer 3 (MEDIUM confidence)\n",
    "    kb.stats[\"l2_medium\"] += 1\n",
    "    verdict, gaps, refined_queries = await check_layer3(query, chunks, kb)\n",
    "    \n",
    "    if verdict == \"SUFFICIENT\":\n",
    "        kb.stats[\"l3_sufficient\"] += 1\n",
    "        kb.stats[\"web_searches_avoided\"] += 1\n",
    "        content = \"\\n\\n\".join([f\"[From: {c.source_url}]\\n{c.text}\" for c, _ in chunks[:3]])\n",
    "        urls = list(set([c.source_url for c, _ in chunks]))\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L3\", decision=\"SUFFICIENT\",\n",
    "            confidence_score=confidence, action_taken=\"USE_CACHE\",\n",
    "            reasoning=\"LLM judged cached content sufficient\", timestamp=timestamp\n",
    "        )\n",
    "        return content, urls, decision\n",
    "    \n",
    "    elif verdict == \"PARTIAL\" and refined_queries:\n",
    "        kb.stats[\"l3_partial\"] += 1\n",
    "        cached_content = \"\\n\\n\".join([f\"[Cached: {c.source_url}]\\n{c.text}\" for c, _ in chunks[:2]])\n",
    "        cached_urls = [c.source_url for c, _ in chunks[:2]]\n",
    "        for refined_query in refined_queries:\n",
    "            summary, results, new_urls = search_web(refined_query, max_results=4)\n",
    "            kb.stats[\"web_searches_executed\"] += 1\n",
    "            gap_content = f\"Query: {refined_query}\\n\\nAnswer: {summary}\\n\\nResults:\\n\" + \"\\n\\n\".join(results)\n",
    "            synthetic_url = f\"search://{kb.compute_content_hash(refined_query)[:16]}\"\n",
    "            kb.add_document(synthetic_url, gap_content, title=f\"Search: {refined_query[:50]}\", source_query=refined_query)\n",
    "            kb.add_query(refined_query, new_urls, summary)\n",
    "            cached_content += f\"\\n\\n[Gap-fill search: {refined_query}]\\n{gap_content}\"\n",
    "            cached_urls.extend(new_urls)\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L3\", decision=\"PARTIAL\",\n",
    "            confidence_score=confidence, action_taken=\"TARGETED_SEARCH\",\n",
    "            reasoning=f\"LLM identified gaps. Executed {len(refined_queries)} targeted searches.\", timestamp=timestamp\n",
    "        )\n",
    "        return cached_content, list(set(cached_urls)), decision\n",
    "    \n",
    "    else:\n",
    "        kb.stats[\"l3_insufficient\"] += 1\n",
    "        summary, results, urls = search_web(query)\n",
    "        kb.stats[\"web_searches_executed\"] += 1\n",
    "        query_content = f\"Query: {query}\\n\\nAnswer: {summary}\\n\\nResults:\\n\" + \"\\n\\n\".join(results)\n",
    "        synthetic_url = f\"search://{kb.compute_content_hash(query)[:16]}\"\n",
    "        kb.add_document(synthetic_url, query_content, title=f\"Search: {query[:50]}\", source_query=query)\n",
    "        kb.add_query(query, urls, summary)\n",
    "        decision = CacheDecision(\n",
    "            query=query, layer_reached=\"L3\", decision=\"INSUFFICIENT\",\n",
    "            confidence_score=confidence, action_taken=\"SEARCH\",\n",
    "            reasoning=\"LLM judged cached content insufficient\", timestamp=timestamp\n",
    "        )\n",
    "        return query_content, urls, decision\n",
    "\n",
    "print(\"Cache layer functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93caa54",
   "metadata": {},
   "source": [
    "## 7. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49b8fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def extract_domain(url: str) -> str:\n",
    "    \"\"\"Extract domain from URL.\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        return parsed.netloc\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "\n",
    "def get_leaf_nodes(skeleton: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Get all leaf node IDs (nodes without children) in document order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "\n",
    "    def collect_leaves(node_ids: List[str]) -> List[str]:\n",
    "        leaves = []\n",
    "        for nid in node_ids:\n",
    "            node = nodes.get(nid, {})\n",
    "            children = node.get(\"children\", [])\n",
    "            if not children:\n",
    "                leaves.append(nid)\n",
    "            else:\n",
    "                leaves.extend(collect_leaves(children))\n",
    "        return leaves\n",
    "    return collect_leaves(root_nodes)\n",
    "\n",
    "\n",
    "def topological_sort_nodes(skeleton: Dict[str, Any], node_ids: List[str]) -> List[str]:\n",
    "    \"\"\"Sort nodes by dependency order.\"\"\"\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    node_id_set = set(node_ids)\n",
    "    remaining = set(node_ids)\n",
    "    sorted_nodes = []\n",
    "    while remaining:\n",
    "        ready = []\n",
    "        for nid in remaining:\n",
    "            node = nodes.get(nid, {})\n",
    "            deps = set(node.get(\"dependencies\", []))\n",
    "            internal_deps = deps & node_id_set\n",
    "            if internal_deps.issubset(set(sorted_nodes)):\n",
    "                ready.append(nid)\n",
    "        if not ready:\n",
    "            for nid in node_ids:\n",
    "                if nid in remaining:\n",
    "                    sorted_nodes.append(nid)\n",
    "            break\n",
    "        ready_ordered = [nid for nid in node_ids if nid in ready]\n",
    "        sorted_nodes.extend(ready_ordered)\n",
    "        remaining -= set(ready_ordered)\n",
    "    return sorted_nodes\n",
    "\n",
    "\n",
    "def get_adjacent_nodes(skeleton: Dict[str, Any], node_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Get the previous and next node IDs in document order.\"\"\"\n",
    "    leaves = get_leaf_nodes(skeleton)\n",
    "    try:\n",
    "        idx = leaves.index(node_id)\n",
    "        prev_node = leaves[idx - 1] if idx > 0 else None\n",
    "        next_node = leaves[idx + 1] if idx < len(leaves) - 1 else None\n",
    "        return prev_node, next_node\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def _validate_skeleton_structure(skeleton: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"Validate skeleton structure.\"\"\"\n",
    "    issues = []\n",
    "    nodes = skeleton.get(\"nodes\", {})\n",
    "    root_nodes = skeleton.get(\"root_nodes\", [])\n",
    "    \n",
    "    for root_id in root_nodes:\n",
    "        if root_id not in nodes:\n",
    "            issues.append(f\"Root node '{root_id}' not found in nodes\")\n",
    "    \n",
    "    # Check dependencies exist and no cycles\n",
    "    visited = set()\n",
    "    rec_stack = set()\n",
    "    \n",
    "    def has_cycle(node_id: str) -> bool:\n",
    "        visited.add(node_id)\n",
    "        rec_stack.add(node_id)\n",
    "        node = nodes.get(node_id, {})\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id not in nodes:\n",
    "                issues.append(f\"Node '{node_id}' depends on non-existent node '{dep_id}'\")\n",
    "                continue\n",
    "            if dep_id not in visited:\n",
    "                if has_cycle(dep_id):\n",
    "                    return True\n",
    "            elif dep_id in rec_stack:\n",
    "                issues.append(f\"Circular dependency detected: {node_id} -> {dep_id}\")\n",
    "                return True\n",
    "        rec_stack.discard(node_id)\n",
    "        return False\n",
    "    \n",
    "    for node_id in nodes:\n",
    "        if node_id not in visited:\n",
    "            has_cycle(node_id)\n",
    "    \n",
    "    # Check reasonable total word count\n",
    "    total_words = sum(n.get(\"target_word_count\", 300) for n in nodes.values())\n",
    "    if total_words < 1000:\n",
    "        issues.append(f\"Total word count too low: {total_words}\")\n",
    "    if total_words > 5000:\n",
    "        issues.append(f\"Total word count too high: {total_words}\")\n",
    "    \n",
    "    return len(issues) == 0, issues\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084c59a",
   "metadata": {},
   "source": [
    "## 8. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eeba014f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts defined\n"
     ]
    }
   ],
   "source": [
    "# === Phase 1: Research Prompts ===\n",
    "DECOMPOSE_QUESTION_PROMPT = \"\"\"You are a research planning expert. Given a research question, \n",
    "decompose it into 4-6 specific sub-questions that need to be investigated.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Generate a prioritized list of specific, focused research questions that together will answer the main question.\n",
    "Each question should be independently searchable and cover a different aspect.\n",
    "\n",
    "Return your response as a numbered list (highest priority first):\n",
    "1. [Most critical sub-question]\n",
    "2. [Second priority sub-question]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "SPRINT_RESEARCH_PROMPT = \"\"\"You are a research agent conducting Sprint {sprint_num} of {max_sprints}.\n",
    "\n",
    "Current research focus: {current_question}\n",
    "\n",
    "Based on the search results below, extract the key findings that address the research question.\n",
    "Be specific and cite sources with URLs where relevant.\n",
    "\n",
    "Search Results:\n",
    "{search_results}\n",
    "\n",
    "Provide a comprehensive summary of findings (400-600 words). Include specific facts, statistics, and source URLs.\n",
    "\"\"\"\n",
    "\n",
    "RETROSPECTIVE_PROMPT = \"\"\"You are conducting a sprint retrospective for a research project.\n",
    "\n",
    "Original Question: {original_question}\n",
    "\n",
    "Sprint {sprint_num} of {max_sprints} has completed.\n",
    "\n",
    "Summary of findings so far:\n",
    "{findings_summary}\n",
    "\n",
    "Current remaining questions in backlog:\n",
    "{remaining_backlog}\n",
    "\n",
    "Analyze the progress and provide a STRUCTURED response:\n",
    "\n",
    "## LEARNINGS\n",
    "What key insights did we gain this sprint?\n",
    "\n",
    "## GAPS\n",
    "What is still unclear or needs more investigation?\n",
    "\n",
    "## CONTINUE\n",
    "Should we continue with another sprint? Answer YES or NO with brief justification.\n",
    "\n",
    "## REPRIORITIZED_BACKLOG\n",
    "Reorder the remaining questions by priority, incorporating any new questions:\n",
    "1. [Highest priority question]\n",
    "2. [Next priority]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "COMPRESS_FINDINGS_PROMPT = \"\"\"Summarize the research findings into a concise brief for document generation.\n",
    "\n",
    "All Findings:\n",
    "{all_findings}\n",
    "\n",
    "Create a structured brief (max 800 words) capturing:\n",
    "- Key facts and statistics discovered\n",
    "- Main themes and evidence\n",
    "- Important sources (include URLs)\n",
    "- Any contradictions or debates\n",
    "\n",
    "Focus on information that will be useful for writing a comprehensive research report.\n",
    "\"\"\"\n",
    "\n",
    "# === Phase 2: Skeleton Prompts ===\n",
    "SKELETON_GENERATION_PROMPT = \"\"\"You are a research document architect. Create a detailed document skeleton for answering this research question.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Research Brief (completed research findings):\n",
    "{research_brief}\n",
    "\n",
    "Create a hierarchical document structure with:\n",
    "1. A clear thesis statement (one sentence capturing the document's central argument)\n",
    "2. 5-7 main sections appropriate for a comprehensive research report\n",
    "3. Each section should have:\n",
    "   - node_id: Unique identifier using format \"sec:topic\" (e.g., \"sec:intro\", \"sec:background\")\n",
    "   - title: Descriptive section title\n",
    "   - intent: 1-3 sentences describing what this section should accomplish\n",
    "   - target_word_count: 250-400 words per section\n",
    "   - dependencies: List of node_ids that this section builds upon\n",
    "   - children: Empty list (flat structure)\n",
    "\n",
    "REQUIRED SECTIONS:\n",
    "1. Introduction - Present the topic, context, and thesis\n",
    "2. Background/Context - Provide necessary foundation knowledge  \n",
    "3. Main Body (2-4 sections) - Cover key aspects in depth\n",
    "4. Analysis/Discussion - Synthesize findings\n",
    "5. Conclusion - Summarize key points\n",
    "\n",
    "IMPORTANT: Map research findings to appropriate sections. Each finding should have a home.\n",
    "\"\"\"\n",
    "\n",
    "CLAIM_PLACEHOLDER_PROMPT = \"\"\"Analyze this document skeleton and identify claims that will need evidence.\n",
    "\n",
    "Document Thesis: {thesis}\n",
    "\n",
    "Skeleton Sections:\n",
    "{skeleton_summary}\n",
    "\n",
    "Research Brief:\n",
    "{research_brief}\n",
    "\n",
    "For each section, identify 2-4 key claims that the section will need to make and verify.\n",
    "These are \"placeholder\" claims - assertions that the document structure implies but haven't been written yet.\n",
    "\n",
    "For each claim:\n",
    "- claim_id: Format \"claim_placeholder_{{section}}_{{number}}\"\n",
    "- claim_text: The anticipated assertion\n",
    "- source_node: The section where this claim belongs\n",
    "- verification_status: \"placeholder\" \n",
    "- supporting_evidence: Empty list (to be filled during research)\n",
    "\n",
    "Focus on substantive factual claims that will require evidence.\n",
    "\"\"\"\n",
    "\n",
    "# === Phase 3: Expansion Prompts ===\n",
    "PROSE_GENERATION_PROMPT = \"\"\"You are a research writer generating content for a specific section.\n",
    "\n",
    "DOCUMENT CONTEXT:\n",
    "Research Question: {question}\n",
    "Document Thesis: {thesis}\n",
    "\n",
    "SECTION TO WRITE:\n",
    "Node ID: {node_id}\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "Target Length: ~{target_words} words\n",
    "\n",
    "DOCUMENT STRUCTURE:\n",
    "{skeleton_summary}\n",
    "\n",
    "PREVIOUS SECTION'S ENDING:\n",
    "{previous_bridge_out}\n",
    "\n",
    "CONTENT FROM DEPENDENCY SECTIONS:\n",
    "{dependency_summaries}\n",
    "\n",
    "RELEVANT RESEARCH FINDINGS:\n",
    "{research_findings}\n",
    "\n",
    "WRITING REQUIREMENTS:\n",
    "1. **bridge_in** (1-2 sentences): Transition from previous section\n",
    "2. **main_content** (~{target_words} words): Substantive prose with citations (Source: URL)\n",
    "3. **bridge_out** (1-2 sentences): Setup the next section\n",
    "4. **summary** (1-2 sentences): What this section establishes\n",
    "\n",
    "Be comprehensive, specific, and well-sourced.\n",
    "\"\"\"\n",
    "\n",
    "CLAIM_EXTRACTION_PROMPT = \"\"\"Extract all factual claims from this research prose.\n",
    "\n",
    "Section Node ID: {node_id}\n",
    "\n",
    "Prose Content:\n",
    "{prose}\n",
    "\n",
    "A claim is any statement that:\n",
    "- Has a truth value (could be verified or refuted)\n",
    "- Contributes to the document's argument\n",
    "\n",
    "For each claim:\n",
    "- claim_id: Format \"claim_{{node_id}}_{{number}}\"\n",
    "- claim_text: The precise assertion\n",
    "- source_node: Use the node_id value provided above\n",
    "- verification_status: \"verified\" if it cites a source, \"unverified\" otherwise\n",
    "- supporting_evidence: List of cited sources\n",
    "\n",
    "Extract 3-8 key claims per section.\n",
    "\"\"\"\n",
    "\n",
    "# === Phase 4: Verification Prompts ===\n",
    "CRITIQUE_PROMPT = \"\"\"You are a critical reviewer evaluating a research document.\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "DOCUMENT THESIS: {thesis}\n",
    "\n",
    "DOCUMENT STRUCTURE:\n",
    "{skeleton_summary}\n",
    "\n",
    "CLAIMS REGISTRY:\n",
    "{claims_summary}\n",
    "\n",
    "FULL DOCUMENT:\n",
    "{document_content}\n",
    "\n",
    "Analyze at THREE levels:\n",
    "\n",
    "## 1. GLOBAL ISSUES\n",
    "- Is the thesis clearly stated and supported?\n",
    "- Does the argument flow logically?\n",
    "\n",
    "## 2. SECTION ISSUES (per node)\n",
    "- weak_claim: Claims lacking evidence\n",
    "- missing_evidence: Key assertions need sources\n",
    "- logical_gap: Reasoning jumps\n",
    "- depth: Insufficient detail\n",
    "\n",
    "## 3. TRANSITION ISSUES\n",
    "- Abrupt topic shifts\n",
    "- Broken references\n",
    "\n",
    "For each issue provide:\n",
    "- issue_id, scope, target_nodes, issue_type, severity\n",
    "- affected_claims, description, suggestion, search_query\n",
    "\n",
    "SCORING (1-10):\n",
    "- 9-10: Publication ready\n",
    "- 7-8: Good, minor issues\n",
    "- 5-6: Needs improvement\n",
    "- 3-4: Significant problems\n",
    "- 1-2: Major rework needed\n",
    "\"\"\"\n",
    "\n",
    "# Gate 2 prompt with V1's multi-dimensional scoring\n",
    "GATE2_CHECK_PROMPT = \"\"\"Evaluate this research report on four dimensions (1-10 each):\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "Report:\n",
    "{document_content}\n",
    "\n",
    "Claims and Evidence:\n",
    "{claims_summary}\n",
    "\n",
    "1. QUESTION_COVERAGE: Does it address ALL parts of the research question?\n",
    "2. EVIDENCE_QUALITY: Are major claims supported by cited sources?\n",
    "3. COHERENCE: Is the argument logical and well-structured?\n",
    "4. DEPTH: Does it go beyond surface-level information?\n",
    "\n",
    "Also identify any claims that still need evidence.\n",
    "\n",
    "Format your response EXACTLY as:\n",
    "QUESTION_COVERAGE: [score]\n",
    "EVIDENCE_QUALITY: [score]\n",
    "COHERENCE: [score]\n",
    "DEPTH: [score]\n",
    "OVERALL: [average]\n",
    "PASS: [YES/NO] (YES if OVERALL >= 7.5 AND EVIDENCE_QUALITY >= 6)\n",
    "WEAK_CLAIMS: [list of claims needing more support, or \"None\"]\n",
    "\"\"\"\n",
    "\n",
    "PATCH_PROMPT = \"\"\"Revise this section based on critique feedback and new evidence.\n",
    "\n",
    "SECTION TO REVISE:\n",
    "Node ID: {node_id}\n",
    "Title: {title}\n",
    "Intent: {intent}\n",
    "\n",
    "CURRENT CONTENT:\n",
    "Bridge In: {current_bridge_in}\n",
    "Main Content: {current_main_content}\n",
    "Bridge Out: {current_bridge_out}\n",
    "\n",
    "ISSUES TO ADDRESS:\n",
    "{issues_for_node}\n",
    "\n",
    "NEW EVIDENCE:\n",
    "{new_evidence}\n",
    "\n",
    "ADJACENT SECTIONS:\n",
    "Previous ends with: {prev_bridge_out}\n",
    "Next starts with: {next_bridge_in}\n",
    "\n",
    "Output complete revised section with:\n",
    "- bridge_in, main_content, bridge_out, summary\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompts defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc587334",
   "metadata": {},
   "source": [
    "## 9. Phase 1 Node Functions (Research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9982f6d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def decompose_question(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Decompose research question into sub-questions.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 1a: Decomposing Research Question\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    prompt = DECOMPOSE_QUESTION_PROMPT.format(question=question)\n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    lines = response.content.strip().split(\"\\n\")\n",
    "    backlog = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "            clean = line.lstrip(\"0123456789.-) \").strip()\n",
    "            if clean:\n",
    "                backlog.append(clean)\n",
    "    \n",
    "    print(f\"  Created backlog with {len(backlog)} research questions\")\n",
    "    \n",
    "    return {\n",
    "        \"research_backlog\": backlog,\n",
    "        \"current_research_sprint\": 1,\n",
    "        \"max_research_sprints\": MAX_RESEARCH_SPRINTS,\n",
    "        \"gate1_attempts\": 0\n",
    "    }\n",
    "\n",
    "\n",
    "async def execute_research_sprint(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Execute a research sprint using Knowledge Cache.\"\"\"\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    \n",
    "    if not backlog:\n",
    "        return {\"sprint_findings\": [\"No questions in backlog.\"]}\n",
    "    \n",
    "    current_question = backlog[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sprint {current_sprint}/{max_sprints}: {current_question[:70]}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Generate search queries\n",
    "    all_results = []\n",
    "    all_urls = []\n",
    "    all_decisions = []\n",
    "    queries = [current_question]\n",
    "    \n",
    "    if SEARCHES_PER_QUESTION > 1:\n",
    "        query_prompt = f\"\"\"Generate {SEARCHES_PER_QUESTION - 1} specific search queries for:\n",
    "Question: {current_question}\n",
    "\n",
    "Return queries one per line.\"\"\"\n",
    "        query_response = await llm.ainvoke([HumanMessage(content=query_prompt)])\n",
    "        additional = [q.strip() for q in query_response.content.split(\"\\n\") if q.strip()]\n",
    "        queries.extend(additional[:SEARCHES_PER_QUESTION - 1])\n",
    "    \n",
    "    # Execute searches through cache\n",
    "    for query in queries:\n",
    "        print(f\"  Searching: {query[:50]}...\")\n",
    "        content, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "        all_results.append(content)\n",
    "        all_urls.extend(urls)\n",
    "        all_decisions.append(decision.model_dump())\n",
    "    \n",
    "    combined_results = \"\\n\\n---\\n\\n\".join(all_results)\n",
    "    \n",
    "    # Synthesize findings\n",
    "    synthesis_prompt = SPRINT_RESEARCH_PROMPT.format(\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        current_question=current_question,\n",
    "        search_results=combined_results[:MAX_FINDINGS_CHARS]\n",
    "    )\n",
    "    synthesis = await llm.ainvoke([HumanMessage(content=synthesis_prompt)])\n",
    "    \n",
    "    finding = f\"## Sprint {current_sprint} Findings: {current_question}\\n\\n{synthesis.content}\"\n",
    "    print(f\"  Synthesized {len(synthesis.content)} characters\")\n",
    "    print(f\"  Collected {len(all_urls)} source URLs\")\n",
    "    \n",
    "    updated_backlog = backlog[1:] if len(backlog) > 1 else []\n",
    "    \n",
    "    return {\n",
    "        \"sprint_findings\": [finding],\n",
    "        \"research_source_urls\": all_urls,\n",
    "        \"research_backlog\": updated_backlog,\n",
    "        \"cache_decisions\": all_decisions\n",
    "    }\n",
    "\n",
    "\n",
    "async def research_retrospective(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Conduct retrospective after sprint.\"\"\"\n",
    "    original_question = state[\"question\"]\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "    remaining_backlog = state.get(\"research_backlog\", [])\n",
    "    \n",
    "    # Summarize if too long\n",
    "    if len(all_findings) > 4000:\n",
    "        summary_prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:8000])\n",
    "        summary_response = await llm.ainvoke([HumanMessage(content=summary_prompt)])\n",
    "        findings_summary = summary_response.content\n",
    "    else:\n",
    "        findings_summary = all_findings\n",
    "    \n",
    "    prompt = RETROSPECTIVE_PROMPT.format(\n",
    "        original_question=original_question,\n",
    "        sprint_num=current_sprint,\n",
    "        max_sprints=max_sprints,\n",
    "        findings_summary=findings_summary,\n",
    "        remaining_backlog=\"\\n\".join(f\"- {q}\" for q in remaining_backlog) if remaining_backlog else \"None\"\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Parse reprioritized backlog\n",
    "    backlog_match = re.search(r'## REPRIORITIZED_BACKLOG\\s*(.*?)(?=##|$)', response.content, re.DOTALL | re.IGNORECASE)\n",
    "    reprioritized = []\n",
    "    if backlog_match:\n",
    "        for line in backlog_match.group(1).strip().split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            if line and (line[0].isdigit() or line.startswith(\"-\")):\n",
    "                clean = re.sub(r'^[\\d\\.\\-\\)\\s]+', '', line).strip()\n",
    "                if clean and len(clean) > 10:\n",
    "                    reprioritized.append(clean)\n",
    "    \n",
    "    if not reprioritized and remaining_backlog:\n",
    "        reprioritized = remaining_backlog\n",
    "    \n",
    "    # Parse continue decision\n",
    "    continue_match = re.search(r'## CONTINUE\\s*(.*?)(?=##|$)', response.content, re.DOTALL | re.IGNORECASE)\n",
    "    should_continue = True\n",
    "    if continue_match:\n",
    "        continue_text = continue_match.group(1).strip().lower()\n",
    "        if re.search(r'^no\\b|should\\s+stop|sufficient', continue_text):\n",
    "            should_continue = False\n",
    "    \n",
    "    print(f\"  Retrospective: {'Continue' if should_continue else 'Stop'}, {len(reprioritized)} questions\")\n",
    "    \n",
    "    return {\n",
    "        \"research_retrospective_notes\": [f\"### Sprint {current_sprint} Retrospective\\n\\n{response.content}\"],\n",
    "        \"current_research_sprint\": current_sprint + 1,\n",
    "        \"research_backlog\": reprioritized,\n",
    "        \"research_brief\": findings_summary if not should_continue or current_sprint >= max_sprints else \"\"\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_retrospective(state: CombinedTier1State) -> Literal[\"execute_research_sprint\", \"quality_gate_1\"]:\n",
    "    \"\"\"Decide whether to continue sprinting or proceed to Gate 1.\"\"\"\n",
    "    current_sprint = state.get(\"current_research_sprint\", 1)\n",
    "    max_sprints = state.get(\"max_research_sprints\", MAX_RESEARCH_SPRINTS)\n",
    "    backlog = state.get(\"research_backlog\", [])\n",
    "    \n",
    "    if current_sprint > max_sprints:\n",
    "        print(f\"\\nMax sprints ({max_sprints}) reached. Proceeding to Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    if not backlog:\n",
    "        print(f\"\\nBacklog empty. Proceeding to Gate 1.\")\n",
    "        return \"quality_gate_1\"\n",
    "    \n",
    "    print(f\"\\nContinuing to sprint {current_sprint}. {len(backlog)} questions remaining.\")\n",
    "    return \"execute_research_sprint\"\n",
    "\n",
    "\n",
    "async def quality_gate_1(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Gate 1: Validate source sufficiency.\"\"\"\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    unique_urls = list(set(source_urls))\n",
    "    domains = list(set(extract_domain(url) for url in unique_urls))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Quality Gate 1: Source Validation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Unique sources: {len(unique_urls)} (min: {MIN_SOURCES_FOR_GATE1})\")\n",
    "    print(f\"  Unique domains: {len(domains)} (min: {MIN_DOMAINS_FOR_GATE1})\")\n",
    "    \n",
    "    passed = len(unique_urls) >= MIN_SOURCES_FOR_GATE1 and len(domains) >= MIN_DOMAINS_FOR_GATE1\n",
    "    \n",
    "    if passed:\n",
    "        print(f\"  Gate 1: PASSED\")\n",
    "    else:\n",
    "        print(f\"  Gate 1: FAILED\")\n",
    "    \n",
    "    # Compress findings if not already done\n",
    "    research_brief = state.get(\"research_brief\", \"\")\n",
    "    if not research_brief:\n",
    "        all_findings = \"\\n\\n\".join(state.get(\"sprint_findings\", []))\n",
    "        if len(all_findings) > 4000:\n",
    "            summary_prompt = COMPRESS_FINDINGS_PROMPT.format(all_findings=all_findings[:8000])\n",
    "            summary_response = await llm.ainvoke([HumanMessage(content=summary_prompt)])\n",
    "            research_brief = summary_response.content\n",
    "        else:\n",
    "            research_brief = all_findings\n",
    "    \n",
    "    return {\n",
    "        \"gate1_passed\": passed,\n",
    "        \"gate1_attempts\": state.get(\"gate1_attempts\", 0) + 1,\n",
    "        \"research_brief\": research_brief\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_gate1(state: CombinedTier1State) -> Literal[\"execute_research_sprint\", \"generate_skeleton\"]:\n",
    "    \"\"\"Route after Gate 1.\"\"\"\n",
    "    passed = state.get(\"gate1_passed\", False)\n",
    "    attempts = state.get(\"gate1_attempts\", 0)\n",
    "    \n",
    "    if passed:\n",
    "        return \"generate_skeleton\"\n",
    "    elif attempts < 2:\n",
    "        print(f\"  Gate 1 failed, attempting additional sprint...\")\n",
    "        return \"execute_research_sprint\"\n",
    "    else:\n",
    "        print(f\"  Gate 1 failed after {attempts} attempts, proceeding anyway...\")\n",
    "        return \"generate_skeleton\"\n",
    "\n",
    "print(\"Phase 1 node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b06665",
   "metadata": {},
   "source": [
    "## 10. Phase 2 Node Functions (Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a6fcee9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def generate_skeleton(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Generate document skeleton from research brief.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    research_brief = state.get(\"research_brief\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 2a: Generating Document Skeleton\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    prompt = SKELETON_GENERATION_PROMPT.format(\n",
    "        question=question,\n",
    "        research_brief=research_brief[:MAX_CONTEXT_CHARS]\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SkeletonGenerationOutput)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Build skeleton dict\n",
    "    skeleton = {\n",
    "        \"thesis\": result.thesis,\n",
    "        \"root_nodes\": [s.node_id for s in result.sections],\n",
    "        \"nodes\": {s.node_id: s.model_dump() for s in result.sections},\n",
    "        \"style_constraints\": \"Academic tone, comprehensive citations\"\n",
    "    }\n",
    "    \n",
    "    print(f\"  Generated skeleton with {len(result.sections)} sections\")\n",
    "    print(f\"  Thesis: {result.thesis[:80]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"skeleton\": skeleton\n",
    "    }\n",
    "\n",
    "\n",
    "async def identify_claim_placeholders(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Identify claims that need to be researched (from V2).\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    research_brief = state.get(\"research_brief\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 2b: Identifying Claim Placeholders\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build skeleton summary\n",
    "    skeleton_summary = []\n",
    "    for node_id in skeleton.get(\"root_nodes\", []):\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        skeleton_summary.append(f\"- {node_id}: {node.get('title', '')} - {node.get('intent', '')[:100]}\")\n",
    "    \n",
    "    prompt = CLAIM_PLACEHOLDER_PROMPT.format(\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        skeleton_summary=\"\\n\".join(skeleton_summary),\n",
    "        research_brief=research_brief[:MAX_CONTEXT_CHARS]\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(ClaimPlaceholderOutput)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    claims_registry = {claim.claim_id: claim.model_dump() for claim in result.claims}\n",
    "    \n",
    "    print(f\"  Identified {len(claims_registry)} placeholder claims\")\n",
    "    \n",
    "    return {\n",
    "        \"claims_registry\": claims_registry\n",
    "    }\n",
    "\n",
    "\n",
    "async def validate_skeleton(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Gate 1.5: Validate skeleton structure.\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 2c: Skeleton Validation (Gate 1.5)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    is_valid, issues = _validate_skeleton_structure(skeleton)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"  Skeleton validation: PASSED\")\n",
    "    else:\n",
    "        print(f\"  Skeleton validation: FAILED\")\n",
    "        for issue in issues:\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    return {\n",
    "        \"skeleton_validated\": is_valid\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_skeleton_validation(state: CombinedTier1State) -> Literal[\"expand_all_nodes\", \"generate_skeleton\"]:\n",
    "    \"\"\"Route after skeleton validation.\"\"\"\n",
    "    validated = state.get(\"skeleton_validated\", False)\n",
    "    if validated:\n",
    "        return \"expand_all_nodes\"\n",
    "    else:\n",
    "        # Could retry skeleton generation, but for now just proceed\n",
    "        print(\"  Proceeding despite validation issues...\")\n",
    "        return \"expand_all_nodes\"\n",
    "\n",
    "print(\"Phase 2 node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3120a1",
   "metadata": {},
   "source": [
    "## 11. Phase 3 Node Functions (Expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2d9aa44",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def expand_all_nodes(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Expand all skeleton nodes into prose.\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    question = state[\"question\"]\n",
    "    research_brief = state.get(\"research_brief\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 3a: Expanding Nodes\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    sorted_nodes = topological_sort_nodes(skeleton, leaf_nodes)\n",
    "    \n",
    "    prose_store = {}\n",
    "    nodes_expanded = []\n",
    "    \n",
    "    # Build skeleton summary\n",
    "    skeleton_summary = []\n",
    "    for node_id in skeleton.get(\"root_nodes\", []):\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        skeleton_summary.append(f\"- {node_id}: {node.get('title', '')}\")\n",
    "    \n",
    "    for node_id in sorted_nodes:\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        print(f\"  Expanding: {node_id} - {node.get('title', '')[:40]}...\")\n",
    "        \n",
    "        # Get previous bridge_out\n",
    "        prev_node, next_node = get_adjacent_nodes(skeleton, node_id)\n",
    "        previous_bridge_out = \"\"\n",
    "        if prev_node and prev_node in prose_store:\n",
    "            previous_bridge_out = prose_store[prev_node].get(\"bridge_out\", \"\")\n",
    "        \n",
    "        # Get dependency summaries\n",
    "        dependency_summaries = []\n",
    "        for dep_id in node.get(\"dependencies\", []):\n",
    "            if dep_id in prose_store:\n",
    "                dep_summary = prose_store[dep_id].get(\"summary\", \"\")\n",
    "                if dep_summary:\n",
    "                    dep_title = skeleton.get(\"nodes\", {}).get(dep_id, {}).get(\"title\", dep_id)\n",
    "                    dependency_summaries.append(f\"[{dep_title}]: {dep_summary}\")\n",
    "        \n",
    "        prompt = PROSE_GENERATION_PROMPT.format(\n",
    "            question=question,\n",
    "            thesis=skeleton.get(\"thesis\", \"\"),\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            target_words=node.get(\"target_word_count\", TARGET_WORDS_PER_NODE),\n",
    "            skeleton_summary=\"\\n\".join(skeleton_summary),\n",
    "            previous_bridge_out=previous_bridge_out if previous_bridge_out else \"(First section - no previous content)\",\n",
    "            dependency_summaries=\"\\n\".join(dependency_summaries) if dependency_summaries else \"(No dependencies)\",\n",
    "            research_findings=research_brief[:MAX_CONTEXT_CHARS]\n",
    "        )\n",
    "        \n",
    "        structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "        result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        prose_entry = ProseEntry(\n",
    "            node_id=node_id,\n",
    "            main_content=result.main_content,\n",
    "            bridge_in=result.bridge_in,\n",
    "            bridge_out=result.bridge_out,\n",
    "            summary=result.summary\n",
    "        )\n",
    "        prose_store[node_id] = prose_entry.model_dump()\n",
    "        nodes_expanded.append(node_id)\n",
    "    \n",
    "    print(f\"  Expanded {len(nodes_expanded)} nodes\")\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": prose_store,\n",
    "        \"nodes_expanded\": nodes_expanded\n",
    "    }\n",
    "\n",
    "\n",
    "async def extract_inline_claims(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Extract claims from expanded prose.\"\"\"\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    existing_claims = state.get(\"claims_registry\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 3b: Extracting Claims\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_claims = dict(existing_claims)  # Start with placeholder claims\n",
    "    \n",
    "    for node_id, prose_entry in prose_store.items():\n",
    "        prose = f\"{prose_entry.get('bridge_in', '')}\\n{prose_entry.get('main_content', '')}\\n{prose_entry.get('bridge_out', '')}\"\n",
    "        \n",
    "        prompt = CLAIM_EXTRACTION_PROMPT.format(\n",
    "            node_id=node_id,\n",
    "            prose=prose\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            structured_llm = llm.with_structured_output(ClaimExtractionOutput)\n",
    "            result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "            \n",
    "            for claim in result.claims:\n",
    "                all_claims[claim.claim_id] = claim.model_dump()\n",
    "        except Exception as e:\n",
    "            print(f\"    Error extracting claims from {node_id}: {e}\")\n",
    "    \n",
    "    print(f\"  Total claims in registry: {len(all_claims)}\")\n",
    "    \n",
    "    return {\n",
    "        \"claims_registry\": all_claims\n",
    "    }\n",
    "\n",
    "\n",
    "async def assemble_draft(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Assemble prose into initial draft.\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 3c: Assembling Draft\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    \n",
    "    document_parts = []\n",
    "    document_parts.append(f\"# Research Report\\n\\n**Thesis:** {skeleton.get('thesis', '')}\\n\\n---\\n\")\n",
    "    \n",
    "    for node_id in leaf_nodes:\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        prose = prose_store.get(node_id, {})\n",
    "        \n",
    "        section = f\"## {node.get('title', node_id)}\\n\\n\"\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            section += f\"{prose['bridge_in']}\\n\\n\"\n",
    "        section += f\"{prose.get('main_content', '')}\\n\\n\"\n",
    "        if prose.get(\"bridge_out\"):\n",
    "            section += f\"{prose['bridge_out']}\\n\"\n",
    "        \n",
    "        document_parts.append(section)\n",
    "    \n",
    "    assembled_draft = \"\\n---\\n\\n\".join(document_parts)\n",
    "    \n",
    "    print(f\"  Assembled draft: {len(assembled_draft)} characters\")\n",
    "    \n",
    "    return {\n",
    "        \"assembled_draft\": assembled_draft,\n",
    "        \"current_verification_iteration\": 0,\n",
    "        \"max_verification_iterations\": MAX_VERIFICATION_ITERATIONS\n",
    "    }\n",
    "\n",
    "print(\"Phase 3 node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586165dd",
   "metadata": {},
   "source": [
    "## 12. Phase 4 Node Functions (Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fa04abd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def structured_critique(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Perform structured critique of the document.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4a: Structured Critique\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build skeleton summary\n",
    "    skeleton_summary = []\n",
    "    for node_id in skeleton.get(\"root_nodes\", []):\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        skeleton_summary.append(f\"- {node_id}: {node.get('title', '')}\")\n",
    "    \n",
    "    # Build claims summary\n",
    "    claims_summary = []\n",
    "    for claim_id, claim in list(claims_registry.items())[:30]:\n",
    "        status = claim.get(\"verification_status\", \"unverified\")\n",
    "        text = claim.get(\"claim_text\", \"\")[:80]\n",
    "        claims_summary.append(f\"- [{status}] {claim_id}: {text}\")\n",
    "    \n",
    "    prompt = CRITIQUE_PROMPT.format(\n",
    "        question=question,\n",
    "        thesis=skeleton.get(\"thesis\", \"\"),\n",
    "        skeleton_summary=\"\\n\".join(skeleton_summary),\n",
    "        claims_summary=\"\\n\".join(claims_summary) if claims_summary else \"(No claims yet)\",\n",
    "        document_content=assembled_draft[:MAX_CONTEXT_CHARS]\n",
    "    )\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(CritiqueResult)\n",
    "    result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    noise_map = [issue.model_dump() for issue in result.issues]\n",
    "    nodes_to_patch = list(set(\n",
    "        node_id \n",
    "        for issue in result.issues \n",
    "        for node_id in issue.target_nodes\n",
    "        if issue.severity in [\"critical\", \"major\"]\n",
    "    ))\n",
    "    \n",
    "    print(f\"  Quality score: {result.overall_quality}/10\")\n",
    "    print(f\"  Issues found: {len(noise_map)}\")\n",
    "    print(f\"  Nodes to patch: {len(nodes_to_patch)}\")\n",
    "    \n",
    "    return {\n",
    "        \"noise_map\": noise_map,\n",
    "        \"nodes_to_patch\": nodes_to_patch,\n",
    "        \"quality_scores\": [{\"critique_score\": result.overall_quality}]\n",
    "    }\n",
    "\n",
    "\n",
    "async def quality_gate_2(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Gate 2: Multi-dimensional quality check (V1's prompt).\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    claims_registry = state.get(\"claims_registry\", {})\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4b: Quality Gate 2 (Multi-dimensional)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build claims summary\n",
    "    claims_summary = []\n",
    "    for claim_id, claim in list(claims_registry.items())[:30]:\n",
    "        status = claim.get(\"verification_status\", \"unverified\")\n",
    "        evidence = claim.get(\"supporting_evidence\", [])\n",
    "        text = claim.get(\"claim_text\", \"\")[:80]\n",
    "        claims_summary.append(f\"- [{status}, {len(evidence)} sources] {text}\")\n",
    "    \n",
    "    prompt = GATE2_CHECK_PROMPT.format(\n",
    "        question=question,\n",
    "        document_content=assembled_draft[:MAX_CONTEXT_CHARS],\n",
    "        claims_summary=\"\\n\".join(claims_summary) if claims_summary else \"(No claims)\"\n",
    "    )\n",
    "    \n",
    "    response = await llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse scores\n",
    "    scores = {}\n",
    "    for dim in [\"QUESTION_COVERAGE\", \"EVIDENCE_QUALITY\", \"COHERENCE\", \"DEPTH\", \"OVERALL\"]:\n",
    "        match = re.search(rf'{dim}:\\s*(\\d+(?:\\.\\d+)?)', content, re.IGNORECASE)\n",
    "        if match:\n",
    "            scores[dim.lower()] = float(match.group(1))\n",
    "    \n",
    "    # Parse pass/fail\n",
    "    pass_match = re.search(r'PASS:\\s*(YES|NO)', content, re.IGNORECASE)\n",
    "    passed = pass_match and pass_match.group(1).upper() == \"YES\"\n",
    "    \n",
    "    # Parse weak claims\n",
    "    weak_claims = []\n",
    "    weak_match = re.search(r'WEAK_CLAIMS:\\s*(.+?)(?=\\n\\n|$)', content, re.DOTALL | re.IGNORECASE)\n",
    "    if weak_match:\n",
    "        weak_text = weak_match.group(1).strip()\n",
    "        if weak_text.lower() != \"none\":\n",
    "            weak_claims = [c.strip() for c in re.split(r'[-â€¢\\n,]', weak_text) if c.strip()]\n",
    "    \n",
    "    print(f\"  Scores: {scores}\")\n",
    "    print(f\"  Gate 2: {'PASSED' if passed else 'FAILED'}\")\n",
    "    if weak_claims:\n",
    "        print(f\"  Weak claims: {len(weak_claims)}\")\n",
    "    \n",
    "    return {\n",
    "        \"gate2_passed\": passed,\n",
    "        \"quality_scores\": [scores],\n",
    "        \"nodes_to_patch\": [c.get(\"source_node\") for c in claims_registry.values() \n",
    "                          if c.get(\"claim_text\", \"\") in weak_claims][:5]\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_gate2(state: CombinedTier1State) -> Literal[\"targeted_retrieval\", \"assemble_document\", \"mark_limitations\"]:\n",
    "    \"\"\"Route after Gate 2.\"\"\"\n",
    "    passed = state.get(\"gate2_passed\", False)\n",
    "    iteration = state.get(\"current_verification_iteration\", 0)\n",
    "    max_iterations = state.get(\"max_verification_iterations\", MAX_VERIFICATION_ITERATIONS)\n",
    "    \n",
    "    if passed:\n",
    "        return \"assemble_document\"\n",
    "    elif iteration < max_iterations:\n",
    "        return \"targeted_retrieval\"\n",
    "    else:\n",
    "        return \"mark_limitations\"\n",
    "\n",
    "\n",
    "async def targeted_retrieval(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Fetch evidence for weak claims using Knowledge Cache.\"\"\"\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4c: Targeted Retrieval\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    targeted_evidence = {}\n",
    "    all_decisions = []\n",
    "    \n",
    "    # Get search queries from noise map\n",
    "    search_queries = []\n",
    "    for issue in noise_map:\n",
    "        if issue.get(\"search_query\") and issue.get(\"severity\") in [\"critical\", \"major\"]:\n",
    "            for node_id in issue.get(\"target_nodes\", []):\n",
    "                search_queries.append((node_id, issue[\"search_query\"]))\n",
    "    \n",
    "    # Execute searches\n",
    "    for node_id, query in search_queries[:6]:  # Limit searches\n",
    "        print(f\"  Searching for {node_id}: {query[:40]}...\")\n",
    "        content, urls, decision = await cascaded_search(query, knowledge_base)\n",
    "        \n",
    "        if node_id not in targeted_evidence:\n",
    "            targeted_evidence[node_id] = []\n",
    "        targeted_evidence[node_id].append(content[:2000])\n",
    "        all_decisions.append(decision.model_dump())\n",
    "    \n",
    "    print(f\"  Retrieved evidence for {len(targeted_evidence)} nodes\")\n",
    "    \n",
    "    return {\n",
    "        \"targeted_evidence\": targeted_evidence,\n",
    "        \"cache_decisions\": all_decisions\n",
    "    }\n",
    "\n",
    "\n",
    "async def apply_patches(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Apply patches to nodes with issues.\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    nodes_to_patch = state.get(\"nodes_to_patch\", [])\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    targeted_evidence = state.get(\"targeted_evidence\", {})\n",
    "    iteration = state.get(\"current_verification_iteration\", 0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4d: Applying Patches (Iteration {iteration + 1})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    updated_prose_store = dict(prose_store)\n",
    "    \n",
    "    for node_id in nodes_to_patch[:5]:  # Limit patches per iteration\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        current_prose = prose_store.get(node_id, {})\n",
    "        \n",
    "        if not current_prose:\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Patching: {node_id}\")\n",
    "        \n",
    "        # Get issues for this node\n",
    "        node_issues = [issue for issue in noise_map if node_id in issue.get(\"target_nodes\", [])]\n",
    "        issues_text = \"\\n\".join([\n",
    "            f\"- [{i.get('severity')}] {i.get('issue_type')}: {i.get('description')}\\n  Suggestion: {i.get('suggestion')}\"\n",
    "            for i in node_issues[:3]\n",
    "        ])\n",
    "        \n",
    "        # Get evidence\n",
    "        evidence = targeted_evidence.get(node_id, [])\n",
    "        evidence_text = \"\\n\\n\".join(evidence) if evidence else \"(No new evidence)\"\n",
    "        \n",
    "        # Get adjacent prose\n",
    "        prev_node, next_node = get_adjacent_nodes(skeleton, node_id)\n",
    "        prev_bridge = prose_store.get(prev_node, {}).get(\"bridge_out\", \"\") if prev_node else \"\"\n",
    "        next_bridge = prose_store.get(next_node, {}).get(\"bridge_in\", \"\") if next_node else \"\"\n",
    "        \n",
    "        prompt = PATCH_PROMPT.format(\n",
    "            node_id=node_id,\n",
    "            title=node.get(\"title\", \"\"),\n",
    "            intent=node.get(\"intent\", \"\"),\n",
    "            current_bridge_in=current_prose.get(\"bridge_in\", \"\"),\n",
    "            current_main_content=current_prose.get(\"main_content\", \"\"),\n",
    "            current_bridge_out=current_prose.get(\"bridge_out\", \"\"),\n",
    "            issues_for_node=issues_text if issues_text else \"(No specific issues)\",\n",
    "            new_evidence=evidence_text[:MAX_CONTEXT_CHARS],\n",
    "            prev_bridge_out=prev_bridge if prev_bridge else \"(Start of document)\",\n",
    "            next_bridge_in=next_bridge if next_bridge else \"(End of document)\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            structured_llm = llm.with_structured_output(ProseGenerationOutput)\n",
    "            result = await structured_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "            \n",
    "            updated_prose = {\n",
    "                \"node_id\": node_id,\n",
    "                \"main_content\": result.main_content,\n",
    "                \"bridge_in\": result.bridge_in,\n",
    "                \"bridge_out\": result.bridge_out,\n",
    "                \"summary\": result.summary,\n",
    "                \"revision_count\": current_prose.get(\"revision_count\", 0) + 1\n",
    "            }\n",
    "            updated_prose_store[node_id] = updated_prose\n",
    "        except Exception as e:\n",
    "            print(f\"    Error patching {node_id}: {e}\")\n",
    "    \n",
    "    print(f\"  Patched {min(len(nodes_to_patch), 5)} nodes\")\n",
    "    \n",
    "    # Reassemble draft\n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    document_parts = [f\"# Research Report\\n\\n**Thesis:** {skeleton.get('thesis', '')}\\n\\n---\\n\"]\n",
    "    \n",
    "    for node_id in leaf_nodes:\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        prose = updated_prose_store.get(node_id, {})\n",
    "        \n",
    "        section = f\"## {node.get('title', node_id)}\\n\\n\"\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            section += f\"{prose['bridge_in']}\\n\\n\"\n",
    "        section += f\"{prose.get('main_content', '')}\\n\\n\"\n",
    "        if prose.get(\"bridge_out\"):\n",
    "            section += f\"{prose['bridge_out']}\\n\"\n",
    "        \n",
    "        document_parts.append(section)\n",
    "    \n",
    "    assembled_draft = \"\\n---\\n\\n\".join(document_parts)\n",
    "    \n",
    "    return {\n",
    "        \"prose_store\": updated_prose_store,\n",
    "        \"assembled_draft\": assembled_draft,\n",
    "        \"current_verification_iteration\": iteration + 1,\n",
    "        \"nodes_to_patch\": []  # Clear for next iteration\n",
    "    }\n",
    "\n",
    "\n",
    "def route_after_patches(state: CombinedTier1State) -> Literal[\"structured_critique\", \"mark_limitations\"]:\n",
    "    \"\"\"Route after applying patches.\"\"\"\n",
    "    iteration = state.get(\"current_verification_iteration\", 0)\n",
    "    max_iterations = state.get(\"max_verification_iterations\", MAX_VERIFICATION_ITERATIONS)\n",
    "    \n",
    "    # Skip cascade on first iteration (optimization)\n",
    "    if SKIP_CASCADE_ON_FIRST_ITERATION and iteration == 1:\n",
    "        print(\"  Skipping cascade check on first iteration\")\n",
    "    \n",
    "    if iteration < max_iterations:\n",
    "        return \"structured_critique\"\n",
    "    else:\n",
    "        return \"mark_limitations\"\n",
    "\n",
    "\n",
    "async def mark_limitations(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Mark limitations for unresolved issues (graceful degradation from V2).\"\"\"\n",
    "    noise_map = state.get(\"noise_map\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 4e: Marking Limitations\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Collect unresolved critical/major issues\n",
    "    limitations = []\n",
    "    for issue in noise_map:\n",
    "        if issue.get(\"severity\") in [\"critical\", \"major\"]:\n",
    "            limitations.append(f\"- {issue.get('description', 'Unresolved issue')}\")\n",
    "    \n",
    "    if limitations:\n",
    "        print(f\"  Noted {len(limitations)} limitations\")\n",
    "    else:\n",
    "        print(f\"  No significant limitations to note\")\n",
    "    \n",
    "    return {\n",
    "        \"limitations_noted\": limitations[:5],  # Keep top 5\n",
    "        \"gate2_passed\": True  # Proceed anyway after marking limitations\n",
    "    }\n",
    "\n",
    "print(\"Phase 4 node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1013f",
   "metadata": {},
   "source": [
    "## 13. Phase 5 Node Functions (Finalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f67d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 5 node functions defined\n"
     ]
    }
   ],
   "source": [
    "async def assemble_document(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Assemble final document with references.\"\"\"\n",
    "    skeleton = state.get(\"skeleton\", {})\n",
    "    prose_store = state.get(\"prose_store\", {})\n",
    "    source_urls = state.get(\"research_source_urls\", [])\n",
    "    limitations = state.get(\"limitations_noted\", [])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 5a: Assembling Final Document\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    leaf_nodes = get_leaf_nodes(skeleton)\n",
    "    \n",
    "    # Build document\n",
    "    document_parts = []\n",
    "    document_parts.append(f\"# Research Report\\n\\n**Thesis:** {skeleton.get('thesis', '')}\\n\")\n",
    "    \n",
    "    for node_id in leaf_nodes:\n",
    "        node = skeleton.get(\"nodes\", {}).get(node_id, {})\n",
    "        prose = prose_store.get(node_id, {})\n",
    "        \n",
    "        section = f\"\\n## {node.get('title', node_id)}\\n\\n\"\n",
    "        if prose.get(\"bridge_in\"):\n",
    "            section += f\"{prose['bridge_in']}\\n\\n\"\n",
    "        section += f\"{prose.get('main_content', '')}\\n\\n\"\n",
    "        if prose.get(\"bridge_out\"):\n",
    "            section += f\"{prose['bridge_out']}\\n\"\n",
    "        \n",
    "        document_parts.append(section)\n",
    "    \n",
    "    # Add limitations if any\n",
    "    if limitations:\n",
    "        limitations_section = \"\\n## Limitations and Caveats\\n\\n\"\n",
    "        limitations_section += \"The following aspects could not be fully addressed:\\n\\n\"\n",
    "        limitations_section += \"\\n\".join(limitations)\n",
    "        document_parts.append(limitations_section)\n",
    "    \n",
    "    # Add references\n",
    "    unique_urls = list(set(source_urls))[:30]\n",
    "    if unique_urls:\n",
    "        refs_section = \"\\n## References\\n\\n\"\n",
    "        for i, url in enumerate(unique_urls, 1):\n",
    "            refs_section += f\"{i}. {url}\\n\"\n",
    "        document_parts.append(refs_section)\n",
    "    \n",
    "    final_document = \"\\n\".join(document_parts)\n",
    "    \n",
    "    print(f\"  Document assembled: {len(final_document)} characters\")\n",
    "    \n",
    "    return {\n",
    "        \"assembled_draft\": final_document\n",
    "    }\n",
    "\n",
    "\n",
    "async def final_polish(state: CombinedTier1State) -> dict:\n",
    "    \"\"\"Apply final polish to document.\"\"\"\n",
    "    assembled_draft = state.get(\"assembled_draft\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Phase 5b: Final Polish\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # For now, just pass through - could add executive summary generation\n",
    "    final_report = assembled_draft\n",
    "    \n",
    "    # Print cache statistics\n",
    "    print(f\"\\n{knowledge_base.get_stats_summary()}\")\n",
    "    \n",
    "    print(f\"\\n  Final report: {len(final_report)} characters\")\n",
    "    print(f\"  Word count: ~{len(final_report.split())}\")\n",
    "    \n",
    "    return {\n",
    "        \"final_report\": final_report\n",
    "    }\n",
    "\n",
    "print(\"Phase 5 node functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c75dbd",
   "metadata": {},
   "source": [
    "## 14. Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33e8da57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Tier 1 Agent compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Build the Combined Tier 1 Agent graph\n",
    "builder = StateGraph(CombinedTier1State)\n",
    "\n",
    "# Phase 1: Research\n",
    "builder.add_node(\"decompose_question\", decompose_question)\n",
    "builder.add_node(\"execute_research_sprint\", execute_research_sprint)\n",
    "builder.add_node(\"research_retrospective\", research_retrospective)\n",
    "builder.add_node(\"quality_gate_1\", quality_gate_1)\n",
    "\n",
    "# Phase 2: Structure\n",
    "builder.add_node(\"generate_skeleton\", generate_skeleton)\n",
    "builder.add_node(\"identify_claim_placeholders\", identify_claim_placeholders)\n",
    "builder.add_node(\"validate_skeleton\", validate_skeleton)\n",
    "\n",
    "# Phase 3: Expansion\n",
    "builder.add_node(\"expand_all_nodes\", expand_all_nodes)\n",
    "builder.add_node(\"extract_inline_claims\", extract_inline_claims)\n",
    "builder.add_node(\"assemble_draft\", assemble_draft)\n",
    "\n",
    "# Phase 4: Verification\n",
    "builder.add_node(\"structured_critique\", structured_critique)\n",
    "builder.add_node(\"quality_gate_2\", quality_gate_2)\n",
    "builder.add_node(\"targeted_retrieval\", targeted_retrieval)\n",
    "builder.add_node(\"apply_patches\", apply_patches)\n",
    "builder.add_node(\"mark_limitations\", mark_limitations)\n",
    "\n",
    "# Phase 5: Finalization\n",
    "builder.add_node(\"assemble_document\", assemble_document)\n",
    "builder.add_node(\"final_polish\", final_polish)\n",
    "\n",
    "# Edges: Phase 1\n",
    "builder.add_edge(START, \"decompose_question\")\n",
    "builder.add_edge(\"decompose_question\", \"execute_research_sprint\")\n",
    "builder.add_edge(\"execute_research_sprint\", \"research_retrospective\")\n",
    "builder.add_conditional_edges(\"research_retrospective\", route_after_retrospective)\n",
    "builder.add_conditional_edges(\"quality_gate_1\", route_after_gate1)\n",
    "\n",
    "# Edges: Phase 2\n",
    "builder.add_edge(\"generate_skeleton\", \"identify_claim_placeholders\")\n",
    "builder.add_edge(\"identify_claim_placeholders\", \"validate_skeleton\")\n",
    "builder.add_conditional_edges(\"validate_skeleton\", route_after_skeleton_validation)\n",
    "\n",
    "# Edges: Phase 3\n",
    "builder.add_edge(\"expand_all_nodes\", \"extract_inline_claims\")\n",
    "builder.add_edge(\"extract_inline_claims\", \"assemble_draft\")\n",
    "builder.add_edge(\"assemble_draft\", \"structured_critique\")\n",
    "\n",
    "# Edges: Phase 4\n",
    "builder.add_edge(\"structured_critique\", \"quality_gate_2\")\n",
    "builder.add_conditional_edges(\"quality_gate_2\", route_after_gate2)\n",
    "builder.add_edge(\"targeted_retrieval\", \"apply_patches\")\n",
    "builder.add_conditional_edges(\"apply_patches\", route_after_patches)\n",
    "builder.add_edge(\"mark_limitations\", \"assemble_document\")\n",
    "\n",
    "# Edges: Phase 5\n",
    "builder.add_edge(\"assemble_document\", \"final_polish\")\n",
    "builder.add_edge(\"final_polish\", END)\n",
    "\n",
    "# Compile\n",
    "combined_tier1_graph = builder.compile()\n",
    "\n",
    "print(\"Combined Tier 1 Agent compiled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6dbd3a4b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "try:\n",
    "    display(Image(combined_tier1_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe0850",
   "metadata": {},
   "source": [
    "## 15. Agent Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5980b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent wrappers defined\n"
     ]
    }
   ],
   "source": [
    "async def combined_tier1_agent_async(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Async version of the Combined Tier 1 research agent.\n",
    "    \"\"\"\n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    # Reset knowledge base for new session\n",
    "    global knowledge_base\n",
    "    knowledge_base = KnowledgeBase()\n",
    "    \n",
    "    result = await combined_tier1_graph.ainvoke(\n",
    "        {\"question\": question},\n",
    "        config={\"recursion_limit\": 100}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"sprint_findings\": result.get(\"sprint_findings\", []),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.get_stats_summary(),\n",
    "        \"limitations\": result.get(\"limitations_noted\", [])\n",
    "    }\n",
    "\n",
    "\n",
    "def combined_tier1_agent(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Sync wrapper for Combined Tier 1 research agent.\n",
    "    Compatible with evaluation harness.\n",
    "    \"\"\"\n",
    "    question = inputs.get(\"question\", \"\")\n",
    "    \n",
    "    async def _execute():\n",
    "        global knowledge_base\n",
    "        knowledge_base = KnowledgeBase()\n",
    "        return await combined_tier1_graph.ainvoke(\n",
    "            {\"question\": question},\n",
    "            config={\"recursion_limit\": 100}\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import concurrent.futures\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(asyncio.run, _execute())\n",
    "            result = future.result()\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(_execute())\n",
    "    \n",
    "    return {\n",
    "        \"output\": result.get(\"final_report\", \"\"),\n",
    "        \"sprint_findings\": result.get(\"sprint_findings\", []),\n",
    "        \"source_urls\": list(set(result.get(\"research_source_urls\", []))),\n",
    "        \"quality_scores\": result.get(\"quality_scores\", []),\n",
    "        \"cache_stats\": knowledge_base.get_stats_summary(),\n",
    "        \"limitations\": result.get(\"limitations_noted\", [])\n",
    "    }\n",
    "\n",
    "print(\"Agent wrappers defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f7c1b",
   "metadata": {},
   "source": [
    "## 16. Manual Test\n",
    "\n",
    "Run this cell to verify the agent works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7bce60b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Combined Tier 1 Agent with question:\n",
      "What are the key benefits and challenges of using large language models in enterprise applications?\n",
      "\n",
      "Running combined research agent (this may take several minutes)...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Phase 1a: Decomposing Research Question\n",
      "============================================================\n",
      "  Created backlog with 6 research questions\n",
      "\n",
      "============================================================\n",
      "Sprint 1/2: What measurable business outcomes (e.g., productivity gains, cost redu...\n",
      "============================================================\n",
      "  Searching: What measurable business outcomes (e.g., productiv...\n",
      "  Searching: (\"measurable business outcomes\" OR \"quantified res...\n",
      "  Searching: (\"highest ROI\" OR \"best ROI\" OR \"top ROI\" OR \"most...\n",
      "  Synthesized 4759 characters\n",
      "  Collected 12 source URLs\n",
      "  Retrospective: Continue, 7 questions\n",
      "\n",
      "Continuing to sprint 2. 7 questions remaining.\n",
      "\n",
      "============================================================\n",
      "Sprint 2/2: Data security, privacy, and regulatory-compliance risks with LLMs (inc...\n",
      "============================================================\n",
      "  Searching: Data security, privacy, and regulatory-compliance ...\n",
      "  Searching: (\"large language model\" OR LLM) AND (\"data leakage...\n",
      "  Searching: (\"private inference\" OR \"onâ€‘prem\" OR \"on premises\"...\n",
      "  Synthesized 4789 characters\n",
      "  Collected 24 source URLs\n",
      "  Retrospective: Continue, 24 questions\n",
      "\n",
      "Max sprints (2) reached. Proceeding to Gate 1.\n",
      "\n",
      "============================================================\n",
      "Quality Gate 1: Source Validation\n",
      "============================================================\n",
      "  Unique sources: 36 (min: 15)\n",
      "  Unique domains: 35 (min: 5)\n",
      "  Gate 1: PASSED\n",
      "\n",
      "============================================================\n",
      "Phase 2a: Generating Document Skeleton\n",
      "============================================================\n",
      "  Generated skeleton with 7 sections\n",
      "  Thesis: Large language models can deliver substantial, measurable benefits in scoped ent...\n",
      "\n",
      "============================================================\n",
      "Phase 2b: Identifying Claim Placeholders\n",
      "============================================================\n",
      "  Identified 21 placeholder claims\n",
      "\n",
      "============================================================\n",
      "Phase 2c: Skeleton Validation (Gate 1.5)\n",
      "============================================================\n",
      "  Skeleton validation: PASSED\n",
      "\n",
      "============================================================\n",
      "Phase 3a: Expanding Nodes\n",
      "============================================================\n",
      "  Expanding: sec:intro - Introduction...\n",
      "  Expanding: sec:background - Background and Technical Foundations...\n",
      "  Expanding: sec:benefits - Business Benefits and Highâ€‘ROI Use Cases...\n",
      "  Expanding: sec:security - Security, Privacy, and Compliance Risks...\n",
      "  Expanding: sec:deployment - Deployment Models and Operational Challe...\n",
      "  Expanding: sec:analysis - Analysis and Discussion...\n",
      "  Expanding: sec:conclusion - Conclusion and Recommendations...\n",
      "  Expanded 7 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 3b: Extracting Claims\n",
      "============================================================\n",
      "  Total claims in registry: 71\n",
      "\n",
      "============================================================\n",
      "Phase 3c: Assembling Draft\n",
      "============================================================\n",
      "  Assembled draft: 22115 characters\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Structured Critique\n",
      "============================================================\n",
      "  Quality score: 4.0/10\n",
      "  Issues found: 11\n",
      "  Nodes to patch: 7\n",
      "\n",
      "============================================================\n",
      "Phase 4b: Quality Gate 2 (Multi-dimensional)\n",
      "============================================================\n",
      "  Scores: {}\n",
      "  Gate 2: FAILED\n",
      "  Weak claims: 14\n",
      "\n",
      "============================================================\n",
      "Phase 4c: Targeted Retrieval\n",
      "============================================================\n",
      "  Searching for sec:security: best practices for drafting complete res...\n",
      "  Searching for sec:deployment: best practices for drafting complete res...\n",
      "  Searching for sec:analysis: best practices for drafting complete res...\n",
      "  Searching for sec:conclusion: best practices for drafting complete res...\n",
      "  Searching for sec:intro: independent studies LLM enterprise ROI c...\n",
      "  Searching for sec:benefits: independent studies LLM enterprise ROI c...\n",
      "  Retrieved evidence for 6 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 4d: Applying Patches (Iteration 1)\n",
      "============================================================\n",
      "  Patched 0 nodes\n",
      "  Skipping cascade check on first iteration\n",
      "\n",
      "============================================================\n",
      "Phase 4a: Structured Critique\n",
      "============================================================\n",
      "  Quality score: 4.0/10\n",
      "  Issues found: 12\n",
      "  Nodes to patch: 7\n",
      "\n",
      "============================================================\n",
      "Phase 4b: Quality Gate 2 (Multi-dimensional)\n",
      "============================================================\n",
      "  Scores: {'question_coverage': 9.0, 'evidence_quality': 6.0, 'coherence': 7.0, 'depth': 7.0, 'overall': 7.25}\n",
      "  Gate 2: FAILED\n",
      "  Weak claims: 13\n",
      "\n",
      "============================================================\n",
      "Phase 4c: Targeted Retrieval\n",
      "============================================================\n",
      "  Searching for sec:security: differential privacy LLM enterprise miti...\n",
      "  Searching for sec:deployment: differential privacy LLM enterprise miti...\n",
      "  Searching for sec:analysis: differential privacy LLM enterprise miti...\n",
      "  Searching for sec:conclusion: differential privacy LLM enterprise miti...\n",
      "  Searching for sec:intro: independent study LLM contact center AHT...\n",
      "  Searching for sec:benefits: independent study LLM contact center AHT...\n",
      "  Retrieved evidence for 6 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 4d: Applying Patches (Iteration 2)\n",
      "============================================================\n",
      "  Patched 0 nodes\n",
      "\n",
      "============================================================\n",
      "Phase 4e: Marking Limitations\n",
      "============================================================\n",
      "  Noted 8 limitations\n",
      "\n",
      "============================================================\n",
      "Phase 5a: Assembling Final Document\n",
      "============================================================\n",
      "  Document assembled: 26050 characters\n",
      "\n",
      "============================================================\n",
      "Phase 5b: Final Polish\n",
      "============================================================\n",
      "\n",
      "\n",
      "Cache Statistics:\n",
      "- Total queries: 18\n",
      "- Web searches avoided: 7 (38.9% hit rate)\n",
      "- Web searches executed: 14\n",
      "- Documents cached: 14\n",
      "- Chunks indexed: 115\n",
      "\n",
      "\n",
      "  Final report: 26050 characters\n",
      "  Word count: ~2600\n",
      "================================================================================\n",
      "FINAL REPORT\n",
      "================================================================================\n",
      "# Research Report\n",
      "\n",
      "**Thesis:** Large language models can deliver substantial, measurable benefits in scoped enterprise workflows (contact centers, process automation, CRM, and knowledge work) but realizing those gains at scale requires disciplined pilots, rigorous KPIs, and a layered security/privacy and contractual strategy that balances cloud delivery speed against thirdâ€‘party exposure.\n",
      "\n",
      "\n",
      "## Introduction\n",
      "\n",
      "This report opens by framing why enterprises are rapidly experimenting with large language models (LLMs) while also needing a sober, riskâ€‘aware approach.\n",
      "\n",
      "Large language models are delivering material, measured gains in focused enterprise workflows â€” but they are not a plugâ€‘andâ€‘play panacea. Highâ€‘visibility vendor and customer case studies show rapid, tangible outcomes: one contactâ€‘center deployment reported a 40% reduction in Average Handle Time (AHT), translating into direct costâ€‘perâ€‘contact savings and capacity gains (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12). EchoStarâ€™s Hughes division used Azure AI Foundry to put 12 production applications into service (sales call auditing, retention analysis, fieldâ€‘service automation), illustrating how cloud+AI platforms accelerate app delivery (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). CRM vendors likewise report â€œmillions of dollars savedâ€ by automating call summaries, record updates, and nextâ€‘best action workflows (Source: https://deselect.com/blog/ai-for-crm-how-to-turn-customer-data-into-revenue-in-2026/).\n",
      "\n",
      "At the same time, independent analyses counsel caution. Broad enterprise AI programs often yield modest enterpriseâ€‘wide ROI unless tightly scoped â€” IBMâ€™s assessment showed average enterprise AI ROI near 5.9% (Source: https://www.ibm.com/think/insights/ai-roi). Measurement gaps are common: many headline metrics are vendorâ€‘reported or caseâ€‘study based, underscoring the need for controlled pilots and TEIâ€‘style evaluations before scaling. Security, privacy, and compliance concerns are equally consequential: documented risks include data leakage, promptâ€‘injection and modelâ€‘inversion attacks, and nonâ€‘technical exposures in logs and telemetry; expert reports recommend layered technical controls plus contractual safeguards (Sources: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf; https://cloudatg.com/).\n",
      "\n",
      "This report therefore argues: LLMs can deliver substantial, measurable benefits in scoped enterprise workflows (contact centers, process automation, CRM, and knowledge work), but realizing gains at scale requires disciplined pilots, rigorous KPIs, and a layered security/privacy and contractual strategy that balances cloud delivery speed against thirdâ€‘party exposure. The evidence base combines vendor case studies, independent analyses, and security expert reports cited throughout.\n",
      "\n",
      "The ne...\n",
      "\n",
      "================================================================================\n",
      "Report length: 26050 characters\n",
      "Sprint findings: 2\n",
      "Unique sources: 36\n",
      "Quality scores: [{'critique_score': 4.0}, {}, {'critique_score': 4.0}, {'question_coverage': 9.0, 'evidence_quality': 6.0, 'coherence': 7.0, 'depth': 7.0, 'overall': 7.25}]\n",
      "\n",
      "\n",
      "Cache Statistics:\n",
      "- Total queries: 18\n",
      "- Web searches avoided: 7 (38.9% hit rate)\n",
      "- Web searches executed: 14\n",
      "- Documents cached: 14\n",
      "- Chunks indexed: 115\n",
      "\n",
      "Limitations noted: ['- The full document is truncated mid-sentence in the Security section (\"Consider differentialâ€‘privacy te...\") and the subsequent sections (Deployment Models and Operational Challenges, Analysis and Discussion, Conclusion and Recommendations) are missing or incomplete. This prevents assessment of key arguments, mitigations, deployment guidance, the promised riskâ€‘benefit matrix, and final recommendations that are central to the thesis.', \"- Many headline benefit figures (AHT reductions, 'millions of dollars saved', multi-application rollouts) are sourced to vendor blogs and singleâ€‘customer case studies. The report relies heavily on these sources without sufficient independent, systematically gathered evidence or methodologically described evaluations.\", '- Security mitigations are asserted at a high level (VPCs, TEEs/HSMs, prompt filtering, telemetry policies) but the discussion is truncated and lacks implementation detail, tradeoffs, cost implications, monitoring strategies, and references to authoritative security frameworks and advisories.', \"- The Deployment Models and Operational Challenges section is absent from the supplied full text. The thesis explicitly depends on a 'layered security/privacy and contractual strategy' and a 'cloud-vs-onprem decision framework', but the document does not contain the promised operational guidance or evaluation of deployment tradeoffs.\", \"- The Analysis and Discussion section is missing. The report promises an 'evidence-weighted riskâ€‘benefit matrix' and discussion of enterprise-wide ROI heterogeneity, but does not present those artifacts, quantitative analyses, or sensitivity checks.\"]\n",
      "Agent test PASSED\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "test_question = \"What are the key benefits and challenges of using large language models in enterprise applications?\"\n",
    "\n",
    "print(f\"Testing Combined Tier 1 Agent with question:\\n{test_question}\\n\")\n",
    "print(\"Running combined research agent (this may take several minutes)...\\n\")\n",
    "\n",
    "try:\n",
    "    result = await combined_tier1_agent_async({\"question\": test_question})\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"FINAL REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    print(result[\"output\"][:3000] + \"...\" if len(result[\"output\"]) > 3000 else result[\"output\"])\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Report length: {len(result['output'])} characters\")\n",
    "    print(f\"Sprint findings: {len(result.get('sprint_findings', []))}\")\n",
    "    print(f\"Unique sources: {len(result.get('source_urls', []))}\")\n",
    "    print(f\"Quality scores: {result.get('quality_scores', [])}\")\n",
    "    print(f\"\\n{result.get('cache_stats', '')}\")\n",
    "    if result.get(\"limitations\"):\n",
    "        print(f\"Limitations noted: {result['limitations']}\")\n",
    "    print(\"Agent test PASSED\")\n",
    "except Exception as e:\n",
    "    print(f\"Agent test FAILED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7dac7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report\n",
       "\n",
       "**Thesis:** Large language models can deliver substantial, measurable benefits in scoped enterprise workflows (contact centers, process automation, CRM, and knowledge work) but realizing those gains at scale requires disciplined pilots, rigorous KPIs, and a layered security/privacy and contractual strategy that balances cloud delivery speed against thirdâ€‘party exposure.\n",
       "\n",
       "\n",
       "## Introduction\n",
       "\n",
       "This report opens by framing why enterprises are rapidly experimenting with large language models (LLMs) while also needing a sober, riskâ€‘aware approach.\n",
       "\n",
       "Large language models are delivering material, measured gains in focused enterprise workflows â€” but they are not a plugâ€‘andâ€‘play panacea. Highâ€‘visibility vendor and customer case studies show rapid, tangible outcomes: one contactâ€‘center deployment reported a 40% reduction in Average Handle Time (AHT), translating into direct costâ€‘perâ€‘contact savings and capacity gains (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12). EchoStarâ€™s Hughes division used Azure AI Foundry to put 12 production applications into service (sales call auditing, retention analysis, fieldâ€‘service automation), illustrating how cloud+AI platforms accelerate app delivery (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). CRM vendors likewise report â€œmillions of dollars savedâ€ by automating call summaries, record updates, and nextâ€‘best action workflows (Source: https://deselect.com/blog/ai-for-crm-how-to-turn-customer-data-into-revenue-in-2026/).\n",
       "\n",
       "At the same time, independent analyses counsel caution. Broad enterprise AI programs often yield modest enterpriseâ€‘wide ROI unless tightly scoped â€” IBMâ€™s assessment showed average enterprise AI ROI near 5.9% (Source: https://www.ibm.com/think/insights/ai-roi). Measurement gaps are common: many headline metrics are vendorâ€‘reported or caseâ€‘study based, underscoring the need for controlled pilots and TEIâ€‘style evaluations before scaling. Security, privacy, and compliance concerns are equally consequential: documented risks include data leakage, promptâ€‘injection and modelâ€‘inversion attacks, and nonâ€‘technical exposures in logs and telemetry; expert reports recommend layered technical controls plus contractual safeguards (Sources: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf; https://cloudatg.com/).\n",
       "\n",
       "This report therefore argues: LLMs can deliver substantial, measurable benefits in scoped enterprise workflows (contact centers, process automation, CRM, and knowledge work), but realizing gains at scale requires disciplined pilots, rigorous KPIs, and a layered security/privacy and contractual strategy that balances cloud delivery speed against thirdâ€‘party exposure. The evidence base combines vendor case studies, independent analyses, and security expert reports cited throughout.\n",
       "\n",
       "The next section reviews LLM technical foundations and background assumptions that underpin both the opportunities and the risks described here.\n",
       "\n",
       "\n",
       "## Background and Technical Foundations\n",
       "\n",
       "To ground the reportâ€™s claims about opportunity and risk, this section summarizes what LLMs are, how enterprises typically deploy them, and the basic threat surface and regulatory context that shape controls and tradeoffs.\n",
       "\n",
       "Large language models (LLMs) are statistical neural networks trained on large text corpora to predict and generate human-like language; in enterprise use they are applied as generation, summarization, classification, and retrieval-augmented components. Typical deployment patterns include: (1) cloud API consumption of thirdâ€‘party hosted models, (2) managed/virtual private inference (cloud-managed services with VPC or private endpoints, e.g., Azure AI Foundry used for multi-app delivery) (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/), and (3) onâ€‘premises or private inference (self-hosted GPU clusters or appliance-based inference) to reduce external exposure. Each architecture trades delivery speed, scalability, and cost against control over data, telemetry, and vendor access. \n",
       "\n",
       "The enterprise threat surface centers on data exposure (PII/PHI), model-based attacks, and operational telemetry. Practical vectors include memorized leakage and model inversion, promptâ€‘injection and reprompt-style exfiltration, insecure telemetry/logging that persists user inputs, and leakage during fineâ€‘tuning or when sharing training traces (Source: https://cloudatg.com/; https://medium.com/@bijit211987/llm-privacy-and-security-56a859cbd1cb). Fineâ€‘tuning and feedback telemetry are especially sensitive because they can embed customer data into model parameters or logs; controllers must treat these artifacts as potential personal data (Source: expert report: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf).\n",
       "\n",
       "Regulatory obligations under GDPR and CCPA apply when LLMs process personal data: lawful basis, purpose limitation, data minimization, DPIAs for highâ€‘risk processing, and enabling of data subject rights. Nonâ€‘technical exposures (logs, vendor access) can produce compliance failures; contractual safeguards (DPAs, SOC 2, BAAs) complement technical controls (encryption in transit/at rest, VPC/private endpoints, TEEs/HSMs for keys, query filtering, prompt sanitization, RBAC) (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf; https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12). \n",
       "\n",
       "These foundations frame later sectionsâ€™ discussion of highâ€‘ROI use cases and a risk matrix mapping attack vectors to operational and contractual mitigations.\n",
       "\n",
       "With that technical and regulatory baseline established, the report next examines where LLMs deliver the clearest business value and measurable ROI in scoped enterprise workflows.\n",
       "\n",
       "\n",
       "## Business Benefits and Highâ€‘ROI Use Cases\n",
       "\n",
       "With the technical foundations and regulatory constraints in view, we next consider where LLMs show the clearest, measurable business value and which workflows are most likely to deliver nearâ€‘term ROI.\n",
       "\n",
       "Enterprises are seeing the strongest, repeatable value from LLMs when models are applied to narrowly scoped workflows that replace routine human effort or accelerate decisionmaking. Four categories have consistent vendor and caseâ€‘study support:\n",
       "\n",
       "- Contactâ€‘center automation: Generative assistants and assisted-agent UIs can materially reduce Average Handle Time (AHT), increase capacity, and cut cost per contact. A vendor case study reports a ~40% reduction in AHT after deploying generative AI across support channels, a level of impact that translates directly to FTE savings or higher throughput (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12). Measured KPIs: AHT, firstâ€‘contact resolution, cost per contact, and NPS.\n",
       "\n",
       "- Process and document automation: Invoice processing, compliance checks, contract triage, and structured-data extraction are highâ€‘ROI targets because they replace repetitive, rulesâ€‘driven work and integrate well with RPA and workflow engines. Vendors and industry writeâ€‘ups highlight fast payback in backâ€‘office workflows where accuracy thresholds are achievable and measurable (Source: https://iapptechnologies.com/blog/ai-use-cases-enterprise-roi-2026).\n",
       "\n",
       "- CRM and sales enablement: Automated call summaries, record updates, and nextâ€‘best action recommendations reduce administrative lift and accelerate pipeline management. CRM vendors report â€œmillions of dollarsâ€ saved in aggregate for customers who automate these tasks, though outcomes vary by customer size and process maturity (Source: https://deselect.com/blog/ai-for-crm-how-to-turn-customer-data-into-revenue-in-2026/). Key metrics: time saved per rep, data completeness, and revenue uplift.\n",
       "\n",
       "- Knowledgeâ€‘worker and developer productivity: Copilots and codeâ€‘assist tools shorten development cycles, reduce debugging time, and speed content creationâ€”benefits that scale with adoption and careful integration into workflows (Source: Microsoft customer stories: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/).\n",
       "\n",
       "Caveats and measurement guidance: many highâ€‘impact figures come from vendors or singleâ€‘customer case studies; independent analyses paint a more conservative pictureâ€”IBM reports average enterpriseâ€‘wide AI ROI near 5.9% when initiatives are broad rather than tightly scoped (Source: https://www.ibm.com/think/insights/ai-roi). To bridge this gap, run controlled pilots with preâ€‘specified KPIs (FTE saved, minutes per transaction, AHT, resolution rate, revenue uplift, NPS) and baseline measurements (Source: PwC/Terralogic guidance). Finally, choose deployment models (cloud vs onâ€‘prem) with the workloadâ€™s regulatory and telemetry risks in mind; cloud speeds delivery but raises thirdâ€‘party exposure (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf).\n",
       "\n",
       "Having identified the highâ€‘ROI opportunities and the measurement discipline required, the report now turns to the security, privacy, and compliance risks that must be mitigated to realize those benefits at scale.\n",
       "\n",
       "\n",
       "## Security, Privacy, and Compliance Risks\n",
       "\n",
       "With highâ€‘ROI workflows identified, enterprises must confront a clustered set of technical and nonâ€‘technical risks that can erode value or create compliance failures if left unmanaged.\n",
       "\n",
       "Core technical risks include data leakage via memorization (models reproducing sensitive training tokens), model inversion and membershipâ€‘inference attacks that reveal whether specific records were present in training data, and promptâ€‘injection/reprompt attacks that subvert model behavior to exfiltrate secrets (including reported â€œsingleâ€‘clickâ€ exfiltration vectors) (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf; Source: https://cloudatg.com/; Source: https://medium.com/@bijit211987/llm-privacy-and-security-56a859cbd1cb). Nonâ€‘technical exposures include insecure telemetry and logging (retained prompts, PII in traces), and risk during fineâ€‘tuning or when using thirdâ€‘party APIs that grant vendors access to raw data. Practical examples: contactâ€‘center summaries that include customer identifiers can be memorized or logged and later exposed if telemetry isnâ€™t sanitized (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12).\n",
       "\n",
       "Regulatory implications are material: processing personal data through LLMs triggers GDPR/CCPA obligations (lawful basis, purpose limitation, DPIAs where processing is high risk, and honoring data subject rights). Where health or HIPAAâ€‘regulated data is involved, Business Associate Agreements (BAAs) and specific technical safeguards are required; contractual assurances (Data Processing Agreements, SOC 2 reports) are essential complements to engineering controls (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf).\n",
       "\n",
       "Recommended technical controls include private/onâ€‘prem or VPCâ€‘restricted inference to limit thirdâ€‘party access (tradeoff: slower timeâ€‘toâ€‘value vs lower exposure, illustrated by Azure-powered rapid delivery at scale) (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). Enforce encryption in transit/at rest, use TEEs/HSMs for key isolation, apply data minimization and prompt sanitization, and implement promptâ€‘filtering and robust telemetry retention policies. Consider differentialâ€‘privacy techniques or synthetic data for fineâ€‘tuning, and strict roleâ€‘based access control for model ops (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf). Contractual controls should mandate DPAs, SOC 2/audit evidence, BAAs where applicable, and clear SLAs on logging/retention and incident response. Finally, validate protections via DPIAs, redâ€‘team promptâ€‘injection tests, and scoped pilots with measurable KPIs before scaling (Source: https://www.ibm.com/think/insights/ai-roi; Source: https://terralogic.com/ai-applications-in-business-trends-opportunities-challenges-2026/).\n",
       "\n",
       "Having cataloged risks and controls, the report next examines deployment models and operational tradeoffs that determine how those mitigations are implemented in practice.\n",
       "\n",
       "\n",
       "## Deployment Models and Operational Challenges\n",
       "\n",
       "With risks and mitigations mapped in the previous section, deployment choices determine which controls are practical and how quickly business value can be realized.\n",
       "\n",
       "Enterprises face a clear dichotomy: adopt cloudâ€‘managed AI platforms for rapid delivery and rich ecosystems, or insist on private/onâ€‘prem inference to minimize thirdâ€‘party exposure. Cloud platforms accelerate timeâ€‘toâ€‘production through managed tooling, connectors, and orchestration â€” for example, EchoStar used Azure AI Foundry to deliver 12 production applications across sales, retention, and field service (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). Contactâ€‘center vendors likewise report large operational gains (vendor case study: 40% AHT reduction) that are easiest to realize via cloud delivery (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12). \n",
       "\n",
       "Those speed and ecosystem advantages come with operational and contractual tradeoffs. Cloud inference commonly produces telemetry, logs, and modelâ€‘interaction data that can create compliance and IP exposures unless contractual and technical safeguards (DPAs, SOC2, BAAs; VPC isolation, telemetry controls) are in place (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf). By contrast, onâ€‘prem or private inference reduces vendor access and data exfiltration risk but increases capital and operational cost (hardware, cooling, HSMs/TEEs), slows model updates, and adds integration burden across CI/CD, monitoring, and data pipelines.\n",
       "\n",
       "Practically, organizations struggle with cost forecasting, integration complexity, observability of model quality and drift, and lifecycle governance (fineâ€‘tuning, rollback, and controlled updates). Many published ROI figures are vendorâ€‘led; independent evaluations are scarce, creating measurement gaps that make enterprise scaling risky. Independent analysis has shown that broad, unfocused AI programs often deliver modest enterpriseâ€‘level ROI (~5.9%), underscoring the value of scoped pilots with preâ€‘defined KPIs (Source: https://www.ibm.com/think/insights/ai-roi; see guidance on scoping and KPIs: https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html).\n",
       "\n",
       "Given these operational tradeoffs and evidence limitations, the next section analyzes how to structure pilots and measurement frameworks that balance speed, security, and measurable ROI.\n",
       "\n",
       "\n",
       "## Analysis and Discussion\n",
       "\n",
       "Building on the operational tradeoffs outlined above, this section synthesizes evidence into practical frameworks that help teams prioritize use cases, run disciplined pilots, and map concrete controls to known attack vectors.\n",
       "\n",
       "1) Evidenceâ€‘weighted riskâ€“benefit matrix: map highâ€‘ROI workflows against security exposure and expected ROI. Empirical and vendor reports converge on four highâ€‘priority buckets: contactâ€‘center automation (large AHT reductions reported; vendor case: 40% AHT drop) (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12), document/process automation and RAGâ€‘backed knowledge tools (high ROI, controllable data scope) (Source: https://iapptechnologies.com/blog/ai-use-cases-enterprise-roi-2026), CRM/sales enablement (significant vendorâ€‘reported revenue/admin savings) (Source: https://deselect.com/blog/ai-for-crm-how-to-turn-customer-data-into-revenue-in-2026/), and developer/knowledge worker copilots (productivity gains). Independent analyses temper enterpriseâ€‘wide ROI expectations (e.g., IBM ~5.9% average) and highlight that tightly scoped pilots outperform broad programs (Source: https://www.ibm.com/think/insights/ai-roi).\n",
       "\n",
       "2) Recommended pilot framework and KPIs: run short (6â€“12 week) controlled pilots with preâ€‘defined KPIs and measurement guidance. Core KPIs: FTE saved (modeled from timeâ€‘andâ€‘motion baselines), minutes per transaction, Average Handle Time (AHT), resolution rate, revenue uplift (attributable lift), and NPS/CSAT. Measurement guidance: capture pre/post baselines, use A/B or randomized rollout where feasible, instrument latency/error/rollback metrics, log human overrides, and ensure sample sizes and confidence intervals are calculated. Vendors and consultancies recommend scoping to single workflows, setting clear success thresholds, and requiring independent validation before scale (Source: https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html; https://terralogic.com/ai-applications-in-business-trends-opportunities-challenges-2026/).\n",
       "\n",
       "3) Controls mapping (attack vector â†’ mitigations):\n",
       "- Promptâ€‘injection: input validation, prompt templates, output sanitization, adversarial redâ€‘teaming (Source: https://cloudatg.com/).\n",
       "- Exfiltration/memorization: data minimization, context window controls, RAG with sanitized indices, private inference/VPC or onâ€‘prem inference (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf).\n",
       "- Telemetry/logging leakage: strict logging policies, PII redaction, contractual guarantees (DPA, SOC2, BAA), and encrypted telemetry pipelines.\n",
       "- Model inversion/membership inference: differential privacy for fineâ€‘tuning, access controls, TEEs/HSMs for key management.\n",
       "\n",
       "Across all mappings, combine technical barriers with contractual assurances and DPIAs. Recognize evidence gaps: many ROI claims are vendorâ€‘reported and cloud platforms accelerate delivery (EchoStar on Azure) but increase thirdâ€‘party exposureâ€”tradeoffs must be evaluated per use case (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/; Source: https://www.ibm.com/think/insights/ai-roi).\n",
       "\n",
       "The following section draws conclusions and prescriptive recommendations that operationalize these frameworks for executive decisionâ€‘making and rollout governance.\n",
       "\n",
       "\n",
       "## Conclusion and Recommendations\n",
       "\n",
       "Building on the frameworks in the previous section, we now synthesize where LLMs provide the clearest enterprise value, which risks require mitigation, and the concrete next steps leaders should take to move from pilots to safe scale.\n",
       "\n",
       "LLMs are most likely to deliver measurable, near-term enterprise value when applied to narrowly scoped workflows that produce time- or costâ€‘based KPIs: contactâ€‘center automation (notably AHT and resolution improvements; vendor case study: 40% AHT reduction) (Source: https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12); document and process automation (invoicing, compliance checks, onboarding) and CRM/sales enablement (automated summaries, record updates, nextâ€‘best action) (Source: https://deselect.com/blog/ai-for-crm-how-to-turn-customer-data-into-revenue-in-2026/; https://iapptechnologies.com/blog/ai-use-cases-enterprise-roi-2026); and knowledgeâ€‘worker copilot scenarios that increase developer and analyst productivity (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). At the same time, core security and compliance risksâ€”data leakage via memorization, promptâ€‘injection and reprompt attacks, model inversion/membership inference, insecure telemetry/logging, and exposures during fineâ€‘tuning or thirdâ€‘party inferenceâ€”must be managed through a mix of technical and contractual controls (Source: https://cloudatg.com/; https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf). Regulatory obligations under GDPR/CCPA amplify nonâ€‘technical requirements (DPIAs, lawful basis, data minimization) and make contractual assurances (DPAs, SOC2, BAAs) essential complements to engineering controls (Source: https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf). Prioritized recommendations: 1) Run controlled pilots on highâ€‘ROI workflows with preâ€‘defined KPIs (FTE saved, AHT, minutes per transaction, revenue uplift, NPS) and baseline measurements; validate results via independent TEIâ€‘style evaluation rather than relying only on vendor case studies (Source: https://www.ibm.com/think/insights/ai-roi). 2) Implement layered controls: private or VPCâ€‘restricted inference where required, encryption, TEEs/HSMs for keys, promptâ€‘sanitization, telemetry policies, RBAC, and contractual assurances. 3) Choose deployment model per regulatory contextâ€”favor onâ€‘prem/isolated inference for highâ€‘sensitivity data, cloud for rapid app delivery where controls suffice (Source: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/). 4) Commission independent TEI/Forresterâ€‘style evaluations for scaling decisions to correct for vendor optimism. Finally, maintain a measurement plan that tracks both business KPIs and security telemetry to detect regressions early.\n",
       "\n",
       "The following materials provide an implementation checklist and sample pilot protocol to operationalize these recommendations and the KPI-driven methodology described earlier.\n",
       "\n",
       "\n",
       "## Limitations and Caveats\n",
       "\n",
       "The following aspects could not be fully addressed:\n",
       "\n",
       "- The full document is truncated mid-sentence in the Security section (\"Consider differentialâ€‘privacy te...\") and the subsequent sections (Deployment Models and Operational Challenges, Analysis and Discussion, Conclusion and Recommendations) are missing or incomplete. This prevents assessment of key arguments, mitigations, deployment guidance, the promised riskâ€‘benefit matrix, and final recommendations that are central to the thesis.\n",
       "- Many headline benefit figures (AHT reductions, 'millions of dollars saved', multi-application rollouts) are sourced to vendor blogs and singleâ€‘customer case studies. The report relies heavily on these sources without sufficient independent, systematically gathered evidence or methodologically described evaluations.\n",
       "- Security mitigations are asserted at a high level (VPCs, TEEs/HSMs, prompt filtering, telemetry policies) but the discussion is truncated and lacks implementation detail, tradeoffs, cost implications, monitoring strategies, and references to authoritative security frameworks and advisories.\n",
       "- The Deployment Models and Operational Challenges section is absent from the supplied full text. The thesis explicitly depends on a 'layered security/privacy and contractual strategy' and a 'cloud-vs-onprem decision framework', but the document does not contain the promised operational guidance or evaluation of deployment tradeoffs.\n",
       "- The Analysis and Discussion section is missing. The report promises an 'evidence-weighted riskâ€‘benefit matrix' and discussion of enterprise-wide ROI heterogeneity, but does not present those artifacts, quantitative analyses, or sensitivity checks.\n",
       "\n",
       "## References\n",
       "\n",
       "1. https://www.yourdictionary.com/large\n",
       "2. https://www.thefreedictionary.com/Large\n",
       "3. https://iapptechnologies.com/blog/ai-use-cases-enterprise-roi-2026\n",
       "4. https://www.oxfordlearnersdictionaries.com/definition/american_english/large\n",
       "5. https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/\n",
       "6. https://negd.gov.in/wp-content/uploads/2025/12/document-3.pdf\n",
       "7. https://cloudatg.com/\n",
       "8. https://arxiv.org/list/cs/new\n",
       "9. https://cloudsecurityalliance.org/blog/2024/08/22/understanding-the-differences-between-fully-homomorphic-encryption-and-confidential-computing\n",
       "10. https://www.merriam-webster.com/dictionary/large\n",
       "11. https://dictionary.cambridge.org/dictionary/english/large\n",
       "12. https://medium.com/@bijit211987/llm-privacy-and-security-56a859cbd1cb\n",
       "13. https://hazyresearch.stanford.edu/blog/2025-05-12-security\n",
       "14. https://arxiv.org/abs/2509.01253\n",
       "15. https://terralogic.com/ai-applications-in-business-trends-opportunities-challenges-2026/\n",
       "16. https://next.redhat.com/2025/10/23/enhancing-ai-inference-security-with-confidential-computing-a-path-to-private-data-inference-with-proprietary-llms/\n",
       "17. search://516675066044b5a2\n",
       "18. https://onereach.ai/blog/agentic-ai-adoption-rates-roi-market-trends/\n",
       "19. https://intuitionlabs.ai/articles/private-llm-pharma-compliance-architecture\n",
       "20. search://0aeb7c246887b098\n",
       "21. https://www.aigl.blog/content/files/2025/07/Privacy-and-Data-Protection-Risks-in-Large-Language-Models--LLMs-.pdf\n",
       "22. https://data.www.sbir.gov/mod_awarddatapublic/award_data.csv\n",
       "23. https://www.wordreference.com/definition/large\n",
       "24. https://www.uhd.nhs.uk/assets/uploads/members/Board-of-Directors-Part-1-14-January-2026.pdf\n",
       "25. https://www.ibm.com/think/insights/ai-roi\n",
       "26. https://www.reddit.com/r/cryptography/comments/1q1hqq0/homomorphic_encryption_for_llm_inference_is_it/\n",
       "27. https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\n",
       "28. https://www.agilesoftlabs.com/blog/2026/01/generative-ai-in-enterprises-12\n",
       "29. https://www.gartner.com/ngw/globalassets/en/information-technology/documents/top-10-strategic-technology-trends-for-2018.pdf.\n",
       "30. https://www.collinsdictionary.com/dictionary/english/large\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ln3tqjr1s7",
   "metadata": {},
   "source": [
    "# Test Execution Section\n",
    "\n",
    "This section runs the 5-query test dataset against this notebook variant and saves outputs for comparison.\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "test_output/\n",
    "    question_1/\n",
    "        question_1_V08-1.md\n",
    "    question_2/\n",
    "        question_2_V08-1.md\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Instructions:**\n",
    "1. Run all cells above first to define the agent\n",
    "2. Run the cells below to execute tests\n",
    "3. Choose to run a single question or all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2gi2vluphba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Setup and Configuration\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = Path('.').resolve()\n",
    "OUTPUT_DIR = NOTEBOOK_DIR / 'test_output'\n",
    "DATASET_PATH = NOTEBOOK_DIR / 'test_dataset.yaml'\n",
    "\n",
    "# Notebook version (automatically set based on filename)\n",
    "CURRENT_VERSION = \"V08-1\"\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load test dataset\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    dataset = yaml.safe_load(f)\n",
    "\n",
    "questions = dataset.get('questions', [])\n",
    "\n",
    "# Create output directories for each question\n",
    "for i in range(1, len(questions) + 1):\n",
    "    question_dir = OUTPUT_DIR / f\"question_{i}\"\n",
    "    question_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Test Configuration:\")\n",
    "print(f\"  Version: {CURRENT_VERSION}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Loaded {len(questions)} test questions\")\n",
    "print(f\"\\nTest Questions:\")\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"  {i}. [{q['category']}] {q['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o09kewrsu4k",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(question_num: int, version: str, result: dict, question_data: dict) -> Path:\n",
    "    \"\"\"Save the output to a markdown file.\"\"\"\n",
    "    output_dir = OUTPUT_DIR / f\"question_{question_num}\"\n",
    "    output_file = output_dir / f\"question_{question_num}_{version}.md\"\n",
    "    \n",
    "    question_text = question_data.get('question', '')\n",
    "    question_title = question_data.get('title', 'Untitled')\n",
    "    question_id = question_data.get('id', f'Q{question_num}')\n",
    "    \n",
    "    content = f\"\"\"# Question {question_num} - {version}\n",
    "\n",
    "                **Question ID:** {question_id}  \n",
    "                **Title:** {question_title}  \n",
    "                **Category:** {question_data.get('category', 'N/A')}  \n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Original Question\n",
    "\n",
    "                {question_text}\n",
    "\n",
    "                ---\n",
    "\n",
    "                ## Research Report\n",
    "\n",
    "                {result.get('output', 'No output generated')}\n",
    "\n",
    "                \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hsx94u26rdg",
   "metadata": {},
   "source": [
    "## Run All Questions Test\n",
    "\n",
    "Run ALL 5 questions for comprehensive testing:\n",
    "\n",
    "**WARNING:** This will take 30-60+ minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "at65okof4q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ALL questions for the current version\n",
    "# WARNING: This will take a long time (potentially 30-60+ minutes)\n",
    "\n",
    "print(f\"Running ALL {len(questions)} questions with {CURRENT_VERSION}\")\n",
    "print(f\"Estimated time: 30-60+ minutes\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "results_summary = []\n",
    "overall_start = datetime.now()\n",
    "\n",
    "for i, question_data in enumerate(questions, 1):\n",
    "    question_text = question_data.get('question', '')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question {i}/{len(questions)}: {question_data['title']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        result = await combined_tier1_agent_async({\"question\": question_text})\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        output_file = save_output(i, CURRENT_VERSION, result, question_data)\n",
    "        \n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": len(result.get('output', '')),\n",
    "            \"sources\": len(result.get('source_urls', [])),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Completed in {elapsed:.1f}s - {summary['output_chars']} chars, {summary['sources']} sources\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        summary = {\n",
    "            \"question\": i,\n",
    "            \"title\": question_data['title'],\n",
    "            \"version\": CURRENT_VERSION,\n",
    "            \"elapsed_seconds\": elapsed,\n",
    "            \"output_chars\": 0,\n",
    "            \"sources\": 0,\n",
    "            \"status\": f\"error: {str(e)}\"\n",
    "        }\n",
    "        print(f\"FAILED: {e}\")\n",
    "    \n",
    "    results_summary.append(summary)\n",
    "\n",
    "# Save summary\n",
    "overall_elapsed = (datetime.now() - overall_start).total_seconds()\n",
    "\n",
    "summary_file = OUTPUT_DIR / f\"summary_{CURRENT_VERSION}.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"run_time\": datetime.now().isoformat(),\n",
    "        \"version\": CURRENT_VERSION,\n",
    "        \"total_elapsed_seconds\": overall_elapsed,\n",
    "        \"questions_tested\": len(questions),\n",
    "        \"results\": results_summary\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL TESTS COMPLETE for {CURRENT_VERSION}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total time: {overall_elapsed:.1f} seconds ({overall_elapsed/60:.1f} minutes)\")\n",
    "print(f\"Summary saved: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
